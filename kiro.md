Repository: jwadow/kiro-openai-gateway
Files analyzed: 40

Estimated tokens: 161.5k

Directory structure:
‚îî‚îÄ‚îÄ jwadow-kiro-openai-gateway/
    ‚îú‚îÄ‚îÄ README.md
    ‚îú‚îÄ‚îÄ CLA.md
    ‚îú‚îÄ‚îÄ CONTRIBUTORS.md
    ‚îú‚îÄ‚îÄ LICENSE
    ‚îú‚îÄ‚îÄ main.py
    ‚îú‚îÄ‚îÄ manual_api_test.py
    ‚îú‚îÄ‚îÄ pytest.ini
    ‚îú‚îÄ‚îÄ requirements.txt
    ‚îú‚îÄ‚îÄ .clabot
    ‚îú‚îÄ‚îÄ .env.example
    ‚îú‚îÄ‚îÄ docs/
    ‚îÇ   ‚îú‚îÄ‚îÄ en/
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ARCHITECTURE.md
    ‚îÇ   ‚îî‚îÄ‚îÄ ru/
    ‚îÇ       ‚îî‚îÄ‚îÄ ARCHITECTURE.md
    ‚îú‚îÄ‚îÄ kiro_gateway/
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ auth.py
    ‚îÇ   ‚îú‚îÄ‚îÄ cache.py
    ‚îÇ   ‚îú‚îÄ‚îÄ config.py
    ‚îÇ   ‚îú‚îÄ‚îÄ converters.py
    ‚îÇ   ‚îú‚îÄ‚îÄ debug_logger.py
    ‚îÇ   ‚îú‚îÄ‚îÄ exceptions.py
    ‚îÇ   ‚îú‚îÄ‚îÄ http_client.py
    ‚îÇ   ‚îú‚îÄ‚îÄ models.py
    ‚îÇ   ‚îú‚îÄ‚îÄ parsers.py
    ‚îÇ   ‚îú‚îÄ‚îÄ routes.py
    ‚îÇ   ‚îú‚îÄ‚îÄ streaming.py
    ‚îÇ   ‚îú‚îÄ‚îÄ tokenizer.py
    ‚îÇ   ‚îî‚îÄ‚îÄ utils.py
    ‚îú‚îÄ‚îÄ tests/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ conftest.py
    ‚îÇ   ‚îú‚îÄ‚îÄ integration/
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_full_flow.py
    ‚îÇ   ‚îî‚îÄ‚îÄ unit/
    ‚îÇ       ‚îú‚îÄ‚îÄ test_auth_manager.py
    ‚îÇ       ‚îú‚îÄ‚îÄ test_cache.py
    ‚îÇ       ‚îú‚îÄ‚îÄ test_config.py
    ‚îÇ       ‚îú‚îÄ‚îÄ test_converters.py
    ‚îÇ       ‚îú‚îÄ‚îÄ test_debug_logger.py
    ‚îÇ       ‚îú‚îÄ‚îÄ test_http_client.py
    ‚îÇ       ‚îú‚îÄ‚îÄ test_parsers.py
    ‚îÇ       ‚îú‚îÄ‚îÄ test_routes.py
    ‚îÇ       ‚îú‚îÄ‚îÄ test_streaming.py
    ‚îÇ       ‚îî‚îÄ‚îÄ test_tokenizer.py
    ‚îî‚îÄ‚îÄ .github/
        ‚îî‚îÄ‚îÄ ISSUE_TEMPLATE/
            ‚îî‚îÄ‚îÄ bug_report.yml


================================================
FILE: README.md
================================================
<div align="center">

# üöÄ Kiro OpenAI Gateway

**OpenAI-compatible proxy gateway for Kiro IDE API (AWS CodeWhisperer)**

[![License: AGPL v3](https://img.shields.io/badge/License-AGPL%20v3-blue.svg)](https://www.gnu.org/licenses/agpl-3.0)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)](https://fastapi.tiangolo.com/)

*Use Claude models through any tools that support the OpenAI API*

[Features](#-features) ‚Ä¢ [Quick Start](#-quick-start) ‚Ä¢ [Configuration](#%EF%B8%8F-configuration) ‚Ä¢ [API Reference](#-api-reference) ‚Ä¢ [License](#-license)

</div>

---

## ‚ú® Features

| Feature | Description |
|---------|-------------|
| üîå **OpenAI-compatible API** | Works with any OpenAI client out of the box |
| üí¨ **Full message history** | Passes complete conversation context |
| üõ†Ô∏è **Tool Calling** | Supports function calling in OpenAI format |
| üì° **Streaming** | Full SSE streaming support |
| üîÑ **Retry Logic** | Automatic retries on errors (403, 429, 5xx) |
| üìã **Extended model list** | Including versioned models |
| üîê **Smart token management** | Automatic refresh before expiration |
| üß© **Modular architecture** | Easy to extend with new providers |

---

## üöÄ Quick Start

### Prerequisites

- Python 3.10+
- [Kiro IDE](https://kiro.dev/) with logged in account

### Installation

```bash
# Clone the repository
git clone https://github.com/Jwadow/kiro-openai-gateway.git
cd kiro-openai-gateway

# Install dependencies
pip install -r requirements.txt

# Configure (see Configuration section)
cp .env.example .env
# Edit .env with your credentials

# Start the server
python main.py
```

The server will be available at `http://localhost:8000`

---

## ‚öôÔ∏è Configuration

### Option 1: JSON Credentials File

Specify the path to the credentials file:

```env
KIRO_CREDS_FILE="~/.aws/sso/cache/kiro-auth-token.json"

# Password to protect YOUR proxy server (make up any secure string)
# You'll use this as api_key when connecting to your gateway
PROXY_API_KEY="my-super-secret-password-123"
```

<details>
<summary>üìÑ JSON file format</summary>

```json
{
  "accessToken": "eyJ...",
  "refreshToken": "eyJ...",
  "expiresAt": "2025-01-12T23:00:00.000Z",
  "profileArn": "arn:aws:codewhisperer:us-east-1:...",
  "region": "us-east-1"
}
```

</details>

### Option 2: Environment Variables (.env file)

Create a `.env` file in the project root:

```env
# Required
REFRESH_TOKEN="your_kiro_refresh_token"

# Password to protect YOUR proxy server (make up any secure string)
PROXY_API_KEY="my-super-secret-password-123"

# Optional
PROFILE_ARN="arn:aws:codewhisperer:us-east-1:..."
KIRO_REGION="us-east-1"
```

### Getting the Refresh Token

The refresh token can be obtained by intercepting Kiro IDE traffic. Look for requests to:
- `prod.us-east-1.auth.desktop.kiro.dev/refreshToken`

---

## üì° API Reference

### Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Health check |
| `/health` | GET | Detailed health check |
| `/v1/models` | GET | List available models |
| `/v1/chat/completions` | POST | Chat completions |

### Available Models

| Model | Description |
|-------|-------------|
| `claude-opus-4-5` | Top-tier model |
| `claude-opus-4-5-20251101` | Top-tier model (versioned) |
| `claude-sonnet-4-5` | Enhanced model |
| `claude-sonnet-4-5-20250929` | Enhanced model (versioned) |
| `claude-sonnet-4` | Balanced model |
| `claude-sonnet-4-20250514` | Balanced model (versioned) |
| `claude-haiku-4-5` | Fast model |
| `claude-3-7-sonnet-20250219` | Legacy model |

---

## üí° Usage Examples

<details>
<summary>üîπ Simple cURL Request</summary>

```bash
curl http://localhost:8000/v1/chat/completions \
  -H "Authorization: Bearer my-super-secret-password-123" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "claude-sonnet-4-5",
    "messages": [{"role": "user", "content": "Hello!"}],
    "stream": true
  }'
```

> **Note:** Replace `my-super-secret-password-123` with the `PROXY_API_KEY` you set in your `.env` file.

</details>

<details>
<summary>üîπ Streaming Request</summary>

```bash
curl http://localhost:8000/v1/chat/completions \
  -H "Authorization: Bearer my-super-secret-password-123" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "claude-sonnet-4-5",
    "messages": [
      {"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "What is 2+2?"}
    ],
    "stream": true
  }'
```

</details>

<details>
<summary>üîπ With Tool Calling</summary>

```bash
curl http://localhost:8000/v1/chat/completions \
  -H "Authorization: Bearer my-super-secret-password-123" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "claude-sonnet-4-5",
    "messages": [{"role": "user", "content": "What is the weather in London?"}],
    "tools": [{
      "type": "function",
      "function": {
        "name": "get_weather",
        "description": "Get weather for a location",
        "parameters": {
          "type": "object",
          "properties": {
            "location": {"type": "string", "description": "City name"}
          },
          "required": ["location"]
        }
      }
    }]
  }'
```

</details>

<details>
<summary>üêç Python OpenAI SDK</summary>

```python
from openai import OpenAI

client = OpenAI(
    base_url="http://localhost:8000/v1",
    api_key="my-super-secret-password-123"  # Your PROXY_API_KEY from .env
)

response = client.chat.completions.create(
    model="claude-sonnet-4-5",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello!"}
    ],
    stream=True
)

for chunk in response:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="")
```

</details>

<details>
<summary>ü¶ú LangChain</summary>

```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    base_url="http://localhost:8000/v1",
    api_key="my-super-secret-password-123",  # Your PROXY_API_KEY from .env
    model="claude-sonnet-4-5"
)

response = llm.invoke("Hello, how are you?")
print(response.content)
```

</details>

---

## üìÅ Project Structure

```
kiro-openai-gateway/
‚îú‚îÄ‚îÄ main.py                    # Entry point, FastAPI app creation
‚îú‚îÄ‚îÄ requirements.txt           # Python dependencies
‚îú‚îÄ‚îÄ .env.example               # Environment configuration example
‚îÇ
‚îú‚îÄ‚îÄ kiro_gateway/              # Main package
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py            # Package exports
‚îÇ   ‚îú‚îÄ‚îÄ config.py              # Configuration and constants
‚îÇ   ‚îú‚îÄ‚îÄ models.py              # Pydantic models for OpenAI API
‚îÇ   ‚îú‚îÄ‚îÄ auth.py                # KiroAuthManager - token management
‚îÇ   ‚îú‚îÄ‚îÄ cache.py               # ModelInfoCache - model caching
‚îÇ   ‚îú‚îÄ‚îÄ utils.py               # Helper utilities
‚îÇ   ‚îú‚îÄ‚îÄ converters.py          # OpenAI <-> Kiro conversion
‚îÇ   ‚îú‚îÄ‚îÄ parsers.py             # AWS SSE stream parsers
‚îÇ   ‚îú‚îÄ‚îÄ streaming.py           # Response streaming logic
‚îÇ   ‚îú‚îÄ‚îÄ http_client.py         # HTTP client with retry logic
‚îÇ   ‚îú‚îÄ‚îÄ debug_logger.py        # Debug logging (optional)
‚îÇ   ‚îî‚îÄ‚îÄ routes.py              # FastAPI routes
‚îÇ
‚îú‚îÄ‚îÄ tests/                     # Tests
‚îÇ   ‚îú‚îÄ‚îÄ unit/                  # Unit tests
‚îÇ   ‚îî‚îÄ‚îÄ integration/           # Integration tests
‚îÇ
‚îî‚îÄ‚îÄ debug_logs/                # Debug logs (generated when enabled)
```

---

## üîß Debugging

Debug logging is **disabled by default**. To enable, add to your `.env`:

```env
# Debug logging mode:
# - off: disabled (default)
# - errors: save logs only for failed requests (4xx, 5xx) - recommended for troubleshooting
# - all: save logs for every request (overwrites on each request)
DEBUG_MODE=errors
```

### Debug Modes

| Mode | Description | Use Case |
|------|-------------|----------|
| `off` | Disabled (default) | Production |
| `errors` | Save logs only for failed requests (4xx, 5xx) | **Recommended for troubleshooting** |
| `all` | Save logs for every request | Development/debugging |

### Debug Files

When enabled, requests are logged to the `debug_logs/` folder:

| File | Description |
|------|-------------|
| `request_body.json` | Incoming request from client (OpenAI format) |
| `kiro_request_body.json` | Request sent to Kiro API |
| `response_stream_raw.txt` | Raw stream from Kiro |
| `response_stream_modified.txt` | Transformed stream (OpenAI format) |
| `app_logs.txt` | Application logs for the request |
| `error_info.json` | Error details (only on errors) |

---

## üß™ Testing

```bash
# Run all tests
pytest

# Run unit tests only
pytest tests/unit/

# Run with coverage
pytest --cov=kiro_gateway
```

---

## üîå Extending with New Providers

The modular architecture makes it easy to add support for other providers:

1. Create a new module `kiro_gateway/providers/new_provider.py`
2. Implement the required classes:
   - `NewProviderAuthManager` ‚Äî token management
   - `NewProviderConverter` ‚Äî format conversion
   - `NewProviderParser` ‚Äî response parsing
3. Add routes to `routes.py` or create a separate router

---

## üìú License

This project is licensed under the **GNU Affero General Public License v3.0 (AGPL-3.0)**.

This means:
- ‚úÖ You can use, modify, and distribute this software
- ‚úÖ You can use it for commercial purposes
- ‚ö†Ô∏è **You must disclose source code** when you distribute the software
- ‚ö†Ô∏è **Network use is distribution** ‚Äî if you run a modified version on a server and let others interact with it, you must make the source code available to them
- ‚ö†Ô∏è Modifications must be released under the same license

See the [LICENSE](LICENSE) file for the full license text.

### Why AGPL-3.0?

AGPL-3.0 ensures that improvements to this software benefit the entire community. If you modify this gateway and deploy it as a service, you must share your improvements with your users.

### Contributor License Agreement (CLA)

By submitting a contribution to this project, you agree to the terms of our [Contributor License Agreement (CLA)](CLA.md). This ensures that:
- You have the right to submit the contribution
- You grant the maintainer rights to use and relicense your contribution
- The project remains legally protected

---

## üë§ Author

**Jwadow** ‚Äî [@Jwadow](https://github.com/jwadow)

---

## ‚ö†Ô∏è Disclaimer

This project is not affiliated with, endorsed by, or sponsored by Amazon Web Services (AWS), Anthropic, or Kiro IDE. Use at your own risk and in compliance with the terms of service of the underlying APIs.

---

<div align="center">

**[‚¨Ü Back to Top](#-kiro-openai-gateway)**

</div>



================================================
FILE: CLA.md
================================================
# Contributor License Agreement (CLA)

**Kiro OpenAI Gateway**

Version 1.0 ‚Äî Effective Date: December 2025

---

## Introduction

Thank you for your interest in contributing to **Kiro OpenAI Gateway** (the "Project"), maintained by **Jwadow** (the "Maintainer"). This Contributor License Agreement ("Agreement") documents the rights granted by contributors to the Maintainer.

By submitting a Contribution to this Project, you accept and agree to the following terms and conditions for your present and future Contributions.

---

## 1. Definitions

**"You" (or "Your")** means the copyright owner or legal entity authorized by the copyright owner that is making this Agreement with the Maintainer.

**"Contribution"** means any original work of authorship, including any modifications or additions to an existing work, that is intentionally submitted by You to the Maintainer for inclusion in the Project. This includes any communication sent to the Project's repositories, issue trackers, mailing lists, or any other communication channel.

**"Submitted"** means any form of electronic, verbal, or written communication sent to the Maintainer, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems.

---

## 2. Grant of Copyright License

Subject to the terms and conditions of this Agreement, You hereby grant to the Maintainer and to recipients of software distributed by the Maintainer a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to:

- Reproduce, prepare derivative works of, publicly display, publicly perform, sublicense, and distribute Your Contributions and such derivative works
- Relicense the Contribution under any license, including proprietary licenses

---

## 3. Grant of Patent License

Subject to the terms and conditions of this Agreement, You hereby grant to the Maintainer and to recipients of software distributed by the Maintainer a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by You that are necessarily infringed by Your Contribution(s) alone or by combination of Your Contribution(s) with the Work to which such Contribution(s) was submitted.

---

## 4. Representations

You represent that:

### 4.1 Original Work
You are legally entitled to grant the above license. If your employer(s) has rights to intellectual property that you create that includes your Contributions, you represent that:
- You have received permission to make Contributions on behalf of that employer
- Your employer has waived such rights for your Contributions to the Maintainer
- Your employer has executed a separate Corporate CLA with the Maintainer

### 4.2 Third-Party Content
If your Contribution includes or is based on any third-party code, you represent that:
- You have identified all such third-party code in your Contribution
- You have provided complete details of any third-party license or other restriction associated with any part of your Contribution

### 4.3 No Conflicts
Your Contribution does not violate any agreement or obligation you have with any third party.

---

## 5. Support and Warranty Disclaimer

You are not expected to provide support for Your Contributions, except to the extent You desire to provide support. You may provide support for free, for a fee, or not at all.

**UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING, YOU PROVIDE YOUR CONTRIBUTIONS ON AN "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, EITHER EXPRESS OR IMPLIED, INCLUDING, WITHOUT LIMITATION, ANY WARRANTIES OR CONDITIONS OF TITLE, NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.**

---

## 6. Notification of Changes

You agree to notify the Maintainer of any facts or circumstances of which you become aware that would make these representations inaccurate in any respect.

---

## 7. Moral Rights

To the fullest extent permitted under applicable law, You hereby waive, and agree not to assert, all of Your "moral rights" in or relating to Your Contributions for the benefit of the Maintainer, its assigns, and their respective direct and indirect sublicensees.

---

## 8. Governing Law

This Agreement shall be governed by and construed in accordance with the laws of the jurisdiction in which the Maintainer resides, without regard to its conflict of laws provisions.

---

## 9. Entire Agreement

This Agreement constitutes the entire agreement between the parties with respect to the subject matter hereof and supersedes all prior and contemporaneous agreements and understandings, whether written or oral, relating to such subject matter.

---

## How to Sign This CLA

By submitting a pull request or other Contribution to this Project, you signify your acceptance of this Agreement. 

For significant contributions, you may be asked to explicitly confirm your acceptance by:

1. Adding your name to the [CONTRIBUTORS.md](CONTRIBUTORS.md) file (if it exists)
2. Commenting "I have read the CLA and I accept its terms" on your pull request
3. Signing via a CLA bot (if implemented)

---

## Contact

If you have questions about this CLA, please open an issue in the repository or contact the Maintainer directly.

**Maintainer:** Jwadow  
**GitHub:** [@jwadow](https://github.com/jwadow)  
**Project:** [Kiro OpenAI Gateway](https://github.com/jwadow/kiro-openai-gateway)

---

*This CLA is based on the Apache Individual Contributor License Agreement and has been modified for this project.*


================================================
FILE: CONTRIBUTORS.md
================================================
# Contributors

Thank you to all the contributors who have helped improve this project!

## Contributors

- [@Kartvya69](https://github.com/Kartvya69) ‚Äî STREAMING_READ_TIMEOUT feature (#9)



================================================
FILE: LICENSE
================================================
                    GNU AFFERO GENERAL PUBLIC LICENSE
                       Version 3, 19 November 2007

 Copyright (C) 2007 Free Software Foundation, Inc. <https://fsf.org/>
 Everyone is permitted to copy and distribute verbatim copies
 of this license document, but changing it is not allowed.

                            Preamble

  The GNU Affero General Public License is a free, copyleft license for
software and other kinds of works, specifically designed to ensure
cooperation with the community in the case of network server software.

  The licenses for most software and other practical works are designed
to take away your freedom to share and change the works.  By contrast,
our General Public Licenses are intended to guarantee your freedom to
share and change all versions of a program--to make sure it remains free
software for all its users.

  When we speak of free software, we are referring to freedom, not
price.  Our General Public Licenses are designed to make sure that you
have the freedom to distribute copies of free software (and charge for
them if you wish), that you receive source code or can get it if you
want it, that you can change the software or use pieces of it in new
free programs, and that you know you can do these things.

  Developers that use our General Public Licenses protect your rights
with two steps: (1) assert copyright on the software, and (2) offer
you this License which gives you legal permission to copy, distribute
and/or modify the software.

  A secondary benefit of defending all users' freedom is that
improvements made in alternate versions of the program, if they
receive widespread use, become available for other developers to
incorporate.  Many developers of free software are heartened and
encouraged by the resulting cooperation.  However, in the case of
software used on network servers, this result may fail to come about.
The GNU General Public License permits making a modified version and
letting the public access it on a server without ever releasing its
source code to the public.

  The GNU Affero General Public License is designed specifically to
ensure that, in such cases, the modified source code becomes available
to the community.  It requires the operator of a network server to
provide the source code of the modified version running there to the
users of that server.  Therefore, public use of a modified version, on
a publicly accessible server, gives the public access to the source
code of the modified version.

  An older license, called the Affero General Public License and
published by Affero, was designed to accomplish similar goals.  This is
a different license, not a version of the Affero GPL, but Affero has
released a new version of the Affero GPL which permits relicensing under
this license.

  The precise terms and conditions for copying, distribution and
modification follow.

                       TERMS AND CONDITIONS

  0. Definitions.

  "This License" refers to version 3 of the GNU Affero General Public License.

  "Copyright" also means copyright-like laws that apply to other kinds of
works, such as semiconductor masks.

  "The Program" refers to any copyrightable work licensed under this
License.  Each licensee is addressed as "you".  "Licensees" and
"recipients" may be individuals or organizations.

  To "modify" a work means to copy from or adapt all or part of the work
in a fashion requiring copyright permission, other than the making of an
exact copy.  The resulting work is called a "modified version" of the
earlier work or a work "based on" the earlier work.

  A "covered work" means either the unmodified Program or a work based
on the Program.

  To "propagate" a work means to do anything with it that, without
permission, would make you directly or secondarily liable for
infringement under applicable copyright law, except executing it on a
computer or modifying a private copy.  Propagation includes copying,
distribution (with or without modification), making available to the
public, and in some countries other activities as well.

  To "convey" a work means any kind of propagation that enables other
parties to make or receive copies.  Mere interaction with a user through
a computer network, with no transfer of a copy, is not conveying.

  An interactive user interface displays "Appropriate Legal Notices"
to the extent that it includes a convenient and prominently visible
feature that (1) displays an appropriate copyright notice, and (2)
tells the user that there is no warranty for the work (except to the
extent that warranties are provided), that licensees may convey the
work under this License, and how to view a copy of this License.  If
the interface presents a list of user commands or options, such as a
menu, a prominent item in the list meets this criterion.

  1. Source Code.

  The "source code" for a work means the preferred form of the work
for making modifications to it.  "Object code" means any non-source
form of a work.

  A "Standard Interface" means an interface that either is an official
standard defined by a recognized standards body, or, in the case of
interfaces specified for a particular programming language, one that
is widely used among developers working in that language.

  The "System Libraries" of an executable work include anything, other
than the work as a whole, that (a) is included in the normal form of
packaging a Major Component, but which is not part of that Major
Component, and (b) serves only to enable use of the work with that
Major Component, or to implement a Standard Interface for which an
implementation is available to the public in source code form.  A
"Major Component", in this context, means a major essential component
(kernel, window system, and so on) of the specific operating system
(if any) on which the executable work runs, or a compiler used to
produce the work, or an object code interpreter used to run it.

  The "Corresponding Source" for a work in object code form means all
the source code needed to generate, install, and (for an executable
work) run the object code and to modify the work, including scripts to
control those activities.  However, it does not include the work's
System Libraries, or general-purpose tools or generally available free
programs which are used unmodified in performing those activities but
which are not part of the work.  For example, Corresponding Source
includes interface definition files associated with source files for
the work, and the source code for shared libraries and dynamically
linked subprograms that the work is specifically designed to require,
such as by intimate data communication or control flow between those
subprograms and other parts of the work.

  The Corresponding Source need not include anything that users
can regenerate automatically from other parts of the Corresponding
Source.

  The Corresponding Source for a work in source code form is that
same work.

  2. Basic Permissions.

  All rights granted under this License are granted for the term of
copyright on the Program, and are irrevocable provided the stated
conditions are met.  This License explicitly affirms your unlimited
permission to run the unmodified Program.  The output from running a
covered work is covered by this License only if the output, given its
content, constitutes a covered work.  This License acknowledges your
rights of fair use or other equivalent, as provided by copyright law.

  You may make, run and propagate covered works that you do not
convey, without conditions so long as your license otherwise remains
in force.  You may convey covered works to others for the sole purpose
of having them make modifications exclusively for you, or provide you
with facilities for running those works, provided that you comply with
the terms of this License in conveying all material for which you do
not control copyright.  Those thus making or running the covered works
for you must do so exclusively on your behalf, under your direction
and control, on terms that prohibit them from making any copies of
your copyrighted material outside their relationship with you.

  Conveying under any other circumstances is permitted solely under
the conditions stated below.  Sublicensing is not allowed; section 10
makes it unnecessary.

  3. Protecting Users' Legal Rights From Anti-Circumvention Law.

  No covered work shall be deemed part of an effective technological
measure under any applicable law fulfilling obligations under article
11 of the WIPO copyright treaty adopted on 20 December 1996, or
similar laws prohibiting or restricting circumvention of such
measures.

  When you convey a covered work, you waive any legal power to forbid
circumvention of technological measures to the extent such circumvention
is effected by exercising rights under this License with respect to
the covered work, and you disclaim any intention to limit operation or
modification of the work as a means of enforcing, against the work's
users, your or third parties' legal rights to forbid circumvention of
technological measures.

  4. Conveying Verbatim Copies.

  You may convey verbatim copies of the Program's source code as you
receive it, in any medium, provided that you conspicuously and
appropriately publish on each copy an appropriate copyright notice;
keep intact all notices stating that this License and any
non-permissive terms added in accord with section 7 apply to the code;
keep intact all notices of the absence of any warranty; and give all
recipients a copy of this License along with the Program.

  You may charge any price or no price for each copy that you convey,
and you may offer support or warranty protection for a fee.

  5. Conveying Modified Source Versions.

  You may convey a work based on the Program, or the modifications to
produce it from the Program, in the form of source code under the
terms of section 4, provided that you also meet all of these conditions:

    a) The work must carry prominent notices stating that you modified
    it, and giving a relevant date.

    b) The work must carry prominent notices stating that it is
    released under this License and any conditions added under section
    7.  This requirement modifies the requirement in section 4 to
    "keep intact all notices".

    c) You must license the entire work, as a whole, under this
    License to anyone who comes into possession of a copy.  This
    License will therefore apply, along with any applicable section 7
    additional terms, to the whole of the work, and all its parts,
    regardless of how they are packaged.  This License gives no
    permission to license the work in any other way, but it does not
    invalidate such permission if you have separately received it.

    d) If the work has interactive user interfaces, each must display
    Appropriate Legal Notices; however, if the Program has interactive
    interfaces that do not display Appropriate Legal Notices, your
    work need not make them do so.

  A compilation of a covered work with other separate and independent
works, which are not by their nature extensions of the covered work,
and which are not combined with it such as to form a larger program,
in or on a volume of a storage or distribution medium, is called an
"aggregate" if the compilation and its resulting copyright are not
used to limit the access or legal rights of the compilation's users
beyond what the individual works permit.  Inclusion of a covered work
in an aggregate does not cause this License to apply to the other
parts of the aggregate.

  6. Conveying Non-Source Forms.

  You may convey a covered work in object code form under the terms
of sections 4 and 5, provided that you also convey the
machine-readable Corresponding Source under the terms of this License,
in one of these ways:

    a) Convey the object code in, or embodied in, a physical product
    (including a physical distribution medium), accompanied by the
    Corresponding Source fixed on a durable physical medium
    customarily used for software interchange.

    b) Convey the object code in, or embodied in, a physical product
    (including a physical distribution medium), accompanied by a
    written offer, valid for at least three years and valid for as
    long as you offer spare parts or customer support for that product
    model, to give anyone who possesses the object code either (1) a
    copy of the Corresponding Source for all the software in the
    product that is covered by this License, on a durable physical
    medium customarily used for software interchange, for a price no
    more than your reasonable cost of physically performing this
    conveying of source, or (2) access to copy the
    Corresponding Source from a network server at no charge.

    c) Convey individual copies of the object code with a copy of the
    written offer to provide the Corresponding Source.  This
    alternative is allowed only occasionally and noncommercially, and
    only if you received the object code with such an offer, in accord
    with subsection 6b.

    d) Convey the object code by offering access from a designated
    place (gratis or for a charge), and offer equivalent access to the
    Corresponding Source in the same way through the same place at no
    further charge.  You need not require recipients to copy the
    Corresponding Source along with the object code.  If the place to
    copy the object code is a network server, the Corresponding Source
    may be on a different server (operated by you or a third party)
    that supports equivalent copying facilities, provided you maintain
    clear directions next to the object code saying where to find the
    Corresponding Source.  Regardless of what server hosts the
    Corresponding Source, you remain obligated to ensure that it is
    available for as long as needed to satisfy these requirements.

    e) Convey the object code using peer-to-peer transmission, provided
    you inform other peers where the object code and Corresponding
    Source of the work are being offered to the general public at no
    charge under subsection 6d.

  A separable portion of the object code, whose source code is excluded
from the Corresponding Source as a System Library, need not be
included in conveying the object code work.

  A "User Product" is either (1) a "consumer product", which means any
tangible personal property which is normally used for personal, family,
or household purposes, or (2) anything designed or sold for incorporation
into a dwelling.  In determining whether a product is a consumer product,
doubtful cases shall be resolved in favor of coverage.  For a particular
product received by a particular user, "normally used" refers to a
typical or common use of that class of product, regardless of the status
of the particular user or of the way in which the particular user
actually uses, or expects or is expected to use, the product.  A product
is a consumer product regardless of whether the product has substantial
commercial, industrial or non-consumer uses, unless such uses represent
the only significant mode of use of the product.

  "Installation Information" for a User Product means any methods,
procedures, authorization keys, or other information required to install
and execute modified versions of a covered work in that User Product from
a modified version of its Corresponding Source.  The information must
suffice to ensure that the continued functioning of the modified object
code is in no case prevented or interfered with solely because
modification has been made.

  If you convey an object code work under this section in, or with, or
specifically for use in, a User Product, and the conveying occurs as
part of a transaction in which the right of possession and use of the
User Product is transferred to the recipient in perpetuity or for a
fixed term (regardless of how the transaction is characterized), the
Corresponding Source conveyed under this section must be accompanied
by the Installation Information.  But this requirement does not apply
if neither you nor any third party retains the ability to install
modified object code on the User Product (for example, the work has
been installed in ROM).

  The requirement to provide Installation Information does not include a
requirement to continue to provide support service, warranty, or updates
for a work that has been modified or installed by the recipient, or for
the User Product in which it has been modified or installed.  Access to a
network may be denied when the modification itself materially and
adversely affects the operation of the network or violates the rules and
protocols for communication across the network.

  Corresponding Source conveyed, and Installation Information provided,
in accord with this section must be in a format that is publicly
documented (and with an implementation available to the public in
source code form), and must require no special password or key for
unpacking, reading or copying.

  7. Additional Terms.

  "Additional permissions" are terms that supplement the terms of this
License by making exceptions from one or more of its conditions.
Additional permissions that are applicable to the entire Program shall
be treated as though they were included in this License, to the extent
that they are valid under applicable law.  If additional permissions
apply only to part of the Program, that part may be used separately
under those permissions, but the entire Program remains governed by
this License without regard to the additional permissions.

  When you convey a copy of a covered work, you may at your option
remove any additional permissions from that copy, or from any part of
it.  (Additional permissions may be written to require their own
removal in certain cases when you modify the work.)  You may place
additional permissions on material, added by you to a covered work,
for which you have or can give appropriate copyright permission.

  Notwithstanding any other provision of this License, for material you
add to a covered work, you may (if authorized by the copyright holders of
that material) supplement the terms of this License with terms:

    a) Disclaiming warranty or limiting liability differently from the
    terms of sections 15 and 16 of this License; or

    b) Requiring preservation of specified reasonable legal notices or
    author attributions in that material or in the Appropriate Legal
    Notices displayed by works containing it; or

    c) Prohibiting misrepresentation of the origin of that material, or
    requiring that modified versions of such material be marked in
    reasonable ways as different from the original version; or

    d) Limiting the use for publicity purposes of names of licensors or
    authors of the material; or

    e) Declining to grant rights under trademark law for use of some
    trade names, trademarks, or service marks; or

    f) Requiring indemnification of licensors and authors of that
    material by anyone who conveys the material (or modified versions of
    it) with contractual assumptions of liability to the recipient, for
    any liability that these contractual assumptions directly impose on
    those licensors and authors.

  All other non-permissive additional terms are considered "further
restrictions" within the meaning of section 10.  If the Program as you
received it, or any part of it, contains a notice stating that it is
governed by this License along with a term that is a further
restriction, you may remove that term.  If a license document contains
a further restriction but permits relicensing or conveying under this
License, you may add to a covered work material governed by the terms
of that license document, provided that the further restriction does
not survive such relicensing or conveying.

  If you add terms to a covered work in accord with this section, you
must place, in the relevant source files, a statement of the
additional terms that apply to those files, or a notice indicating
where to find the applicable terms.

  Additional terms, permissive or non-permissive, may be stated in the
form of a separately written license, or stated as exceptions;
the above requirements apply either way.

  8. Termination.

  You may not propagate or modify a covered work except as expressly
provided under this License.  Any attempt otherwise to propagate or
modify it is void, and will automatically terminate your rights under
this License (including any patent licenses granted under the third
paragraph of section 11).

  However, if you cease all violation of this License, then your
license from a particular copyright holder is reinstated (a)
provisionally, unless and until the copyright holder explicitly and
finally terminates your license, and (b) permanently, if the copyright
holder fails to notify you of the violation by some reasonable means
prior to 60 days after the cessation.

  Moreover, your license from a particular copyright holder is
reinstated permanently if the copyright holder notifies you of the
violation by some reasonable means, this is the first time you have
received notice of violation of this License (for any work) from that
copyright holder, and you cure the violation prior to 30 days after
your receipt of the notice.

  Termination of your rights under this section does not terminate the
licenses of parties who have received copies or rights from you under
this License.  If your rights have been terminated and not permanently
reinstated, you do not qualify to receive new licenses for the same
material under section 10.

  9. Acceptance Not Required for Having Copies.

  You are not required to accept this License in order to receive or
run a copy of the Program.  Ancillary propagation of a covered work
occurring solely as a consequence of using peer-to-peer transmission
to receive a copy likewise does not require acceptance.  However,
nothing other than this License grants you permission to propagate or
modify any covered work.  These actions infringe copyright if you do
not accept this License.  Therefore, by modifying or propagating a
covered work, you indicate your acceptance of this License to do so.

  10. Automatic Licensing of Downstream Recipients.

  Each time you convey a covered work, the recipient automatically
receives a license from the original licensors, to run, modify and
propagate that work, subject to this License.  You are not responsible
for enforcing compliance by third parties with this License.

  An "entity transaction" is a transaction transferring control of an
organization, or substantially all assets of one, or subdividing an
organization, or merging organizations.  If propagation of a covered
work results from an entity transaction, each party to that
transaction who receives a copy of the work also receives whatever
licenses to the work the party's predecessor in interest had or could
give under the previous paragraph, plus a right to possession of the
Corresponding Source of the work from the predecessor in interest, if
the predecessor has it or can get it with reasonable efforts.

  You may not impose any further restrictions on the exercise of the
rights granted or affirmed under this License.  For example, you may
not impose a license fee, royalty, or other charge for exercise of
rights granted under this License, and you may not initiate litigation
(including a cross-claim or counterclaim in a lawsuit) alleging that
any patent claim is infringed by making, using, selling, offering for
sale, or importing the Program or any portion of it.

  11. Patents.

  A "contributor" is a copyright holder who authorizes use under this
License of the Program or a work on which the Program is based.  The
work thus licensed is called the contributor's "contributor version".

  A contributor's "essential patent claims" are all patent claims
owned or controlled by the contributor, whether already acquired or
hereafter acquired, that would be infringed by some manner, permitted
by this License, of making, using, or selling its contributor version,
but do not include claims that would be infringed only as a
consequence of further modification of the contributor version.  For
purposes of this definition, "control" includes the right to grant
patent sublicenses in a manner consistent with the requirements of
this License.

  Each contributor grants you a non-exclusive, worldwide, royalty-free
patent license under the contributor's essential patent claims, to
make, use, sell, offer for sale, import and otherwise run, modify and
propagate the contents of its contributor version.

  In the following three paragraphs, a "patent license" is any express
agreement or commitment, however denominated, not to enforce a patent
(such as an express permission to practice a patent or covenant not to
sue for patent infringement).  To "grant" such a patent license to a
party means to make such an agreement or commitment not to enforce a
patent against the party.

  If you convey a covered work, knowingly relying on a patent license,
and the Corresponding Source of the work is not available for anyone
to copy, free of charge and under the terms of this License, through a
publicly available network server or other readily accessible means,
then you must either (1) cause the Corresponding Source to be so
available, or (2) arrange to deprive yourself of the benefit of the
patent license for this particular work, or (3) arrange, in a manner
consistent with the requirements of this License, to extend the patent
license to downstream recipients.  "Knowingly relying" means you have
actual knowledge that, but for the patent license, your conveying the
covered work in a country, or your recipient's use of the covered work
in a country, would infringe one or more identifiable patents in that
country that you have reason to believe are valid.

  If, pursuant to or in connection with a single transaction or
arrangement, you convey, or propagate by procuring conveyance of, a
covered work, and grant a patent license to some of the parties
receiving the covered work authorizing them to use, propagate, modify
or convey a specific copy of the covered work, then the patent license
you grant is automatically extended to all recipients of the covered
work and works based on it.

  A patent license is "discriminatory" if it does not include within
the scope of its coverage, prohibits the exercise of, or is
conditioned on the non-exercise of one or more of the rights that are
specifically granted under this License.  You may not convey a covered
work if you are a party to an arrangement with a third party that is
in the business of distributing software, under which you make payment
to the third party based on the extent of your activity of conveying
the work, and under which the third party grants, to any of the
parties who would receive the covered work from you, a discriminatory
patent license (a) in connection with copies of the covered work
conveyed by you (or copies made from those copies), or (b) primarily
for and in connection with specific products or compilations that
contain the covered work, unless you entered into that arrangement,
or that patent license was granted, prior to 28 March 2007.

  Nothing in this License shall be construed as excluding or limiting
any implied license or other defenses to infringement that may
otherwise be available to you under applicable patent law.

  12. No Surrender of Others' Freedom.

  If conditions are imposed on you (whether by court order, agreement or
otherwise) that contradict the conditions of this License, they do not
excuse you from the conditions of this License.  If you cannot convey a
covered work so as to satisfy simultaneously your obligations under this
License and any other pertinent obligations, then as a consequence you may
not convey it at all.  For example, if you agree to terms that obligate you
to collect a royalty for further conveying from those to whom you convey
the Program, the only way you could satisfy both those terms and this
License would be to refrain entirely from conveying the Program.

  13. Remote Network Interaction; Use with the GNU General Public License.

  Notwithstanding any other provision of this License, if you modify the
Program, your modified version must prominently offer all users
interacting with it remotely through a computer network (if your version
supports such interaction) an opportunity to receive the Corresponding
Source of your version by providing access to the Corresponding Source
from a network server at no charge, through some standard or customary
means of facilitating copying of software.  This Corresponding Source
shall include the Corresponding Source for any work covered by version 3
of the GNU General Public License that is incorporated pursuant to the
following paragraph.

  Notwithstanding any other provision of this License, you have
permission to link or combine any covered work with a work licensed
under version 3 of the GNU General Public License into a single
combined work, and to convey the resulting work.  The terms of this
License will continue to apply to the part which is the covered work,
but the work with which it is combined will remain governed by version
3 of the GNU General Public License.

  14. Revised Versions of this License.

  The Free Software Foundation may publish revised and/or new versions of
the GNU Affero General Public License from time to time.  Such new versions
will be similar in spirit to the present version, but may differ in detail to
address new problems or concerns.

  Each version is given a distinguishing version number.  If the
Program specifies that a certain numbered version of the GNU Affero General
Public License "or any later version" applies to it, you have the
option of following the terms and conditions either of that numbered
version or of any later version published by the Free Software
Foundation.  If the Program does not specify a version number of the
GNU Affero General Public License, you may choose any version ever published
by the Free Software Foundation.

  If the Program specifies that a proxy can decide which future
versions of the GNU Affero General Public License can be used, that proxy's
public statement of acceptance of a version permanently authorizes you
to choose that version for the Program.

  Later license versions may give you additional or different
permissions.  However, no additional obligations are imposed on any
author or copyright holder as a result of your choosing to follow a
later version.

  15. Disclaimer of Warranty.

  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY
APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT
HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY
OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,
THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM
IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF
ALL NECESSARY SERVICING, REPAIR OR CORRECTION.

  16. Limitation of Liability.

  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS
THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY
GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE
USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF
DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD
PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),
EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF
SUCH DAMAGES.

  17. Interpretation of Sections 15 and 16.

  If the disclaimer of warranty and limitation of liability provided
above cannot be given local legal effect according to their terms,
reviewing courts shall apply local law that most closely approximates
an absolute waiver of all civil liability in connection with the
Program, unless a warranty or assumption of liability accompanies a
copy of the Program in return for a fee.

                     END OF TERMS AND CONDITIONS

            How to Apply These Terms to Your New Programs

  If you develop a new program, and you want it to be of the greatest
possible use to the public, the best way to achieve this is to make it
free software which everyone can redistribute and change under these terms.

  To do so, attach the following notices to the program.  It is safest
to attach them to the start of each source file to most effectively
state the exclusion of warranty; and each file should have at least
the "copyright" line and a pointer to where the full notice is found.

    <one line to give the program's name and a brief idea of what it does.>
    Copyright (C) <year>  <name of author>

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU Affero General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU Affero General Public License for more details.

    You should have received a copy of the GNU Affero General Public License
    along with this program.  If not, see <https://www.gnu.org/licenses/>.

Also add information on how to contact you by electronic and paper mail.

  If your software can interact with users remotely through a computer
network, you should also make sure that it provides a way for users to
get its source.  For example, if your program is a web application, its
interface could display a "Source" link that leads users to an archive
of the code.  There are many ways you could offer source, and different
solutions will be better for different programs; see section 13 for the
specific requirements.

  You should also get your employer (if you work as a programmer) or school,
if any, to sign a "copyright disclaimer" for the program, if necessary.
For more information on this, and how to apply and follow the GNU AGPL, see
<https://www.gnu.org/licenses/>.



================================================
FILE: main.py
================================================
# -*- coding: utf-8 -*-

# Kiro OpenAI Gateway
# Copyright (C) 2025 Jwadow
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

"""
Kiro API Gateway - OpenAI-compatible interface for Kiro API.

Application entry point. Creates FastAPI app and connects routes.

Usage:
    uvicorn main:app --host 0.0.0.0 --port 8000
    or directly:
    python main.py
"""

import logging
import sys
from contextlib import asynccontextmanager
from pathlib import Path

from fastapi import FastAPI
from fastapi.exceptions import RequestValidationError
from fastapi.middleware.cors import CORSMiddleware
from loguru import logger

from kiro_gateway.config import (
    APP_TITLE,
    APP_DESCRIPTION,
    APP_VERSION,
    REFRESH_TOKEN,
    PROFILE_ARN,
    REGION,
    KIRO_CREDS_FILE,
    PROXY_API_KEY,
    LOG_LEVEL,
    _warn_deprecated_debug_setting,
    _warn_timeout_configuration,
)
from kiro_gateway.auth import KiroAuthManager
from kiro_gateway.cache import ModelInfoCache
from kiro_gateway.routes import router
from kiro_gateway.exceptions import validation_exception_handler


# --- Loguru Configuration ---
logger.remove()
logger.add(
    sys.stderr,
    level=LOG_LEVEL,
    colorize=True,
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>"
)


class InterceptHandler(logging.Handler):
    """
    Intercepts logs from standard logging and redirects them to loguru.
    
    This allows capturing logs from uvicorn, FastAPI and other libraries
    that use standard logging instead of loguru.
    """
    
    def emit(self, record: logging.LogRecord) -> None:
        # Get the corresponding loguru level
        try:
            level = logger.level(record.levelname).name
        except ValueError:
            level = record.levelno
        
        # Find the caller frame for correct source display
        frame, depth = logging.currentframe(), 2
        while frame.f_code.co_filename == logging.__file__:
            frame = frame.f_back
            depth += 1
        
        logger.opt(depth=depth, exception=record.exc_info).log(level, record.getMessage())


def setup_logging_intercept():
    """
    Configures log interception from standard logging to loguru.
    
    Intercepts logs from:
    - uvicorn (access logs, error logs)
    - uvicorn.error
    - uvicorn.access
    - fastapi
    """
    # List of loggers to intercept
    loggers_to_intercept = [
        "uvicorn",
        "uvicorn.error",
        "uvicorn.access",
        "fastapi",
    ]
    
    for logger_name in loggers_to_intercept:
        logging_logger = logging.getLogger(logger_name)
        logging_logger.handlers = [InterceptHandler()]
        logging_logger.propagate = False


# Configure uvicorn/fastapi log interception
setup_logging_intercept()


# --- Configuration Validation ---
def validate_configuration() -> None:
    """
    Validates that required configuration is present.
    
    Checks:
    - .env file exists
    - Either REFRESH_TOKEN or KIRO_CREDS_FILE is configured
    
    Raises:
        SystemExit: If critical configuration is missing
    """
    errors = []
    
    # Check if .env file exists
    env_file = Path(".env")
    env_example = Path(".env.example")
    
    if not env_file.exists():
        errors.append(
            ".env file not found!\n"
            "\n"
            "To get started:\n"
            "1. Create .env or rename from .env.example:\n"
            "   cp .env.example .env\n"
            "\n"
            "2. Edit .env and configure your credentials:\n"
            "   2.1. Set you super-secret password as PROXY_API_KEY\n"
            "   2.2. Set your Kiro credentials:\n"
            "      - 1 way: KIRO_CREDS_FILE to your Kiro credentials JSON file\n"
            "      - 2 way: REFRESH_TOKEN from Kiro IDE traffic\n"
            "\n"
            "See README.md for detailed instructions."
        )
    else:
        # .env exists, check for credentials
        has_refresh_token = bool(REFRESH_TOKEN)
        has_creds_file = bool(KIRO_CREDS_FILE)
        
        # Check if creds file actually exists
        if KIRO_CREDS_FILE:
            creds_path = Path(KIRO_CREDS_FILE).expanduser()
            if not creds_path.exists():
                has_creds_file = False
                logger.warning(f"KIRO_CREDS_FILE not found: {KIRO_CREDS_FILE}")
        
        if not has_refresh_token and not has_creds_file:
            errors.append(
                "No Kiro credentials configured!\n"
                "\n"
                "   Configure one of the following in your .env file:\n"
                "\n"
                "Set you super-secret password as PROXY_API_KEY\n"
                "   PROXY_API_KEY=\"my-super-secret-password-123\"\n"
                "\n"
                "   Option 1 (Recommended): JSON credentials file\n"
                "      KIRO_CREDS_FILE=\"path/to/your/kiro-credentials.json\"\n"
                "\n"
                "   Option 2: Refresh token\n"
                "      REFRESH_TOKEN=\"your_refresh_token_here\"\n"
                "\n"
                "   See README.md for how to obtain credentials."
            )
    
    # Print errors and exit if any
    if errors:
        logger.error("")
        logger.error("=" * 60)
        logger.error("  CONFIGURATION ERROR")
        logger.error("=" * 60)
        for error in errors:
            for line in error.split('\n'):
                logger.error(f"  {line}")
        logger.error("=" * 60)
        logger.error("")
        sys.exit(1)
    
    # Log successful configuration
    if KIRO_CREDS_FILE:
        logger.info(f"Using credentials file: {KIRO_CREDS_FILE}")
    elif REFRESH_TOKEN:
        logger.info("Using refresh token from environment")


# Run configuration validation on import
validate_configuration()

# Warn about deprecated DEBUG_LAST_REQUEST if used
_warn_deprecated_debug_setting()

# Warn about suboptimal timeout configuration
_warn_timeout_configuration()


# --- Lifespan Manager ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    Manages the application lifecycle.
    
    Creates and initializes:
    - KiroAuthManager for token management
    - ModelInfoCache for model caching
    """
    logger.info("Starting application... Creating state managers.")
    
    # Create AuthManager
    app.state.auth_manager = KiroAuthManager(
        refresh_token=REFRESH_TOKEN,
        profile_arn=PROFILE_ARN,
        region=REGION,
        creds_file=KIRO_CREDS_FILE if KIRO_CREDS_FILE else None
    )
    
    # Create model cache
    app.state.model_cache = ModelInfoCache()
    
    yield
    
    logger.info("Shutting down application.")


# --- FastAPI Application ---
app = FastAPI(
    title=APP_TITLE,
    description=APP_DESCRIPTION,
    version=APP_VERSION,
    lifespan=lifespan
)


# --- CORS Middleware ---
# Allow CORS for all origins to support browser clients
# and tools that send preflight OPTIONS requests
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Allow all origins
    allow_credentials=True,
    allow_methods=["*"],  # Allow all methods (GET, POST, OPTIONS, etc.)
    allow_headers=["*"],  # Allow all headers
)


# --- Validation Error Handler Registration ---
app.add_exception_handler(RequestValidationError, validation_exception_handler)


# --- Route Registration ---
app.include_router(router)


# --- Uvicorn log config ---
# Minimal configuration for redirecting uvicorn logs to loguru.
# Uses InterceptHandler which intercepts logs and passes them to loguru.
UVICORN_LOG_CONFIG = {
    "version": 1,
    "disable_existing_loggers": False,
    "handlers": {
        "default": {
            "class": "main.InterceptHandler",
        },
    },
    "loggers": {
        "uvicorn": {"handlers": ["default"], "level": "INFO", "propagate": False},
        "uvicorn.error": {"handlers": ["default"], "level": "INFO", "propagate": False},
        "uvicorn.access": {"handlers": ["default"], "level": "INFO", "propagate": False},
    },
}


# --- Entry Point ---
if __name__ == "__main__":
    import uvicorn
    logger.info("Starting Uvicorn server...")
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_config=UVICORN_LOG_CONFIG,
    )



================================================
FILE: manual_api_test.py
================================================
# -*- coding: utf-8 -*-

# Kiro OpenAI Gateway
# https://github.com/jwadow/kiro-openai-gateway
# Copyright (C) 2025 Jwadow
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

import json
import os
import sys
import uuid
from pathlib import Path

import requests
from dotenv import load_dotenv
from loguru import logger

# --- Load environment variables ---
load_dotenv()

# --- Configuration ---
KIRO_API_HOST = "https://q.us-east-1.amazonaws.com"
TOKEN_URL = "https://prod.us-east-1.auth.desktop.kiro.dev/refreshToken"
REFRESH_TOKEN = os.getenv("REFRESH_TOKEN")
PROFILE_ARN = os.getenv("PROFILE_ARN", "arn:aws:codewhisperer:us-east-1:699475941385:profile/EHGA3GRVQMUK")
KIRO_CREDS_FILE = os.getenv("KIRO_CREDS_FILE", "")

# --- Load credentials from file if REFRESH_TOKEN not in env ---
if not REFRESH_TOKEN and KIRO_CREDS_FILE:
    try:
        creds_path = Path(KIRO_CREDS_FILE).expanduser()
        if creds_path.exists():
            with open(creds_path, 'r', encoding='utf-8') as f:
                creds_data = json.load(f)
            REFRESH_TOKEN = creds_data.get("refreshToken", "")
            if creds_data.get("profileArn"):
                PROFILE_ARN = creds_data["profileArn"]
            logger.info(f"Credentials loaded from {KIRO_CREDS_FILE}")
        else:
            logger.warning(f"Credentials file not found: {KIRO_CREDS_FILE}")
    except Exception as e:
        logger.error(f"Error loading credentials from file: {e}")

# --- Validate required credentials ---
if not REFRESH_TOKEN:
    logger.error("Neither REFRESH_TOKEN env variable nor KIRO_CREDS_FILE is configured. Exiting.")
    sys.exit(1)

# Global variables
AUTH_TOKEN = None
HEADERS = {
    "Authorization": None,
    "Content-Type": "application/json",
    "User-Agent": "aws-sdk-js/1.0.27 ua/2.1 os/win32#10.0.19044 lang/js md/nodejs#22.21.1 api/codewhispererstreaming#1.0.27 m/E KiroIDE-0.7.45-31c325a0ff0a9c8dec5d13048f4257462d751fe5b8af4cb1088f1fca45856c64",
    "x-amz-user-agent": "aws-sdk-js/1.0.27 KiroIDE-0.7.45-31c325a0ff0a9c8dec5d13048f4257462d751fe5b8af4cb1088f1fca45856c64",
    "x-amzn-codewhisperer-optout": "true",
    "x-amzn-kiro-agent-mode": "vibe",
}


def refresh_auth_token():
    """Refreshes AUTH_TOKEN via Kiro API."""
    global AUTH_TOKEN, HEADERS
    logger.info("Refreshing Kiro token...")
    
    payload = {"refreshToken": REFRESH_TOKEN}
    headers = {
        "Content-Type": "application/json",
        "User-Agent": "KiroIDE-0.7.45-31c325a0ff0a9c8dec5d13048f4257462d751fe5b8af4cb1088f1fca45856c64",
    }
    
    try:
        response = requests.post(TOKEN_URL, json=payload, headers=headers)
        response.raise_for_status()
        data = response.json()
        
        new_token = data.get("accessToken")
        expires_in = data.get("expiresIn")
        
        if not new_token:
            logger.error("Failed to get accessToken from response")
            return False

        logger.success(f"Token successfully refreshed. Expires in: {expires_in}s")
        AUTH_TOKEN = new_token
        HEADERS['Authorization'] = f"Bearer {AUTH_TOKEN}"
        return True
        
    except requests.exceptions.RequestException as e:
        logger.error(f"Error refreshing token: {e}")
        if hasattr(e, 'response') and e.response:
            logger.error(f"Server response: {e.response.status_code} {e.response.text}")
        return False


def test_get_models():
    """Tests the ListAvailableModels endpoint."""
    logger.info("Testing /ListAvailableModels...")
    url = f"{KIRO_API_HOST}/ListAvailableModels"
    params = {
        "origin": "AI_EDITOR",
        "profileArn": PROFILE_ARN
    }

    try:
        response = requests.get(url, headers=HEADERS, params=params)
        response.raise_for_status()

        logger.info(f"Response status: {response.status_code}")
        logger.debug(f"Response (JSON):\n{json.dumps(response.json(), indent=2, ensure_ascii=False)}")
        logger.success("ListAvailableModels test COMPLETED SUCCESSFULLY")
        return True
    except requests.exceptions.RequestException as e:
        logger.error(f"ListAvailableModels test failed: {e}")
        return False


def test_generate_content():
    """Tests the generateAssistantResponse endpoint."""
    logger.info("Testing /generateAssistantResponse...")
    url = f"{KIRO_API_HOST}/generateAssistantResponse"
    
    payload = {
        "conversationState": {
            "agentContinuationId": str(uuid.uuid4()),
            "agentTaskType": "vibe",
            "chatTriggerType": "MANUAL",
            "conversationId": str(uuid.uuid4()),
            "currentMessage": {
                "userInputMessage": {
                    "content": "Hello! Say something short.",
                    "modelId": "claude-haiku-4.5",
                    "origin": "AI_EDITOR",
                    "userInputMessageContext": {
                        "tools": []
                    }
                }
            },
            "history": []
        },
        "profileArn": PROFILE_ARN
    }

    try:
        with requests.post(url, headers=HEADERS, json=payload, stream=True) as response:
            response.raise_for_status()
            logger.info(f"Response status: {response.status_code}")
            logger.info("Streaming response:")

            for chunk in response.iter_content(chunk_size=1024):
                if chunk:
                    # Try to decode and find JSON
                    chunk_str = chunk.decode('utf-8', errors='ignore')
                    logger.debug(f"Chunk: {chunk_str[:200]}...")

        logger.success("generateAssistantResponse test COMPLETED")
        return True
    except requests.exceptions.RequestException as e:
        logger.error(f"generateAssistantResponse test failed: {e}")
        return False


if __name__ == "__main__":
    # Determine credential source for logging
    cred_source = "KIRO_CREDS_FILE" if KIRO_CREDS_FILE else "REFRESH_TOKEN"
    logger.info(f"Starting Kiro API tests (credentials from {cred_source})...")

    token_ok = refresh_auth_token()

    if token_ok:
        models_ok = test_get_models()
        generate_ok = test_generate_content()

        if models_ok and generate_ok:
            logger.success(f"All tests passed successfully! (credentials from {cred_source})")
        else:
            logger.warning(f"One or more tests failed. (credentials from {cred_source})")
    else:
        logger.error("Failed to refresh token. Tests not started.")



================================================
FILE: pytest.ini
================================================
[pytest]
# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è pytest –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ PYTHONPATH
pythonpath = .

# –ò—Å–∫–ª—é—á–∞–µ–º manual_api_test.py –∏–∑ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
# (—ç—Ç–æ —Å–∫—Ä–∏–ø—Ç –¥–ª—è —Ä—É—á–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ API, –Ω–µ unit-—Ç–µ—Å—Ç)
# –ß—Ç–æ–±—ã –∑–∞–ø—É—Å—Ç–∏—Ç—å –µ–≥–æ: python manual_api_test.py
norecursedirs = .git __pycache__ old requests _notes


================================================
FILE: requirements.txt
================================================
# Prod dependencies
fastapi
uvicorn[standard]
httpx
loguru
requests
python-dotenv
tiktoken

# Testing dependencies
pytest
pytest-asyncio
hypothesis


================================================
FILE: .clabot
================================================
{
  "contributors": ["Kartvya69", "Doggyman67"],
  "label": "cla-signed",
  "message": "Thanks for the PR! üéâ\n\nBefore merge, we need a one-time CLA confirmation.\nIt confirms that you have the right to contribute this code and allow the project to use it.\n\nFull CLA text:\nhttps://github.com/jwadow/kiro-openai-gateway/blob/main/CLA.md\n\nPlease reply with:\n```\nI have read the CLA and I accept its terms\n```"
}


================================================
FILE: .env.example
================================================
# Kiro OpenAI Gateway - Environment Configuration
# Copy this file to .env and fill in your values

# ===========================================
# REQUIRED
# ===========================================

# Password to protect YOUR proxy server
# This is NOT a token from anywhere - YOU make it up!
# Use this same value as api_key when connecting to your gateway
# Example: "my-super-secret-password-123" or any secure string
PROXY_API_KEY="my-super-secret-password-123"

# ===========================================
# FIRST WAY: JSON credentials file
# ===========================================

# Path to JSON credentials file (alternative to REFRESH_TOKEN)
KIRO_CREDS_FILE="~/.aws/sso/cache/kiro-auth-token.json"

# ===========================================
# SECOND WAY: Kiro refresh token
# ===========================================

# Your Kiro refresh token obtained from Kiro IDE traffic.
# (Alternative to KIRO_CREDS_FILE)
# REFRESH_TOKEN="your_kiro_refresh_token_here"

# ===========================================
# OPTIONAL
# ===========================================

# AWS CodeWhisperer profile ARN (usually auto-detected)
# PROFILE_ARN="arn:aws:codewhisperer:us-east-1:..."

# AWS region (default: us-east-1)
# KIRO_REGION="us-east-1"

# ===========================================
# LOGGING
# ===========================================

# Log level: TRACE, DEBUG, INFO, WARNING, ERROR, CRITICAL
# Default: INFO (recommended for production)
# Set to DEBUG for detailed troubleshooting
# LOG_LEVEL="INFO"

# ===========================================
# FIRST TOKEN TIMEOUT (Streaming Retry)
# ===========================================

# Timeout for waiting for the first token from the model (in seconds).
# If the model doesn't respond within this time, the request will be cancelled and retried.
# This helps handle "stuck" requests when the model takes too long to start responding.
# Default: 15 seconds (recommended for production)
# Set a lower value (e.g., 5-10) for more aggressive retry behavior.
# FIRST_TOKEN_TIMEOUT="15"

# Maximum number of retry attempts when first token timeout occurs.
# After exhausting all attempts, a 504 Gateway Timeout error will be returned.
# Default: 3 attempts
# FIRST_TOKEN_MAX_RETRIES="3"

# Read timeout for streaming responses (in seconds).
# This is the maximum time to wait for data between chunks during streaming.
# Should be longer than FIRST_TOKEN_TIMEOUT since the model may pause between chunks
# while "thinking" (especially for tool calls or complex reasoning).
# Default: 300 seconds (5 minutes) - generous timeout to avoid premature disconnects.
# STREAMING_READ_TIMEOUT="300"

# ===========================================
# DEBUG (for development only)
# ===========================================

# Debug logging mode:
# - off: disabled (default)
# - errors: save logs only for failed requests (4xx, 5xx) - recommended for troubleshooting
# - all: save logs for every request (overwrites on each request)
# DEBUG_MODE=off

# Directory for debug log files
# DEBUG_DIR="debug_logs"

# Legacy option (WILL BE REMOVED in future releases, use DEBUG_MODE instead)
# DEBUG_LAST_REQUEST=true is equivalent to DEBUG_MODE=all
# DEBUG_LAST_REQUEST=true



================================================
FILE: docs/en/ARCHITECTURE.md
================================================
# Architectural Overview: Kiro OpenAI Gateway

## 1. System Purpose and Goals

The project is a high-level proxy gateway implementing the **"Adapter"** structural design pattern.

The main goal of the system is to provide transparent compatibility between two heterogeneous interfaces:
1.  **Target Interface (Client):** Standard OpenAI API protocol (endpoints `/v1/models`, `/v1/chat/completions`).
2.  **Adaptee (Provider):** Internal Kiro IDE API (AWS CodeWhisperer), discovered in the Amazon Kiro ecosystem.

The system acts as a "translator", allowing the use of any tools, libraries, and IDE plugins developed for the OpenAI ecosystem with Claude models through the Kiro API.

## 2. Project Structure

The project is organized as a modular Python package `kiro_gateway/`:

```
kiro-openai-gateway/
‚îú‚îÄ‚îÄ main.py                    # Entry point, FastAPI application creation
‚îú‚îÄ‚îÄ requirements.txt           # Python dependencies
‚îú‚îÄ‚îÄ .env.example               # Environment configuration example
‚îÇ
‚îú‚îÄ‚îÄ kiro_gateway/              # Main package
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py            # Package exports, version
‚îÇ   ‚îú‚îÄ‚îÄ config.py              # Configuration and constants
‚îÇ   ‚îú‚îÄ‚îÄ models.py              # Pydantic models for OpenAI API
‚îÇ   ‚îú‚îÄ‚îÄ auth.py                # KiroAuthManager - token management
‚îÇ   ‚îú‚îÄ‚îÄ cache.py               # ModelInfoCache - model cache
‚îÇ   ‚îú‚îÄ‚îÄ utils.py               # Helper utilities
‚îÇ   ‚îú‚îÄ‚îÄ converters.py          # OpenAI <-> Kiro conversion
‚îÇ   ‚îú‚îÄ‚îÄ parsers.py             # AWS SSE stream parsers
‚îÇ   ‚îú‚îÄ‚îÄ streaming.py           # Response streaming logic
‚îÇ   ‚îú‚îÄ‚îÄ http_client.py         # HTTP client with retry logic
‚îÇ   ‚îú‚îÄ‚îÄ routes.py              # FastAPI routes
‚îÇ   ‚îú‚îÄ‚îÄ debug_logger.py        # Debug request logging
‚îÇ   ‚îú‚îÄ‚îÄ tokenizer.py           # Token counting (tiktoken)
‚îÇ   ‚îî‚îÄ‚îÄ exceptions.py          # Exception handlers
‚îÇ
‚îú‚îÄ‚îÄ tests/                     # Tests
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py            # Pytest fixtures
‚îÇ   ‚îú‚îÄ‚îÄ unit/                  # Unit tests
‚îÇ   ‚îî‚îÄ‚îÄ integration/           # Integration tests
‚îÇ
‚îú‚îÄ‚îÄ docs/                      # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ ru/                    # Russian version
‚îÇ   ‚îî‚îÄ‚îÄ en/                    # English version
‚îÇ
‚îî‚îÄ‚îÄ debug_logs/                # Debug logs (generated when DEBUG_LAST_REQUEST=true)
```

## 3. Architectural Topology and Components

The system is built on the asynchronous `FastAPI` framework and uses an event-driven lifecycle management model (`Lifespan Events`).

### 3.1. Entry Point (`main.py`)

The `main.py` file is responsible for:

1. **Logging configuration** ‚Äî Loguru setup with colored output
2. **Configuration validation** ‚Äî `validate_configuration()` function checks:
   - Presence of `.env` file
   - Presence of credentials (REFRESH_TOKEN or KIRO_CREDS_FILE)
3. **Lifespan Manager** ‚Äî creation and initialization of:
   - `KiroAuthManager` for token management
   - `ModelInfoCache` for model caching
4. **Error handler registration** ‚Äî `validation_exception_handler` for 422 errors
5. **Route connection** ‚Äî `app.include_router(router)`

### 3.2. Configuration Module (`kiro_gateway/config.py`)

Centralized storage of all settings:

| Parameter | Description | Default Value |
|-----------|-------------|---------------|
| `PROXY_API_KEY` | API key for proxy access | `changeme_proxy_secret` |
| `REFRESH_TOKEN` | Kiro refresh token | from `.env` |
| `PROFILE_ARN` | AWS CodeWhisperer profile ARN | from `.env` |
| `REGION` | AWS region | `us-east-1` |
| `KIRO_CREDS_FILE` | Path to JSON credentials file | from `.env` |
| `TOKEN_REFRESH_THRESHOLD` | Time before token refresh | 600 sec (10 min) |
| `MAX_RETRIES` | Max retry attempts | 3 |
| `BASE_RETRY_DELAY` | Base retry delay | 1.0 sec |
| `MODEL_CACHE_TTL` | Model cache TTL | 3600 sec (1 hour) |
| `DEFAULT_MAX_INPUT_TOKENS` | Default max input tokens | 200000 |
| `TOOL_DESCRIPTION_MAX_LENGTH` | Max tool description length | 10000 characters |
| `DEBUG_LAST_REQUEST` | Enable debug logging | `false` |
| `DEBUG_DIR` | Debug logs directory | `debug_logs` |
| `APP_VERSION` | Application version | `0.0.0` |

**Helper functions:**
- `get_kiro_refresh_url(region)` ‚Äî URL for token refresh
- `get_kiro_api_host(region)` ‚Äî main API host
- `get_kiro_q_host(region)` ‚Äî Q API host
- `get_internal_model_id(external_model)` ‚Äî model name conversion

### 3.3. Pydantic Models (`kiro_gateway/models.py`)

#### Models for `/v1/models`

| Model | Description |
|-------|-------------|
| `OpenAIModel` | AI model description (id, object, created, owned_by) |
| `ModelList` | Model list for endpoint response |

#### Models for `/v1/chat/completions`

| Model | Description |
|-------|-------------|
| `ChatMessage` | Chat message (role, content, tool_calls, tool_call_id) |
| `ToolFunction` | Tool function description (name, description, parameters) |
| `Tool` | OpenAI format tool (type, function) |
| `ChatCompletionRequest` | Generation request (model, messages, stream, tools, ...) |

#### Response Models

| Model | Description |
|-------|-------------|
| `ChatCompletionChoice` | Single response variant |
| `ChatCompletionUsage` | Token information (prompt_tokens, completion_tokens, credits_used) |
| `ChatCompletionResponse` | Full response (non-streaming) |
| `ChatCompletionChunk` | Streaming chunk |
| `ChatCompletionChunkDelta` | Delta changes in chunk |
| `ChatCompletionChunkChoice` | Variant in streaming chunk |

### 3.4. State Management Layer

#### KiroAuthManager (`kiro_gateway/auth.py`)

**Role:** Stateful singleton encapsulating Kiro token management logic.

**Capabilities:**
- Loading credentials from `.env` or JSON file
- Support for `expiresAt` to check token expiration time
- Automatic token refresh 10 minutes before expiration
- Saving updated tokens back to JSON file
- Support for different AWS regions
- Unique fingerprint generation for User-Agent

**Concurrency Control:** Uses `asyncio.Lock` to protect against race conditions.

**Main methods:**
- `get_access_token()` ‚Äî returns valid token, refreshing if necessary
- `force_refresh()` ‚Äî forced token refresh (on 403)
- `is_token_expiring_soon()` ‚Äî expiration time check

**Properties:**
- `profile_arn` ‚Äî profile ARN
- `region` ‚Äî AWS region
- `api_host` ‚Äî API host for region
- `q_host` ‚Äî Q API host for region
- `fingerprint` ‚Äî unique machine fingerprint

```python
# Usage example
auth_manager = KiroAuthManager(
    refresh_token="your_token",
    region="us-east-1",
    creds_file="~/.aws/sso/cache/kiro-auth-token.json"
)
token = await auth_manager.get_access_token()
```

#### ModelInfoCache (`kiro_gateway/cache.py`)

**Role:** Thread-safe storage for model configurations.

**Population Strategy:** 
- Lazy Loading via `/ListAvailableModels`
- Cache TTL: 1 hour
- Fallback to static model list

**Main methods:**
- `update(models_data)` ‚Äî cache update
- `get(model_id)` ‚Äî get model information
- `get_max_input_tokens(model_id)` ‚Äî get token limit
- `is_empty()` / `is_stale()` ‚Äî cache state check
- `get_all_model_ids()` ‚Äî list of all model IDs

### 3.5. Helper Utilities (`kiro_gateway/utils.py`)

| Function | Description |
|----------|-------------|
| `get_machine_fingerprint()` | SHA256 hash of `{hostname}-{username}-kiro-gateway` |
| `get_kiro_headers(auth_manager, token)` | Form headers for Kiro API |
| `generate_completion_id()` | ID in format `chatcmpl-{uuid_hex}` |
| `generate_conversation_id()` | UUID for conversation |
| `generate_tool_call_id()` | ID in format `call_{uuid_hex[:8]}` |

### 3.6. Conversion Layer (`kiro_gateway/converters.py`)

#### Message Conversion

OpenAI messages are transformed into Kiro conversationState:

1. **System prompt** ‚Äî added to the first user message
2. **Message history** ‚Äî fully passed in `history` array
3. **Adjacent message merging** ‚Äî messages with the same role are merged
4. **Tool calls** ‚Äî OpenAI tools format support
5. **Tool results** ‚Äî correct transmission of tool call results

#### Long Tool Description Handling

**Problem:** Kiro API returns error 400 for too long descriptions in `toolSpecification.description`.

**Solution:** Tool Documentation Reference Pattern
- If `description ‚â§ TOOL_DESCRIPTION_MAX_LENGTH` ‚Üí leave as is
- If `description > TOOL_DESCRIPTION_MAX_LENGTH`:
  * In `toolSpecification.description` ‚Üí reference: `"[Full documentation in system prompt under '## Tool: {name}']"`
  * In system prompt, section `"## Tool: {name}"` with full description is added

**Function:** `process_tools_with_long_descriptions(tools)` ‚Üí `(processed_tools, tool_documentation)`

#### Main Functions

| Function | Description |
|----------|-------------|
| `extract_text_content(content)` | Extract text from various formats |
| `merge_adjacent_messages(messages)` | Merge adjacent messages with same role |
| `build_kiro_history(messages, model_id)` | Build history array for Kiro |
| `build_kiro_payload(request_data, conversation_id, profile_arn)` | Full payload for request |

#### Model Mapping

External model names are converted to internal Kiro IDs:

| External Name | Internal Kiro ID |
|---------------|------------------|
| `claude-opus-4-5` | `claude-opus-4.5` |
| `claude-opus-4-5-20251101` | `claude-opus-4.5` |
| `claude-haiku-4-5` | `claude-haiku-4.5` |
| `claude-haiku-4.5` | `claude-haiku-4.5` (direct passthrough) |
| `claude-sonnet-4-5` | `CLAUDE_SONNET_4_5_20250929_V1_0` |
| `claude-sonnet-4-5-20250929` | `CLAUDE_SONNET_4_5_20250929_V1_0` |
| `claude-sonnet-4` | `CLAUDE_SONNET_4_20250514_V1_0` |
| `claude-sonnet-4-20250514` | `CLAUDE_SONNET_4_20250514_V1_0` |
| `claude-3-7-sonnet-20250219` | `CLAUDE_3_7_SONNET_20250219_V1_0` |
| `auto` | `claude-sonnet-4.5` (alias) |

### 3.7. Parsing Layer (`kiro_gateway/parsers.py`)

#### AwsEventStreamParser

Advanced AWS SSE format parser with support for:

- **Bracket counting** ‚Äî correct parsing of nested JSON objects
- **Content deduplication** ‚Äî filtering of duplicate events
- **Tool calls** ‚Äî parsing of structured and bracket-style tool calls
- **Escape sequences** ‚Äî decoding of `\n` and others

#### Event Types

| Event | Description |
|-------|-------------|
| `content` | Text content of the response |
| `tool_start` | Start of tool call (name, toolUseId) |
| `tool_input` | Continuation of input for tool call |
| `tool_stop` | End of tool call |
| `usage` | Credit consumption information |
| `context_usage` | Context usage percentage |

#### Helper Functions

| Function | Description |
|----------|-------------|
| `find_matching_brace(text, start_pos)` | Find closing brace with nesting support |
| `parse_bracket_tool_calls(response_text)` | Parse `[Called func with args: {...}]` |
| `deduplicate_tool_calls(tool_calls)` | Remove duplicate tool calls |

### 3.8. Streaming (`kiro_gateway/streaming.py`)

#### stream_kiro_to_openai

Async generator for transforming Kiro stream to OpenAI format.

**Functionality:**
- Parse AWS SSE stream via `AwsEventStreamParser`
- Form OpenAI `chat.completion.chunk`
- Handle tool calls (structured and bracket-style)
- Calculate usage based on `contextUsagePercentage`
- Debug logging via `debug_logger`

#### collect_stream_response

Collects full response from streaming for non-streaming mode.

### 3.9. HTTP Client (`kiro_gateway/http_client.py`)

#### KiroHttpClient

Automatic error handling with exponential backoff:

| Error Code | Action |
|------------|--------|
| `403` | Token refresh via `force_refresh()` + retry |
| `429` | Exponential backoff: `BASE_RETRY_DELAY * (2 ** attempt)` |
| `5xx` | Exponential backoff (up to MAX_RETRIES attempts) |
| Timeout | Exponential backoff |

**Delay formula:** `1s, 2s, 4s` (with `BASE_RETRY_DELAY=1.0`)

**Methods:**
- `request_with_retry(method, url, json_data, stream)` ‚Äî request with retry
- `close()` ‚Äî close client

Supports async context manager (`async with`).

### 3.10. Routes (`kiro_gateway/routes.py`)

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Health check (status, message, version) |
| `/health` | GET | Detailed health check (status, timestamp, version) |
| `/v1/models` | GET | List of available models (requires API key) |
| `/v1/chat/completions` | POST | Chat completions (requires API key) |

**Authentication:** Bearer token in `Authorization` header

### 3.11. Exception Handling (`kiro_gateway/exceptions.py`)

| Function | Description |
|----------|-------------|
| `sanitize_validation_errors(errors)` | Convert bytes to strings for JSON serialization |
| `validation_exception_handler(request, exc)` | Pydantic validation error handler (422) |

### 3.12. Debug Logging (`kiro_gateway/debug_logger.py`)

**Class:** `DebugLogger` (singleton)

**Activation:** `DEBUG_LAST_REQUEST=true` in `.env`

**Methods:**
| Method | Description |
|--------|-------------|
| `prepare_new_request()` | Clear directory for new request |
| `log_request_body(body)` | Save incoming request |
| `log_kiro_request_body(body)` | Save request to Kiro API |
| `log_raw_chunk(chunk)` | Append raw chunk from Kiro |
| `log_modified_chunk(chunk)` | Append transformed chunk |

**Files in `debug_logs/`:**
- `request_body.json` ‚Äî incoming request (OpenAI format)
- `kiro_request_body.json` ‚Äî request to Kiro API
- `response_stream_raw.txt` ‚Äî raw stream from Kiro
- `response_stream_modified.txt` ‚Äî transformed stream (OpenAI format)

### 3.13. Tokenizer (`kiro_gateway/tokenizer.py`)

**Problem:** Kiro API does not return token counts directly. Instead, the API only provides `context_usage_percentage` ‚Äî the percentage of model context usage.

**Solution:** Tokenizer module based on `tiktoken` (OpenAI's Rust library) for fast token counting.

**Features:**
- Uses `cl100k_base` encoding (GPT-4), close to Claude tokenization
- Correction factor `CLAUDE_CORRECTION_FACTOR = 1.15` for improved accuracy
- Lazy initialization for faster imports
- Fallback to rough estimation if tiktoken is unavailable

**Token calculation formula in response:**
```
total_tokens = context_usage_percentage √ó max_input_tokens  (from Kiro API)
completion_tokens = tiktoken(response)                       (our calculation)
prompt_tokens = total_tokens - completion_tokens             (subtraction)
```

**Main functions:**

| Function | Description |
|----------|-------------|
| `count_tokens(text)` | Count tokens in text |
| `count_message_tokens(messages)` | Count tokens in message list |
| `count_tools_tokens(tools)` | Count tokens in tool definitions |
| `estimate_request_tokens(messages, tools)` | Full request token estimation |

**Debug log:**
```
[Usage] claude-opus-4-5: prompt_tokens=142211 (subtraction), completion_tokens=769 (tiktoken), total_tokens=142980 (API Kiro)
```

**Accuracy:** ~97-99.7% compared to API data.

### 3.14. Kiro API Endpoints

All URLs are dynamically formed based on the region:

*   **Token Refresh:** `POST https://prod.{region}.auth.desktop.kiro.dev/refreshToken`
*   **List Models:** `GET https://q.{region}.amazonaws.com/ListAvailableModels`
*   **Generate Response:** `POST https://codewhisperer.{region}.amazonaws.com/generateAssistantResponse`

## 4. Detailed Data Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  OpenAI Client  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ POST /v1/chat/completions
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Security Gate  ‚îÇ ‚óÑ‚îÄ‚îÄ Proxy Bearer token verification
‚îÇ  (routes.py)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ KiroAuthManager ‚îÇ ‚óÑ‚îÄ‚îÄ Get/refresh accessToken
‚îÇ   (auth.py)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Payload Builder ‚îÇ ‚óÑ‚îÄ‚îÄ Convert OpenAI ‚Üí Kiro format
‚îÇ (converters.py) ‚îÇ     (history, system prompt, tools)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ KiroHttpClient  ‚îÇ ‚óÑ‚îÄ‚îÄ Retry logic (403, 429, 5xx)
‚îÇ (http_client.py)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ POST /generateAssistantResponse
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Kiro API      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ AWS SSE Stream
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ SSE Parser      ‚îÇ ‚óÑ‚îÄ‚îÄ Event parsing, tool calls
‚îÇ  (parsers.py)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ OpenAI Format   ‚îÇ ‚óÑ‚îÄ‚îÄ Convert to OpenAI SSE
‚îÇ (streaming.py)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  OpenAI Client  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## 5. Available Models

| Model | Description | Credits |
|-------|-------------|---------|
| `claude-opus-4-5` | Top-tier model | ~2.2 |
| `claude-opus-4-5-20251101` | Top-tier model (version) | ~2.2 |
| `claude-sonnet-4-5` | Enhanced model | ~1.3 |
| `claude-sonnet-4-5-20250929` | Enhanced model (version) | ~1.3 |
| `claude-sonnet-4` | Balanced model | ~1.3 |
| `claude-sonnet-4-20250514` | Balanced (version) | ~1.3 |
| `claude-haiku-4-5` | Fast model | ~0.4 |
| `claude-3-7-sonnet-20250219` | Legacy model | ~1.0 |

## 6. Configuration

### Environment Variables (.env)

```env
# Required
REFRESH_TOKEN="your_kiro_refresh_token"
PROXY_API_KEY="your_proxy_secret"

# Optional
PROFILE_ARN="arn:aws:codewhisperer:..."
KIRO_REGION="us-east-1"
KIRO_CREDS_FILE="~/.aws/sso/cache/kiro-auth-token.json"

# Debug
DEBUG_LAST_REQUEST="false"
DEBUG_DIR="debug_logs"

# Limits
TOOL_DESCRIPTION_MAX_LENGTH="10000"
```

### JSON Credentials File (optional)

```json
{
  "accessToken": "eyJ...",
  "refreshToken": "eyJ...",
  "expiresAt": "2025-01-12T23:00:00.000Z",
  "profileArn": "arn:aws:codewhisperer:us-east-1:...",
  "region": "us-east-1"
}
```

## 7. API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Health check |
| `/health` | GET | Detailed health check |
| `/v1/models` | GET | List of available models |
| `/v1/chat/completions` | POST | Chat completions (streaming/non-streaming) |

## 8. Implementation Features

### Tool Calling

Support for OpenAI-compatible tools format:

```json
{
  "tools": [{
    "type": "function",
    "function": {
      "name": "get_weather",
      "description": "Get weather for a location",
      "parameters": {
        "type": "object",
        "properties": {
          "location": {"type": "string"}
        }
      }
    }
  }]
}
```

### Streaming

Full SSE streaming support with correct OpenAI format:

```
data: {"id":"chatcmpl-...","object":"chat.completion.chunk",...}

data: [DONE]
```

### Debugging

When `DEBUG_LAST_REQUEST=true`, all requests and responses are logged in `debug_logs/`:
- `request_body.json` ‚Äî incoming request
- `kiro_request_body.json` ‚Äî request to Kiro API
- `response_stream_raw.txt` ‚Äî raw stream from Kiro
- `response_stream_modified.txt` ‚Äî transformed stream

## 9. Extensibility

### Adding a New Provider

The modular architecture allows easy addition of support for other providers:

1. Create a new module `kiro_gateway/providers/new_provider.py`
2. Implement classes:
   - `NewProviderAuthManager` ‚Äî token management
   - `NewProviderConverter` ‚Äî format conversion
   - `NewProviderParser` ‚Äî response parsing
3. Add routes to `routes.py` or create a separate router

### Example Structure for a New Provider

```python
# kiro_gateway/providers/gemini.py

class GeminiAuthManager:
    """Gemini API key management."""
    pass

class GeminiConverter:
    """OpenAI -> Gemini format conversion."""
    pass

class GeminiParser:
    """Gemini SSE stream parsing."""
    pass
```

## 10. Dependencies

Main project dependencies (from `requirements.txt`):

| Package | Purpose |
|---------|---------|
| `fastapi` | Asynchronous web framework |
| `uvicorn` | ASGI server |
| `httpx` | Asynchronous HTTP client |
| `pydantic` | Data validation and models |
| `python-dotenv` | Environment variable loading |
| `loguru` | Advanced logging |
| `tiktoken` | Fast token counting |


================================================
FILE: docs/ru/ARCHITECTURE.md
================================================
# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π –û–±–∑–æ—Ä: Kiro OpenAI Gateway

## 1. –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ –∏ –¶–µ–ª–∏ –°–∏—Å—Ç–µ–º—ã

–ü—Ä–æ–µ–∫—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π –ø—Ä–æ–∫—Å–∏-—à–ª—é–∑, —Ä–µ–∞–ª–∏–∑—É—é—â–∏–π —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è **"–ê–¥–∞–ø—Ç–µ—Ä" (Adapter)**.

–û—Å–Ω–æ–≤–Ω–∞—è —Ü–µ–ª—å —Å–∏—Å—Ç–µ–º—ã ‚Äî –æ–±–µ—Å–ø–µ—á–∏—Ç—å –ø—Ä–æ–∑—Ä–∞—á–Ω—É—é —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –º–µ–∂–¥—É –¥–≤—É–º—è –≥–µ—Ç–µ—Ä–æ–≥–µ–Ω–Ω—ã–º–∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞–º–∏:
1.  **Target Interface (–ö–ª–∏–µ–Ω—Ç):** –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø—Ä–æ—Ç–æ–∫–æ–ª OpenAI API (—ç–Ω–¥–ø–æ–∏–Ω—Ç—ã `/v1/models`, `/v1/chat/completions`).
2.  **Adaptee (–ü–æ—Å—Ç–∞–≤—â–∏–∫):** –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π API Kiro IDE (AWS CodeWhisperer), –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–π –≤ —ç–∫–æ—Å–∏—Å—Ç–µ–º–µ Amazon Kiro.

–°–∏—Å—Ç–µ–º–∞ –≤—ã—Å—Ç—É–ø–∞–µ—Ç –≤ —Ä–æ–ª–∏ "–ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∞", –ø–æ–∑–≤–æ–ª—è—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª—é–±—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã, –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∏ IDE-–ø–ª–∞–≥–∏–Ω—ã, —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–ª—è —ç–∫–æ—Å–∏—Å—Ç–µ–º—ã OpenAI, —Å –º–æ–¥–µ–ª—è–º–∏ Claude —á–µ—Ä–µ–∑ Kiro API.

## 2. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ü—Ä–æ–µ–∫—Ç–∞

–ü—Ä–æ–µ–∫—Ç –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–Ω –≤ –≤–∏–¥–µ –º–æ–¥—É–ª—å–Ω–æ–≥–æ Python-–ø–∞–∫–µ—Ç–∞ `kiro_gateway/`:

```
kiro-openai-gateway/
‚îú‚îÄ‚îÄ main.py                    # –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞, —Å–æ–∑–¥–∞–Ω–∏–µ FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
‚îú‚îÄ‚îÄ requirements.txt           # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ Python
‚îú‚îÄ‚îÄ .env.example               # –ü—Ä–∏–º–µ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è
‚îÇ
‚îú‚îÄ‚îÄ kiro_gateway/              # –û—Å–Ω–æ–≤–Ω–æ–π –ø–∞–∫–µ—Ç
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py            # –≠–∫—Å–ø–æ—Ä—Ç—ã –ø–∞–∫–µ—Ç–∞, –≤–µ—Ä—Å–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ config.py              # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã
‚îÇ   ‚îú‚îÄ‚îÄ models.py              # Pydantic –º–æ–¥–µ–ª–∏ OpenAI API
‚îÇ   ‚îú‚îÄ‚îÄ auth.py                # KiroAuthManager - —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞–º–∏
‚îÇ   ‚îú‚îÄ‚îÄ cache.py               # ModelInfoCache - –∫—ç—à –º–æ–¥–µ–ª–µ–π
‚îÇ   ‚îú‚îÄ‚îÄ utils.py               # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —É—Ç–∏–ª–∏—Ç—ã
‚îÇ   ‚îú‚îÄ‚îÄ converters.py          # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è OpenAI <-> Kiro
‚îÇ   ‚îú‚îÄ‚îÄ parsers.py             # –ü–∞—Ä—Å–µ—Ä—ã AWS SSE –ø–æ—Ç–æ–∫–æ–≤
‚îÇ   ‚îú‚îÄ‚îÄ streaming.py           # –õ–æ–≥–∏–∫–∞ —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–æ–≤
‚îÇ   ‚îú‚îÄ‚îÄ http_client.py         # HTTP –∫–ª–∏–µ–Ω—Ç —Å retry –ª–æ–≥–∏–∫–æ–π
‚îÇ   ‚îú‚îÄ‚îÄ routes.py              # FastAPI —Ä–æ—É—Ç—ã
‚îÇ   ‚îú‚îÄ‚îÄ debug_logger.py        # –û—Ç–ª–∞–¥–æ—á–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤
‚îÇ   ‚îú‚îÄ‚îÄ tokenizer.py           # –ü–æ–¥—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤ (tiktoken)
‚îÇ   ‚îî‚îÄ‚îÄ exceptions.py          # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∏—Å–∫–ª—é—á–µ–Ω–∏–π
‚îÇ
‚îú‚îÄ‚îÄ tests/                     # –¢–µ—Å—Ç—ã
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py            # Pytest fixtures
‚îÇ   ‚îú‚îÄ‚îÄ unit/                  # –Æ–Ω–∏—Ç-—Ç–µ—Å—Ç—ã
‚îÇ   ‚îî‚îÄ‚îÄ integration/           # –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã
‚îÇ
‚îú‚îÄ‚îÄ docs/                      # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ ru/                    # –†—É—Å—Å–∫–∞—è –≤–µ—Ä—Å–∏—è
‚îÇ   ‚îî‚îÄ‚îÄ en/                    # –ê–Ω–≥–ª–∏–π—Å–∫–∞—è –≤–µ—Ä—Å–∏—è
‚îÇ
‚îî‚îÄ‚îÄ debug_logs/                # –û—Ç–ª–∞–¥–æ—á–Ω—ã–µ –ª–æ–≥–∏ (–≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è –ø—Ä–∏ DEBUG_LAST_REQUEST=true)
```

## 3. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω–∞—è –¢–æ–ø–æ–ª–æ–≥–∏—è –∏ –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

–°–∏—Å—Ç–µ–º–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∞ –Ω–∞ –±–∞–∑–µ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞ `FastAPI` –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–æ–±—ã—Ç–∏–π–Ω—É—é –º–æ–¥–µ–ª—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º (`Lifespan Events`).

### 3.1. –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ (`main.py`)

–§–∞–π–ª `main.py` –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞:

1. **–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è** ‚Äî –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ Loguru —Å —Ü–≤–µ—Ç–Ω—ã–º –≤—ã–≤–æ–¥–æ–º
2. **–í–∞–ª–∏–¥–∞—Ü–∏—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏** ‚Äî —Ñ—É–Ω–∫—Ü–∏—è `validate_configuration()` –ø—Ä–æ–≤–µ—Ä—è–µ—Ç:
   - –ù–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞ `.env`
   - –ù–∞–ª–∏—á–∏–µ credentials (REFRESH_TOKEN –∏–ª–∏ KIRO_CREDS_FILE)
3. **Lifespan Manager** ‚Äî —Å–æ–∑–¥–∞–Ω–∏–µ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è:
   - `KiroAuthManager` –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞–º–∏
   - `ModelInfoCache` –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π
4. **–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ –æ—à–∏–±–æ–∫** ‚Äî `validation_exception_handler` –¥–ª—è –æ—à–∏–±–æ–∫ 422
5. **–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —Ä–æ—É—Ç–æ–≤** ‚Äî `app.include_router(router)`

### 3.2. –ú–æ–¥—É–ª—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (`kiro_gateway/config.py`)

–¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫:

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –û–ø–∏—Å–∞–Ω–∏–µ | –ó–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é |
|----------|----------|----------------------|
| `PROXY_API_KEY` | API –∫–ª—é—á –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –ø—Ä–æ–∫—Å–∏ | `changeme_proxy_secret` |
| `REFRESH_TOKEN` | Refresh token Kiro | –∏–∑ `.env` |
| `PROFILE_ARN` | ARN –ø—Ä–æ—Ñ–∏–ª—è AWS CodeWhisperer | –∏–∑ `.env` |
| `REGION` | –†–µ–≥–∏–æ–Ω AWS | `us-east-1` |
| `KIRO_CREDS_FILE` | –ü—É—Ç—å –∫ JSON —Ñ–∞–π–ª—É credentials | –∏–∑ `.env` |
| `TOKEN_REFRESH_THRESHOLD` | –í—Ä–µ–º—è –¥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞ | 600 —Å–µ–∫ (10 –º–∏–Ω) |
| `MAX_RETRIES` | –ú–∞–∫—Å. –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–æ–≤ | 3 |
| `BASE_RETRY_DELAY` | –ë–∞–∑–æ–≤–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ retry | 1.0 —Å–µ–∫ |
| `MODEL_CACHE_TTL` | TTL –∫—ç—à–∞ –º–æ–¥–µ–ª–µ–π | 3600 —Å–µ–∫ (1 —á–∞—Å) |
| `DEFAULT_MAX_INPUT_TOKENS` | –ú–∞–∫—Å. input —Ç–æ–∫–µ–Ω–æ–≤ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é | 200000 |
| `TOOL_DESCRIPTION_MAX_LENGTH` | –ú–∞–∫—Å. –¥–ª–∏–Ω–∞ –æ–ø–∏—Å–∞–Ω–∏—è tool | 10000 —Å–∏–º–≤–æ–ª–æ–≤ |
| `DEBUG_LAST_REQUEST` | –í–∫–ª—é—á–∏—Ç—å –æ—Ç–ª–∞–¥–æ—á–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ | `false` |
| `DEBUG_DIR` | –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è debug –ª–æ–≥–æ–≤ | `debug_logs` |
| `APP_VERSION` | –í–µ—Ä—Å–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è | `0.0.0` |

**–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:**
- `get_kiro_refresh_url(region)` ‚Äî URL –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞
- `get_kiro_api_host(region)` ‚Äî —Ö–æ—Å—Ç –æ—Å–Ω–æ–≤–Ω–æ–≥–æ API
- `get_kiro_q_host(region)` ‚Äî —Ö–æ—Å—Ç Q API
- `get_internal_model_id(external_model)` ‚Äî –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–º–µ–Ω–∏ –º–æ–¥–µ–ª–∏

### 3.3. Pydantic –ú–æ–¥–µ–ª–∏ (`kiro_gateway/models.py`)

#### –ú–æ–¥–µ–ª–∏ –¥–ª—è `/v1/models`

| –ú–æ–¥–µ–ª—å | –û–ø–∏—Å–∞–Ω–∏–µ |
|--------|----------|
| `OpenAIModel` | –û–ø–∏—Å–∞–Ω–∏–µ AI –º–æ–¥–µ–ª–∏ (id, object, created, owned_by) |
| `ModelList` | –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è –æ—Ç–≤–µ—Ç–∞ endpoint |

#### –ú–æ–¥–µ–ª–∏ –¥–ª—è `/v1/chat/completions`

| –ú–æ–¥–µ–ª—å | –û–ø–∏—Å–∞–Ω–∏–µ |
|--------|----------|
| `ChatMessage` | –°–æ–æ–±—â–µ–Ω–∏–µ —á–∞—Ç–∞ (role, content, tool_calls, tool_call_id) |
| `ToolFunction` | –û–ø–∏—Å–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ (name, description, parameters) |
| `Tool` | –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç OpenAI —Ñ–æ—Ä–º–∞—Ç–∞ (type, function) |
| `ChatCompletionRequest` | –ó–∞–ø—Ä–æ—Å –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é (model, messages, stream, tools, ...) |

#### –ú–æ–¥–µ–ª–∏ –æ—Ç–≤–µ—Ç–æ–≤

| –ú–æ–¥–µ–ª—å | –û–ø–∏—Å–∞–Ω–∏–µ |
|--------|----------|
| `ChatCompletionChoice` | –û–¥–∏–Ω –≤–∞—Ä–∏–∞–Ω—Ç –æ—Ç–≤–µ—Ç–∞ |
| `ChatCompletionUsage` | –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–æ–∫–µ–Ω–∞—Ö (prompt_tokens, completion_tokens, credits_used) |
| `ChatCompletionResponse` | –ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç (non-streaming) |
| `ChatCompletionChunk` | Streaming chunk |
| `ChatCompletionChunkDelta` | –î–µ–ª—å—Ç–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ chunk |
| `ChatCompletionChunkChoice` | –í–∞—Ä–∏–∞–Ω—Ç –≤ streaming chunk |

### 3.4. –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –°–æ—Å—Ç–æ—è–Ω–∏–µ–º (State Management Layer)

#### KiroAuthManager (`kiro_gateway/auth.py`)

**–†–æ–ª—å:** Stateful-—Å–∏–Ω–≥–ª—Ç–æ–Ω, –∏–Ω–∫–∞–ø—Å—É–ª–∏—Ä—É—é—â–∏–π –ª–æ–≥–∏–∫—É —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞–º–∏ Kiro.

**–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**
- –ó–∞–≥—Ä—É–∑–∫–∞ credentials –∏–∑ `.env` –∏–ª–∏ JSON —Ñ–∞–π–ª–∞
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ `expiresAt` –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤—Ä–µ–º–µ–Ω–∏ –∏—Å—Ç–µ—á–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞ –∑–∞ 10 –º–∏–Ω—É—Ç –¥–æ –∏—Å—Ç–µ—á–µ–Ω–∏—è
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –æ–±—Ä–∞—Ç–Ω–æ –≤ JSON —Ñ–∞–π–ª
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞–∑–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤ AWS
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ fingerprint –¥–ª—è User-Agent

**Concurrency Control:** –ò—Å–ø–æ–ª—å–∑—É–µ—Ç `asyncio.Lock` –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏—è –≥–æ–Ω–∫–∏.

**–û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã:**
- `get_access_token()` ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω, –æ–±–Ω–æ–≤–ª—è—è –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
- `force_refresh()` ‚Äî –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞ (–ø—Ä–∏ 403)
- `is_token_expiring_soon()` ‚Äî –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –∏—Å—Ç–µ—á–µ–Ω–∏—è

**Properties:**
- `profile_arn` ‚Äî ARN –ø—Ä–æ—Ñ–∏–ª—è
- `region` ‚Äî —Ä–µ–≥–∏–æ–Ω AWS
- `api_host` ‚Äî —Ö–æ—Å—Ç API –¥–ª—è —Ä–µ–≥–∏–æ–Ω–∞
- `q_host` ‚Äî —Ö–æ—Å—Ç Q API –¥–ª—è —Ä–µ–≥–∏–æ–Ω–∞
- `fingerprint` ‚Äî —É–Ω–∏–∫–∞–ª—å–Ω—ã–π fingerprint –º–∞—à–∏–Ω—ã

```python
# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
auth_manager = KiroAuthManager(
    refresh_token="your_token",
    region="us-east-1",
    creds_file="~/.aws/sso/cache/kiro-auth-token.json"
)
token = await auth_manager.get_access_token()
```

#### ModelInfoCache (`kiro_gateway/cache.py`)

**–†–æ–ª—å:** –ü–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π –º–æ–¥–µ–ª–µ–π.

**–°—Ç—Ä–∞—Ç–µ–≥–∏—è –ó–∞–ø–æ–ª–Ω–µ–Ω–∏—è:** 
- Lazy Loading —á–µ—Ä–µ–∑ `/ListAvailableModels`
- TTL –∫—ç—à–∞: 1 —á–∞—Å
- Fallback –Ω–∞ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π

**–û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã:**
- `update(models_data)` ‚Äî –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫—ç—à–∞
- `get(model_id)` ‚Äî –ø–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏
- `get_max_input_tokens(model_id)` ‚Äî –ø–æ–ª—É—á–µ–Ω–∏–µ –ª–∏–º–∏—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤
- `is_empty()` / `is_stale()` ‚Äî –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∫—ç—à–∞
- `get_all_model_ids()` ‚Äî —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö ID –º–æ–¥–µ–ª–µ–π

### 3.5. –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –£—Ç–∏–ª–∏—Ç—ã (`kiro_gateway/utils.py`)

| –§—É–Ω–∫—Ü–∏—è | –û–ø–∏—Å–∞–Ω–∏–µ |
|---------|----------|
| `get_machine_fingerprint()` | SHA256 —Ö–µ—à `{hostname}-{username}-kiro-gateway` |
| `get_kiro_headers(auth_manager, token)` | –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –¥–ª—è Kiro API |
| `generate_completion_id()` | ID –≤ —Ñ–æ—Ä–º–∞—Ç–µ `chatcmpl-{uuid_hex}` |
| `generate_conversation_id()` | UUID –¥–ª—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ |
| `generate_tool_call_id()` | ID –≤ —Ñ–æ—Ä–º–∞—Ç–µ `call_{uuid_hex[:8]}` |

### 3.6. –°–ª–æ–π –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ (`kiro_gateway/converters.py`)

#### –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π

OpenAI messages –ø—Ä–µ–æ–±—Ä–∞–∑—É—é—Ç—Å—è –≤ Kiro conversationState:

1. **System prompt** ‚Äî –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –∫ –ø–µ—Ä–≤–æ–º—É user —Å–æ–æ–±—â–µ–Ω–∏—é
2. **–ò—Å—Ç–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π** ‚Äî –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ–¥–∞—ë—Ç—Å—è –≤ `history` array
3. **–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ—Å–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π** ‚Äî —Å–æ–æ–±—â–µ–Ω–∏—è —Å –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π —Ä–æ–ª—å—é –º–µ—Ä–¥–∂–∞—Ç—Å—è
4. **Tool calls** ‚Äî –ø–æ–¥–¥–µ—Ä–∂–∫–∞ OpenAI tools —Ñ–æ—Ä–º–∞—Ç–∞
5. **Tool results** ‚Äî –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –ø–µ—Ä–µ–¥–∞—á–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤—ã–∑–æ–≤–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤

#### –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª–∏–Ω–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π Tools

**–ü—Ä–æ–±–ª–µ–º–∞:** Kiro API –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—à–∏–±–∫—É 400 –ø—Ä–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏—è—Ö –≤ `toolSpecification.description`.

**–†–µ—à–µ–Ω–∏–µ:** Tool Documentation Reference Pattern
- –ï—Å–ª–∏ `description ‚â§ TOOL_DESCRIPTION_MAX_LENGTH` ‚Üí –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
- –ï—Å–ª–∏ `description > TOOL_DESCRIPTION_MAX_LENGTH`:
  * –í `toolSpecification.description` ‚Üí —Å—Å—ã–ª–∫–∞: `"[Full documentation in system prompt under '## Tool: {name}']"`
  * –í system prompt –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è —Å–µ–∫—Ü–∏—è `"## Tool: {name}"` —Å –ø–æ–ª–Ω—ã–º –æ–ø–∏—Å–∞–Ω–∏–µ–º

**–§—É–Ω–∫—Ü–∏—è:** `process_tools_with_long_descriptions(tools)` ‚Üí `(processed_tools, tool_documentation)`

#### –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏

| –§—É–Ω–∫—Ü–∏—è | –û–ø–∏—Å–∞–Ω–∏–µ |
|---------|----------|
| `extract_text_content(content)` | –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ |
| `merge_adjacent_messages(messages)` | –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ—Å–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π —Å –æ–¥–Ω–æ–π —Ä–æ–ª—å—é |
| `build_kiro_history(messages, model_id)` | –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–∞—Å—Å–∏–≤–∞ history –¥–ª—è Kiro |
| `build_kiro_payload(request_data, conversation_id, profile_arn)` | –ü–æ–ª–Ω—ã–π payload –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ |

#### –ú–∞–ø–ø–∏–Ω–≥ –º–æ–¥–µ–ª–µ–π

–í–Ω–µ—à–Ω–∏–µ –∏–º–µ–Ω–∞ –º–æ–¥–µ–ª–µ–π –ø—Ä–µ–æ–±—Ä–∞–∑—É—é—Ç—Å—è –≤–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ ID Kiro:

| –í–Ω–µ—à–Ω–µ–µ –∏–º—è | –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π ID Kiro |
|-------------|-------------------|
| `claude-opus-4-5` | `claude-opus-4.5` |
| `claude-opus-4-5-20251101` | `claude-opus-4.5` |
| `claude-haiku-4-5` | `claude-haiku-4.5` |
| `claude-haiku-4.5` | `claude-haiku-4.5` (–ø—Ä—è–º–æ–π –ø—Ä–æ–±—Ä–æ—Å) |
| `claude-sonnet-4-5` | `CLAUDE_SONNET_4_5_20250929_V1_0` |
| `claude-sonnet-4-5-20250929` | `CLAUDE_SONNET_4_5_20250929_V1_0` |
| `claude-sonnet-4` | `CLAUDE_SONNET_4_20250514_V1_0` |
| `claude-sonnet-4-20250514` | `CLAUDE_SONNET_4_20250514_V1_0` |
| `claude-3-7-sonnet-20250219` | `CLAUDE_3_7_SONNET_20250219_V1_0` |
| `auto` | `claude-sonnet-4.5` (–∞–ª–∏–∞—Å) |

### 3.7. –°–ª–æ–π –ü–∞—Ä—Å–∏–Ω–≥–∞ (`kiro_gateway/parsers.py`)

#### AwsEventStreamParser

–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –ø–∞—Ä—Å–µ—Ä AWS SSE —Ñ–æ—Ä–º–∞—Ç–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π:

- **Bracket counting** ‚Äî –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö JSON –æ–±—ä–µ–∫—Ç–æ–≤
- **–î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞** ‚Äî —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è —Å–æ–±—ã—Ç–∏–π
- **Tool calls** ‚Äî –ø–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏ bracket-style tool calls
- **Escape-–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏** ‚Äî –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ `\n` –∏ –¥—Ä—É–≥–∏—Ö

#### –¢–∏–ø—ã —Å–æ–±—ã—Ç–∏–π

| –°–æ–±—ã—Ç–∏–µ | –û–ø–∏—Å–∞–Ω–∏–µ |
|---------|----------|
| `content` | –¢–µ–∫—Å—Ç–æ–≤—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –æ—Ç–≤–µ—Ç–∞ |
| `tool_start` | –ù–∞—á–∞–ª–æ tool call (name, toolUseId) |
| `tool_input` | –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ input –¥–ª—è tool call |
| `tool_stop` | –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ tool call |
| `usage` | –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–∏ –∫—Ä–µ–¥–∏—Ç–æ–≤ |
| `context_usage` | –ü—Ä–æ—Ü–µ–Ω—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ |

#### –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏

| –§—É–Ω–∫—Ü–∏—è | –û–ø–∏—Å–∞–Ω–∏–µ |
|---------|----------|
| `find_matching_brace(text, start_pos)` | –ü–æ–∏—Å–∫ –∑–∞–∫—Ä—ã–≤–∞—é—â–µ–π —Å–∫–æ–±–∫–∏ —Å —É—á—ë—Ç–æ–º –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏ |
| `parse_bracket_tool_calls(response_text)` | –ü–∞—Ä—Å–∏–Ω–≥ `[Called func with args: {...}]` |
| `deduplicate_tool_calls(tool_calls)` | –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ tool calls |

### 3.8. Streaming (`kiro_gateway/streaming.py`)

#### stream_kiro_to_openai

–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –ø–æ—Ç–æ–∫–∞ Kiro –≤ OpenAI —Ñ–æ—Ä–º–∞—Ç.

**–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å:**
- –ü–∞—Ä—Å–∏–Ω–≥ AWS SSE stream —á–µ—Ä–µ–∑ `AwsEventStreamParser`
- –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ OpenAI `chat.completion.chunk`
- –û–±—Ä–∞–±–æ—Ç–∫–∞ tool calls (—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏ bracket-style)
- –í—ã—á–∏—Å–ª–µ–Ω–∏–µ usage –Ω–∞ –æ—Å–Ω–æ–≤–µ `contextUsagePercentage`
- –û—Ç–ª–∞–¥–æ—á–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ `debug_logger`

#### collect_stream_response

–°–æ–±–∏—Ä–∞–µ—Ç –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –∏–∑ streaming –ø–æ—Ç–æ–∫–∞ –¥–ª—è non-streaming —Ä–µ–∂–∏–º–∞.

### 3.9. HTTP –ö–ª–∏–µ–Ω—Ç (`kiro_gateway/http_client.py`)

#### KiroHttpClient

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ —Å exponential backoff:

| –ö–æ–¥ –æ—à–∏–±–∫–∏ | –î–µ–π—Å—Ç–≤–∏–µ |
|------------|----------|
| `403` | Refresh —Ç–æ–∫–µ–Ω–∞ —á–µ—Ä–µ–∑ `force_refresh()` + –ø–æ–≤—Ç–æ—Ä |
| `429` | Exponential backoff: `BASE_RETRY_DELAY * (2 ** attempt)` |
| `5xx` | Exponential backoff (–¥–æ MAX_RETRIES –ø–æ–ø—ã—Ç–æ–∫) |
| Timeout | Exponential backoff |

**–§–æ—Ä–º—É–ª–∞ –∑–∞–¥–µ—Ä–∂–∫–∏:** `1s, 2s, 4s` (–ø—Ä–∏ `BASE_RETRY_DELAY=1.0`)

**–ú–µ—Ç–æ–¥—ã:**
- `request_with_retry(method, url, json_data, stream)` ‚Äî –∑–∞–ø—Ä–æ—Å —Å retry
- `close()` ‚Äî –∑–∞–∫—Ä—ã—Ç–∏–µ –∫–ª–∏–µ–Ω—Ç–∞

–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç async context manager (`async with`).

### 3.10. –†–æ—É—Ç—ã (`kiro_gateway/routes.py`)

| Endpoint | –ú–µ—Ç–æ–¥ | –û–ø–∏—Å–∞–Ω–∏–µ |
|----------|-------|----------|
| `/` | GET | Health check (status, message, version) |
| `/health` | GET | –î–µ—Ç–∞–ª—å–Ω—ã–π health check (status, timestamp, version) |
| `/v1/models` | GET | –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π (—Ç—Ä–µ–±—É–µ—Ç API key) |
| `/v1/chat/completions` | POST | Chat completions (—Ç—Ä–µ–±—É–µ—Ç API key) |

**–ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è:** Bearer token –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ `Authorization`

### 3.11. –û–±—Ä–∞–±–æ—Ç–∫–∞ –ò—Å–∫–ª—é—á–µ–Ω–∏–π (`kiro_gateway/exceptions.py`)

| –§—É–Ω–∫—Ü–∏—è | –û–ø–∏—Å–∞–Ω–∏–µ |
|---------|----------|
| `sanitize_validation_errors(errors)` | –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è bytes –≤ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è JSON-—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏ |
| `validation_exception_handler(request, exc)` | –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ Pydantic (422) |

### 3.12. –û—Ç–ª–∞–¥–æ—á–Ω–æ–µ –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ (`kiro_gateway/debug_logger.py`)

**–ö–ª–∞—Å—Å:** `DebugLogger` (—Å–∏–Ω–≥–ª—Ç–æ–Ω)

**–ê–∫—Ç–∏–≤–∞—Ü–∏—è:** `DEBUG_LAST_REQUEST=true` –≤ `.env`

**–ú–µ—Ç–æ–¥—ã:**
| –ú–µ—Ç–æ–¥ | –û–ø–∏—Å–∞–Ω–∏–µ |
|-------|----------|
| `prepare_new_request()` | –û—á–∏—Å—Ç–∫–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –Ω–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ |
| `log_request_body(body)` | –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—Ö–æ–¥—è—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ |
| `log_kiro_request_body(body)` | –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –∫ Kiro API |
| `log_raw_chunk(chunk)` | –î–æ–ø–∏—Å—ã–≤–∞–Ω–∏–µ —Å—ã—Ä–æ–≥–æ chunk –æ—Ç Kiro |
| `log_modified_chunk(chunk)` | –î–æ–ø–∏—Å—ã–≤–∞–Ω–∏–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω–æ–≥–æ chunk |

**–§–∞–π–ª—ã –≤ `debug_logs/`:**
- `request_body.json` ‚Äî –≤—Ö–æ–¥—è—â–∏–π –∑–∞–ø—Ä–æ—Å (OpenAI —Ñ–æ—Ä–º–∞—Ç)
- `kiro_request_body.json` ‚Äî –∑–∞–ø—Ä–æ—Å –∫ Kiro API
- `response_stream_raw.txt` ‚Äî —Å—ã—Ä–æ–π –ø–æ—Ç–æ–∫ –æ—Ç Kiro
- `response_stream_modified.txt` ‚Äî –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–π –ø–æ—Ç–æ–∫ (OpenAI —Ñ–æ—Ä–º–∞—Ç)

### 3.13. –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä (`kiro_gateway/tokenizer.py`)

**–ü—Ä–æ–±–ª–µ–º–∞:** Kiro API –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–ø—Ä—è–º—É—é –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤. –í–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ API –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ `context_usage_percentage` ‚Äî –ø—Ä–æ—Ü–µ–Ω—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –º–æ–¥–µ–ª–∏.

**–†–µ—à–µ–Ω–∏–µ:** –ú–æ–¥—É–ª—å —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –Ω–∞ –±–∞–∑–µ `tiktoken` (–±–∏–±–ª–∏–æ—Ç–µ–∫–∞ OpenAI –Ω–∞ Rust) –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–¥—Å—á—ë—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤.

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**
- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∫–æ–¥–∏—Ä–æ–≤–∫—É `cl100k_base` (GPT-4), –±–ª–∏–∑–∫—É—é –∫ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ Claude
- –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ `CLAUDE_CORRECTION_FACTOR = 1.15` –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏
- –õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –∏–º–ø–æ—Ä—Ç–∞
- Fallback –Ω–∞ –≥—Ä—É–±—É—é –æ—Ü–µ–Ω–∫—É –µ—Å–ª–∏ tiktoken –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω

**–§–æ—Ä–º—É–ª–∞ —Ä–∞—Å—á—ë—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ:**
```
total_tokens = context_usage_percentage √ó max_input_tokens  (–æ—Ç API Kiro)
completion_tokens = tiktoken(–æ—Ç–≤–µ—Ç)                         (–Ω–∞—à –ø–æ–¥—Å—á—ë—Ç)
prompt_tokens = total_tokens - completion_tokens            (–≤—ã—á–∏—Ç–∞–Ω–∏–µ)
```

**–û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:**

| –§—É–Ω–∫—Ü–∏—è | –û–ø–∏—Å–∞–Ω–∏–µ |
|---------|----------|
| `count_tokens(text)` | –ü–æ–¥—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ |
| `count_message_tokens(messages)` | –ü–æ–¥—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Å–ø–∏—Å–∫–µ —Å–æ–æ–±—â–µ–Ω–∏–π |
| `count_tools_tokens(tools)` | –ü–æ–¥—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ |
| `estimate_request_tokens(messages, tools)` | –ü–æ–ª–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤ –∑–∞–ø—Ä–æ—Å–∞ |

**–î–µ–±–∞–≥-–ª–æ–≥:**
```
[Usage] claude-opus-4-5: prompt_tokens=142211 (subtraction), completion_tokens=769 (tiktoken), total_tokens=142980 (API Kiro)
```

**–¢–æ—á–Ω–æ—Å—Ç—å:** ~97-99.7% –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –¥–∞–Ω–Ω—ã–º–∏ –æ—Ç API.

### 3.14. Kiro API Endpoints

–í—Å–µ URL –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ —Ñ–æ—Ä–º–∏—Ä—É—é—Ç—Å—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–≥–∏–æ–Ω–∞:

*   **Token Refresh:** `POST https://prod.{region}.auth.desktop.kiro.dev/refreshToken`
*   **List Models:** `GET https://q.{region}.amazonaws.com/ListAvailableModels`
*   **Generate Response:** `POST https://codewhisperer.{region}.amazonaws.com/generateAssistantResponse`

## 4. –î–µ—Ç–∞–ª—å–Ω—ã–π –ü–æ—Ç–æ–∫ –î–∞–Ω–Ω—ã—Ö

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  OpenAI Client  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ POST /v1/chat/completions
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Security Gate  ‚îÇ ‚óÑ‚îÄ‚îÄ –ü—Ä–æ–≤–µ—Ä–∫–∞ Bearer —Ç–æ–∫–µ–Ω–∞ –ø—Ä–æ–∫—Å–∏
‚îÇ  (routes.py)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ KiroAuthManager ‚îÇ ‚óÑ‚îÄ‚îÄ –ü–æ–ª—É—á–µ–Ω–∏–µ/–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ accessToken
‚îÇ   (auth.py)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Payload Builder ‚îÇ ‚óÑ‚îÄ‚îÄ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è OpenAI ‚Üí Kiro —Ñ–æ—Ä–º–∞—Ç
‚îÇ (converters.py) ‚îÇ     (–∏—Å—Ç–æ—Ä–∏—è, system prompt, tools)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ KiroHttpClient  ‚îÇ ‚óÑ‚îÄ‚îÄ Retry –ª–æ–≥–∏–∫–∞ (403, 429, 5xx)
‚îÇ (http_client.py)‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ POST /generateAssistantResponse
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Kiro API      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ AWS SSE Stream
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ SSE Parser      ‚îÇ ‚óÑ‚îÄ‚îÄ –ü–∞—Ä—Å–∏–Ω–≥ —Å–æ–±—ã—Ç–∏–π, tool calls
‚îÇ  (parsers.py)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ OpenAI Format   ‚îÇ ‚óÑ‚îÄ‚îÄ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ OpenAI SSE
‚îÇ (streaming.py)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  OpenAI Client  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## 5. –î–æ—Å—Ç—É–ø–Ω—ã–µ –ú–æ–¥–µ–ª–∏

| –ú–æ–¥–µ–ª—å | –û–ø–∏—Å–∞–Ω–∏–µ | Credits |
|--------|----------|---------|
| `claude-opus-4-5` | –¢–æ–ø–æ–≤–∞—è –º–æ–¥–µ–ª—å | ~2.2 |
| `claude-opus-4-5-20251101` | –¢–æ–ø–æ–≤–∞—è –º–æ–¥–µ–ª—å (–≤–µ—Ä—Å–∏—è) | ~2.2 |
| `claude-sonnet-4-5` | –£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å | ~1.3 |
| `claude-sonnet-4-5-20250929` | –£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å (–≤–µ—Ä—Å–∏—è) | ~1.3 |
| `claude-sonnet-4` | –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å | ~1.3 |
| `claude-sonnet-4-20250514` | –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è (–≤–µ—Ä—Å–∏—è) | ~1.3 |
| `claude-haiku-4-5` | –ë—ã—Å—Ç—Ä–∞—è –º–æ–¥–µ–ª—å | ~0.4 |
| `claude-3-7-sonnet-20250219` | Legacy –º–æ–¥–µ–ª—å | ~1.0 |

## 6. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è (.env)

```env
# –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ
REFRESH_TOKEN="your_kiro_refresh_token"
PROXY_API_KEY="your_proxy_secret"

# –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ
PROFILE_ARN="arn:aws:codewhisperer:..."
KIRO_REGION="us-east-1"
KIRO_CREDS_FILE="~/.aws/sso/cache/kiro-auth-token.json"

# –û—Ç–ª–∞–¥–∫–∞
DEBUG_LAST_REQUEST="false"
DEBUG_DIR="debug_logs"

# –õ–∏–º–∏—Ç—ã
TOOL_DESCRIPTION_MAX_LENGTH="10000"
```

### JSON —Ñ–∞–π–ª credentials (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

```json
{
  "accessToken": "eyJ...",
  "refreshToken": "eyJ...",
  "expiresAt": "2025-01-12T23:00:00.000Z",
  "profileArn": "arn:aws:codewhisperer:us-east-1:...",
  "region": "us-east-1"
}
```

## 7. API Endpoints

| Endpoint | –ú–µ—Ç–æ–¥ | –û–ø–∏—Å–∞–Ω–∏–µ |
|----------|-------|----------|
| `/` | GET | Health check |
| `/health` | GET | –î–µ—Ç–∞–ª—å–Ω—ã–π health check |
| `/v1/models` | GET | –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π |
| `/v1/chat/completions` | POST | Chat completions (streaming/non-streaming) |

## 8. –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –†–µ–∞–ª–∏–∑–∞—Ü–∏–∏

### Tool Calling

–ü–æ–¥–¥–µ—Ä–∂–∫–∞ OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ tools:

```json
{
  "tools": [{
    "type": "function",
    "function": {
      "name": "get_weather",
      "description": "Get weather for a location",
      "parameters": {
        "type": "object",
        "properties": {
          "location": {"type": "string"}
        }
      }
    }
  }]
}
```

### Streaming

–ü–æ–ª–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ SSE streaming —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º —Ñ–æ—Ä–º–∞—Ç–æ–º OpenAI:

```
data: {"id":"chatcmpl-...","object":"chat.completion.chunk",...}

data: [DONE]
```

### –û—Ç–ª–∞–¥–∫–∞

–ü—Ä–∏ `DEBUG_LAST_REQUEST=true` –≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã –∏ –æ—Ç–≤–µ—Ç—ã –ª–æ–≥–∏—Ä—É—é—Ç—Å—è –≤ `debug_logs/`:
- `request_body.json` ‚Äî –≤—Ö–æ–¥—è—â–∏–π –∑–∞–ø—Ä–æ—Å
- `kiro_request_body.json` ‚Äî –∑–∞–ø—Ä–æ—Å –∫ Kiro API
- `response_stream_raw.txt` ‚Äî —Å—ã—Ä–æ–π –ø–æ—Ç–æ–∫ –æ—Ç Kiro
- `response_stream_modified.txt` ‚Äî –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–π –ø–æ—Ç–æ–∫

## 9. –†–∞—Å—à–∏—Ä—è–µ–º–æ—Å—Ç—å

### –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞

–ú–æ–¥—É–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ª–µ–≥–∫–æ –¥–æ–±–∞–≤–∏—Ç—å –ø–æ–¥–¥–µ—Ä–∂–∫—É –¥—Ä—É–≥–∏—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤:

1. –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π –º–æ–¥—É–ª—å `kiro_gateway/providers/new_provider.py`
2. –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∫–ª–∞—Å—Å—ã:
   - `NewProviderAuthManager` ‚Äî —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞–º–∏
   - `NewProviderConverter` ‚Äî –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–æ–≤
   - `NewProviderParser` ‚Äî –ø–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–æ–≤
3. –î–æ–±–∞–≤–∏—Ç—å —Ä–æ—É—Ç—ã –≤ `routes.py` –∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ä–æ—É—Ç–µ—Ä

### –ü—Ä–∏–º–µ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–ª—è –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞

```python
# kiro_gateway/providers/gemini.py

class GeminiAuthManager:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ API –∫–ª—é—á–∞–º–∏ Gemini."""
    pass

class GeminiConverter:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è OpenAI -> Gemini —Ñ–æ—Ä–º–∞—Ç."""
    pass

class GeminiParser:
    """–ü–∞—Ä—Å–∏–Ω–≥ SSE –ø–æ—Ç–æ–∫–∞ Gemini."""
    pass
```

## 10. –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

–û—Å–Ω–æ–≤–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –ø—Ä–æ–µ–∫—Ç–∞ (–∏–∑ `requirements.txt`):

| –ü–∞–∫–µ—Ç | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ |
|-------|------------|
| `fastapi` | –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤–µ–±-—Ñ—Ä–µ–π–º–≤–æ—Ä–∫ |
| `uvicorn` | ASGI —Å–µ—Ä–≤–µ—Ä |
| `httpx` | –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π HTTP –∫–ª–∏–µ–Ω—Ç |
| `pydantic` | –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –∏ –º–æ–¥–µ–ª–∏ |
| `python-dotenv` | –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è |
| `loguru` | –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ |
| `tiktoken` | –ë—ã—Å—Ç—Ä—ã–π –ø–æ–¥—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤ |



================================================
FILE: kiro_gateway/__init__.py
================================================
# -*- coding: utf-8 -*-

# Kiro OpenAI Gateway
# Copyright (C) 2025 Jwadow
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

"""
Kiro Gateway - OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π –ø—Ä–æ–∫—Å–∏ –¥–ª—è Kiro API.

–≠—Ç–æ—Ç –ø–∞–∫–µ—Ç –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –º–æ–¥—É–ª—å–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –¥–ª—è –ø—Ä–æ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏—è
–∑–∞–ø—Ä–æ—Å–æ–≤ OpenAI API –∫ Kiro (AWS CodeWhisperer).

–ú–æ–¥—É–ª–∏:
    - config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã
    - models: Pydantic –º–æ–¥–µ–ª–∏ –¥–ª—è OpenAI API
    - auth: –ú–µ–Ω–µ–¥–∂–µ—Ä –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ Kiro
    - cache: –ö—ç—à –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
    - utils: –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —É—Ç–∏–ª–∏—Ç—ã
    - converters: –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è OpenAI <-> Kiro —Ñ–æ—Ä–º–∞—Ç–æ–≤
    - parsers: –ü–∞—Ä—Å–µ—Ä—ã AWS SSE –ø–æ—Ç–æ–∫–æ–≤
    - streaming: –õ–æ–≥–∏–∫–∞ —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–æ–≤
    - http_client: HTTP –∫–ª–∏–µ–Ω—Ç —Å retry –ª–æ–≥–∏–∫–æ–π
    - routes: FastAPI —Ä–æ—É—Ç—ã
    - exceptions: –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∏—Å–∫–ª—é—á–µ–Ω–∏–π
"""

# –í–µ—Ä—Å–∏—è –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç—Å—è –∏–∑ config.py ‚Äî –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –∏—Å—Ç–∏–Ω—ã (Single Source of Truth)
# –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–µ–Ω—è—Ç—å –≤–µ—Ä—Å–∏—é —Ç–æ–ª—å–∫–æ –≤ –æ–¥–Ω–æ–º –º–µ—Å—Ç–µ
from kiro_gateway.config import APP_VERSION as __version__

__author__ = "Jwadow"

# –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞
from kiro_gateway.auth import KiroAuthManager
from kiro_gateway.cache import ModelInfoCache
from kiro_gateway.http_client import KiroHttpClient
from kiro_gateway.routes import router

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
from kiro_gateway.config import (
    PROXY_API_KEY,
    REGION,
    MODEL_MAPPING,
    AVAILABLE_MODELS,
    APP_VERSION,
)

# –ú–æ–¥–µ–ª–∏
from kiro_gateway.models import (
    ChatCompletionRequest,
    ChatMessage,
    OpenAIModel,
    ModelList,
)

# –ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä—ã
from kiro_gateway.converters import (
    build_kiro_payload,
    extract_text_content,
    merge_adjacent_messages,
)

# –ü–∞—Ä—Å–µ—Ä—ã
from kiro_gateway.parsers import (
    AwsEventStreamParser,
    parse_bracket_tool_calls,
)

# Streaming
from kiro_gateway.streaming import (
    stream_kiro_to_openai,
    collect_stream_response,
)

# Exceptions
from kiro_gateway.exceptions import (
    validation_exception_handler,
    sanitize_validation_errors,
)

__all__ = [
    # –í–µ—Ä—Å–∏—è
    "__version__",
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –∫–ª–∞—Å—Å—ã
    "KiroAuthManager",
    "ModelInfoCache",
    "KiroHttpClient",
    "router",
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    "PROXY_API_KEY",
    "REGION",
    "MODEL_MAPPING",
    "AVAILABLE_MODELS",
    "APP_VERSION",
    
    # –ú–æ–¥–µ–ª–∏
    "ChatCompletionRequest",
    "ChatMessage",
    "OpenAIModel",
    "ModelList",
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä—ã
    "build_kiro_payload",
    "extract_text_content",
    "merge_adjacent_messages",
    
    # –ü–∞—Ä—Å–µ—Ä—ã
    "AwsEventStreamParser",
    "parse_bracket_tool_calls",
    
    # Streaming
    "stream_kiro_to_openai",
    "collect_stream_response",
    
    # Exceptions
    "validation_exception_handler",
    "sanitize_validation_errors",
]


================================================
FILE: kiro_gateway/auth.py
================================================
# -*- coding: utf-8 -*-

# Kiro OpenAI Gateway
# https://github.com/jwadow/kiro-openai-gateway
# Copyright (C) 2025 Jwadow
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

"""
Authentication manager for Kiro API.

Manages the lifecycle of access tokens:
- Loading credentials from .env or JSON file
- Automatic token refresh on expiration
- Thread-safe refresh using asyncio.Lock
"""

import asyncio
import json
from datetime import datetime, timezone
from pathlib import Path
from typing import Optional

import httpx
from loguru import logger

from kiro_gateway.config import (
    TOKEN_REFRESH_THRESHOLD,
    get_kiro_refresh_url,
    get_kiro_api_host,
    get_kiro_q_host,
)
from kiro_gateway.utils import get_machine_fingerprint


class KiroAuthManager:
    """
    Manages the token lifecycle for accessing Kiro API.
    
    Supports:
    - Loading credentials from .env or JSON file
    - Automatic token refresh on expiration
    - Expiration time validation (expiresAt)
    - Saving updated tokens to file
    
    Attributes:
        profile_arn: AWS CodeWhisperer profile ARN
        region: AWS region
        api_host: API host for the current region
        q_host: Q API host for the current region
        fingerprint: Unique machine fingerprint
    
    Example:
        >>> auth_manager = KiroAuthManager(
        ...     refresh_token="your_refresh_token",
        ...     region="us-east-1"
        ... )
        >>> token = await auth_manager.get_access_token()
    """
    
    def __init__(
        self,
        refresh_token: Optional[str] = None,
        profile_arn: Optional[str] = None,
        region: str = "us-east-1",
        creds_file: Optional[str] = None
    ):
        """
        Initializes the authentication manager.
        
        Args:
            refresh_token: Refresh token for obtaining access token
            profile_arn: AWS CodeWhisperer profile ARN
            region: AWS region (default: us-east-1)
            creds_file: Path to JSON file with credentials (optional)
        """
        self._refresh_token = refresh_token
        self._profile_arn = profile_arn
        self._region = region
        self._creds_file = creds_file
        
        self._access_token: Optional[str] = None
        self._expires_at: Optional[datetime] = None
        self._lock = asyncio.Lock()
        
        # Dynamic URLs based on region
        self._refresh_url = get_kiro_refresh_url(region)
        self._api_host = get_kiro_api_host(region)
        self._q_host = get_kiro_q_host(region)
        
        # Fingerprint for User-Agent
        self._fingerprint = get_machine_fingerprint()
        
        # Load credentials from file if specified
        if creds_file:
            self._load_credentials_from_file(creds_file)
    
    def _load_credentials_from_file(self, file_path: str) -> None:
        """
        Loads credentials from a JSON file.
        
        Supported JSON fields:
        - refreshToken: Refresh token
        - accessToken: Access token (if already available)
        - profileArn: Profile ARN
        - region: AWS region
        - expiresAt: Token expiration time (ISO 8601)
        
        Args:
            file_path: Path to JSON file
        """
        try:
            path = Path(file_path).expanduser()
            if not path.exists():
                logger.warning(f"Credentials file not found: {file_path}")
                return
            
            with open(path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # Load data from file
            if 'refreshToken' in data:
                self._refresh_token = data['refreshToken']
            if 'accessToken' in data:
                self._access_token = data['accessToken']
            if 'profileArn' in data:
                self._profile_arn = data['profileArn']
            if 'region' in data:
                self._region = data['region']
                # Update URLs for new region
                self._refresh_url = get_kiro_refresh_url(self._region)
                self._api_host = get_kiro_api_host(self._region)
                self._q_host = get_kiro_q_host(self._region)
            
            # Parse expiresAt
            if 'expiresAt' in data:
                try:
                    expires_str = data['expiresAt']
                    # Support for different date formats
                    if expires_str.endswith('Z'):
                        self._expires_at = datetime.fromisoformat(expires_str.replace('Z', '+00:00'))
                    else:
                        self._expires_at = datetime.fromisoformat(expires_str)
                except Exception as e:
                    logger.warning(f"Failed to parse expiresAt: {e}")
            
            logger.info(f"Credentials loaded from {file_path}")
            
        except Exception as e:
            logger.error(f"Error loading credentials from file: {e}")
    
    def _save_credentials_to_file(self) -> None:
        """
        Saves updated credentials to a JSON file.
        
        Updates the existing file while preserving other fields.
        """
        if not self._creds_file:
            return
        
        try:
            path = Path(self._creds_file).expanduser()
            
            # Read existing data
            existing_data = {}
            if path.exists():
                with open(path, 'r', encoding='utf-8') as f:
                    existing_data = json.load(f)
            
            # Update data
            existing_data['accessToken'] = self._access_token
            existing_data['refreshToken'] = self._refresh_token
            if self._expires_at:
                existing_data['expiresAt'] = self._expires_at.isoformat()
            if self._profile_arn:
                existing_data['profileArn'] = self._profile_arn
            
            # Save
            with open(path, 'w', encoding='utf-8') as f:
                json.dump(existing_data, f, indent=2, ensure_ascii=False)
            
            logger.debug(f"Credentials saved to {self._creds_file}")
            
        except Exception as e:
            logger.error(f"Error saving credentials: {e}")
    
    def is_token_expiring_soon(self) -> bool:
        """
        Checks if the token is expiring soon.
        
        Returns:
            True if the token expires within TOKEN_REFRESH_THRESHOLD seconds
            or if expiration time information is not available
        """
        if not self._expires_at:
            return True  # If no expiration info available, assume refresh is needed
        
        now = datetime.now(timezone.utc)
        threshold = now.timestamp() + TOKEN_REFRESH_THRESHOLD
        
        return self._expires_at.timestamp() <= threshold
    
    async def _refresh_token_request(self) -> None:
        """
        Performs a token refresh request.
        
        Sends a POST request to Kiro API to obtain a new access token.
        Updates internal state and saves credentials to file.
        
        Raises:
            ValueError: If refresh token is not set or response doesn't contain accessToken
            httpx.HTTPError: On HTTP request error
        """
        if not self._refresh_token:
            raise ValueError("Refresh token is not set")
        
        logger.info("Refreshing Kiro token...")
        
        payload = {'refreshToken': self._refresh_token}
        headers = {
            "Content-Type": "application/json",
            "User-Agent": f"KiroIDE-0.7.45-{self._fingerprint}",
        }
        
        async with httpx.AsyncClient(timeout=30) as client:
            response = await client.post(self._refresh_url, json=payload, headers=headers)
            response.raise_for_status()
            data = response.json()
        
        new_access_token = data.get("accessToken")
        new_refresh_token = data.get("refreshToken")
        expires_in = data.get("expiresIn", 3600)
        new_profile_arn = data.get("profileArn")
        
        if not new_access_token:
            raise ValueError(f"Response does not contain accessToken: {data}")
        
        # Update data
        self._access_token = new_access_token
        if new_refresh_token:
            self._refresh_token = new_refresh_token
        if new_profile_arn:
            self._profile_arn = new_profile_arn
        
        # Calculate expiration time with buffer (minus 60 seconds)
        self._expires_at = datetime.now(timezone.utc).replace(microsecond=0)
        self._expires_at = datetime.fromtimestamp(
            self._expires_at.timestamp() + expires_in - 60,
            tz=timezone.utc
        )
        
        logger.info(f"Token refreshed, expires: {self._expires_at.isoformat()}")
        
        # Save to file
        self._save_credentials_to_file()
    
    async def get_access_token(self) -> str:
        """
        Returns a valid access_token, refreshing it if necessary.
        
        Thread-safe method using asyncio.Lock.
        Automatically refreshes the token if it has expired or is about to expire.
        
        Returns:
            Valid access token
        
        Raises:
            ValueError: If unable to obtain access token
        """
        async with self._lock:
            if not self._access_token or self.is_token_expiring_soon():
                await self._refresh_token_request()
            
            if not self._access_token:
                raise ValueError("Failed to obtain access token")
            
            return self._access_token
    
    async def force_refresh(self) -> str:
        """
        Forces a token refresh.
        
        Used when receiving a 403 error from the API.
        
        Returns:
            New access token
        """
        async with self._lock:
            await self._refresh_token_request()
            return self._access_token
    
    @property
    def profile_arn(self) -> Optional[str]:
        """AWS CodeWhisperer profile ARN."""
        return self._profile_arn
    
    @property
    def region(self) -> str:
        """AWS region."""
        return self._region
    
    @property
    def api_host(self) -> str:
        """API host for the current region."""
        return self._api_host
    
    @property
    def q_host(self) -> str:
        """Q API host for the current region."""
        return self._q_host
    
    @property
    def fingerprint(self) -> str:
        """Unique machine fingerprint."""
        return self._fingerprint


================================================
FILE: kiro_gateway/cache.py
================================================
# -*- coding: utf-8 -*-

# Kiro OpenAI Gateway
# Copyright (C) 2025 Jwadow
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

"""
–ö—ç—à –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è Kiro Gateway.

–ü–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö
—Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π TTL –∏ lazy loading.
"""

import asyncio
import time
from typing import Any, Dict, List, Optional

from loguru import logger

from kiro_gateway.config import MODEL_CACHE_TTL, DEFAULT_MAX_INPUT_TOKENS


class ModelInfoCache:
    """
    –ü–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω—ã–π –∫—ç—à –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –æ –º–æ–¥–µ–ª—è—Ö.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Lazy Loading –¥–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è - –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è
    —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∏–ª–∏ –∫–æ–≥–¥–∞ –∫—ç—à —É—Å—Ç–∞—Ä–µ–ª.
    
    Attributes:
        cache_ttl: –í—Ä–µ–º—è –∂–∏–∑–Ω–∏ –∫—ç—à–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
    
    Example:
        >>> cache = ModelInfoCache()
        >>> await cache.update([{"modelId": "claude-sonnet-4", "tokenLimits": {...}}])
        >>> info = cache.get("claude-sonnet-4")
        >>> max_tokens = cache.get_max_input_tokens("claude-sonnet-4")
    """
    
    def __init__(self, cache_ttl: int = MODEL_CACHE_TTL):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫—ç—à –º–æ–¥–µ–ª–µ–π.
        
        Args:
            cache_ttl: –í—Ä–µ–º—è –∂–∏–∑–Ω–∏ –∫—ç—à–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞)
        """
        self._cache: Dict[str, Dict[str, Any]] = {}
        self._lock = asyncio.Lock()
        self._last_update: Optional[float] = None
        self._cache_ttl = cache_ttl
    
    async def update(self, models_data: List[Dict[str, Any]]) -> None:
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç –∫—ç—à –º–æ–¥–µ–ª–µ–π.
        
        –ü–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ –∑–∞–º–µ–Ω—è–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∫—ç—à–∞ –Ω–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏.
        
        Args:
            models_data: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –º–æ–¥–µ–ª—è—Ö.
                        –ö–∞–∂–¥—ã–π —Å–ª–æ–≤–∞—Ä—å –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–ª—é—á "modelId".
        """
        async with self._lock:
            logger.info(f"Updating model cache. Found {len(models_data)} models.")
            self._cache = {model["modelId"]: model for model in models_data}
            self._last_update = time.time()
    
    def get(self, model_id: str) -> Optional[Dict[str, Any]]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏.
        
        Args:
            model_id: ID –º–æ–¥–µ–ª–∏
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –º–æ–¥–µ–ª–∏ –∏–ª–∏ None –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞
        """
        return self._cache.get(model_id)
    
    def get_max_input_tokens(self, model_id: str) -> int:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç maxInputTokens –¥–ª—è –º–æ–¥–µ–ª–∏.
        
        Args:
            model_id: ID –º–æ–¥–µ–ª–∏
        
        Returns:
            –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ input —Ç–æ–∫–µ–Ω–æ–≤ –∏–ª–∏ DEFAULT_MAX_INPUT_TOKENS
        """
        model = self._cache.get(model_id)
        if model and model.get("tokenLimits"):
            return model["tokenLimits"].get("maxInputTokens") or DEFAULT_MAX_INPUT_TOKENS
        return DEFAULT_MAX_INPUT_TOKENS
    
    def is_empty(self) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø—É—Å—Ç –ª–∏ –∫—ç—à.
        
        Returns:
            True –µ—Å–ª–∏ –∫—ç—à –ø—É—Å—Ç
        """
        return not self._cache
    
    def is_stale(self) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —É—Å—Ç–∞—Ä–µ–ª –ª–∏ –∫—ç—à.
        
        Returns:
            True –µ—Å–ª–∏ –∫—ç—à —É—Å—Ç–∞—Ä–µ–ª (–ø—Ä–æ—à–ª–æ –±–æ–ª—å—à–µ cache_ttl —Å–µ–∫—É–Ω–¥)
            –∏–ª–∏ –µ—Å–ª–∏ –∫—ç—à –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –æ–±–Ω–æ–≤–ª—è–ª—Å—è
        """
        if not self._last_update:
            return True
        return time.time() - self._last_update > self._cache_ttl
    
    def get_all_model_ids(self) -> List[str]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö ID –º–æ–¥–µ–ª–µ–π –≤ –∫—ç—à–µ.
        
        Returns:
            –°–ø–∏—Å–æ–∫ ID –º–æ–¥–µ–ª–µ–π
        """
        return list(self._cache.keys())
    
    @property
    def size(self) -> int:
        """–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π –≤ –∫—ç—à–µ."""
        return len(self._cache)
    
    @property
    def last_update_time(self) -> Optional[float]:
        """–í—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è (timestamp) –∏–ª–∏ None."""
        return self._last_update


================================================
FILE: kiro_gateway/config.py
================================================
# -*- coding: utf-8 -*-

# Kiro OpenAI Gateway
# https://github.com/jwadow/kiro-openai-gateway
# Copyright (C) 2025 Jwadow
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

"""
Kiro Gateway Configuration.

Centralized storage for all settings, constants, and mappings.
Loads environment variables and provides typed access to them.
"""

import os
import re
from pathlib import Path
from typing import Dict, List, Optional
from dotenv import load_dotenv

# Load environment variables
load_dotenv()


def _get_raw_env_value(var_name: str, env_file: str = ".env") -> Optional[str]:
    """
    Read variable value from .env file without processing escape sequences.
    
    This is necessary for correct handling of Windows paths where backslashes
    (e.g., D:\\Projects\\file.json) may be incorrectly interpreted
    as escape sequences (\\a -> bell, \\n -> newline, etc.).
    
    Args:
        var_name: Environment variable name
        env_file: Path to .env file (default ".env")
    
    Returns:
        Raw variable value or None if not found
    """
    env_path = Path(env_file)
    if not env_path.exists():
        return None
    
    try:
        # Read file as-is, without interpretation
        content = env_path.read_text(encoding="utf-8")
        
        # Search for variable considering different formats:
        # VAR="value" or VAR='value' or VAR=value
        # Pattern captures value with or without quotes
        pattern = rf'^{re.escape(var_name)}=(["\']?)(.+?)\1\s*$'
        
        for line in content.splitlines():
            line = line.strip()
            if line.startswith("#") or not line:
                continue
            
            match = re.match(pattern, line)
            if match:
                # Return value as-is, without processing escape sequences
                return match.group(2)
    except Exception:
        pass
    
    return None

# ==================================================================================================
# Proxy Server Settings
# ==================================================================================================

# API key for proxy access (clients must pass it in Authorization header)
PROXY_API_KEY: str = os.getenv("PROXY_API_KEY", "changeme_proxy_secret")

# ==================================================================================================
# Kiro API Credentials
# ==================================================================================================

# Refresh token for updating access token
REFRESH_TOKEN: str = os.getenv("REFRESH_TOKEN", "")

# Profile ARN for AWS CodeWhisperer
PROFILE_ARN: str = os.getenv("PROFILE_ARN", "")

# AWS region (default us-east-1)
REGION: str = os.getenv("KIRO_REGION", "us-east-1")

# Path to credentials file (optional, alternative to .env)
# Read directly from .env to avoid escape sequence issues on Windows
# (e.g., \a in path D:\Projects\adolf is interpreted as bell character)
_raw_creds_file = _get_raw_env_value("KIRO_CREDS_FILE") or os.getenv("KIRO_CREDS_FILE", "")
# Normalize path for cross-platform compatibility
KIRO_CREDS_FILE: str = str(Path(_raw_creds_file)) if _raw_creds_file else ""

# ==================================================================================================
# Kiro API URL Templates
# ==================================================================================================

# URL for token refresh
KIRO_REFRESH_URL_TEMPLATE: str = "https://prod.{region}.auth.desktop.kiro.dev/refreshToken"

# Host for main API (generateAssistantResponse)
KIRO_API_HOST_TEMPLATE: str = "https://codewhisperer.{region}.amazonaws.com"

# Host for Q API (ListAvailableModels)
KIRO_Q_HOST_TEMPLATE: str = "https://q.{region}.amazonaws.com"

# ==================================================================================================
# Token Settings
# ==================================================================================================

# Time before token expiration when refresh is needed (in seconds)
# Default 10 minutes - refresh token in advance to avoid errors
TOKEN_REFRESH_THRESHOLD: int = 600

# ==================================================================================================
# Retry Configuration
# ==================================================================================================

# Maximum number of retry attempts on errors
MAX_RETRIES: int = 3

# Base delay between attempts (seconds)
# Uses exponential backoff: delay * (2 ** attempt)
BASE_RETRY_DELAY: float = 1.0

# ==================================================================================================
# Model Mapping
# ==================================================================================================

# External model names (OpenAI-compatible) -> internal Kiro IDs
# Clients use external names, and we convert them to internal ones
MODEL_MAPPING: Dict[str, str] = {
    # Claude Opus 4.5 - top-tier model
    "claude-opus-4-5": "claude-opus-4.5",
    "claude-opus-4-5-20251101": "claude-opus-4.5",
    
    # Claude Haiku 4.5 - fast model
    "claude-haiku-4-5": "claude-haiku-4.5",
    "claude-haiku-4.5": "claude-haiku-4.5",  # Direct passthrough
    
    # Claude Sonnet 4.5 - enhanced model
    "claude-sonnet-4-5": "CLAUDE_SONNET_4_5_20250929_V1_0",
    "claude-sonnet-4-5-20250929": "CLAUDE_SONNET_4_5_20250929_V1_0",
    
    # Claude Sonnet 4 - balanced model
    "claude-sonnet-4": "CLAUDE_SONNET_4_20250514_V1_0",
    "claude-sonnet-4-20250514": "CLAUDE_SONNET_4_20250514_V1_0",
    
    # Claude 3.7 Sonnet - legacy model
    "claude-3-7-sonnet-20250219": "CLAUDE_3_7_SONNET_20250219_V1_0",
    
    # Aliases for convenience
    "auto": "claude-sonnet-4.5",
}

# List of available models for /v1/models endpoint
# These models will be displayed to clients as available
AVAILABLE_MODELS: List[str] = [
    "claude-opus-4-5",
    "claude-opus-4-5-20251101",
    "claude-haiku-4-5",
    "claude-sonnet-4-5",
    "claude-sonnet-4-5-20250929",
    "claude-sonnet-4",
    "claude-sonnet-4-20250514",
    "claude-3-7-sonnet-20250219",
]

# ==================================================================================================
# Model Cache Settings
# ==================================================================================================

# Model cache TTL in seconds (1 hour)
MODEL_CACHE_TTL: int = 3600

# Default maximum number of input tokens
DEFAULT_MAX_INPUT_TOKENS: int = 200000

# ==================================================================================================
# Tool Description Handling (Kiro API Limitations)
# ==================================================================================================

# Kiro API –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—à–∏–±–∫—É 400 "Improperly formed request" –ø—Ä–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã—Ö
# –æ–ø–∏—Å–∞–Ω–∏—è—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –≤ toolSpecification.description.
#
# –†–µ—à–µ–Ω–∏–µ: Tool Documentation Reference Pattern
# - –ï—Å–ª–∏ description ‚â§ –ª–∏–º–∏—Ç–∞ ‚Üí –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
# - –ï—Å–ª–∏ description > –ª–∏–º–∏—Ç–∞:
#   * –í toolSpecification.description ‚Üí —Å—Å—ã–ª–∫–∞ –Ω–∞ system prompt:
#     "[Full documentation in system prompt under '## Tool: {name}']"
#   * –í system prompt –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è —Å–µ–∫—Ü–∏—è "## Tool: {name}" —Å –ø–æ–ª–Ω—ã–º –æ–ø–∏—Å–∞–Ω–∏–µ–º
#
# –ú–æ–¥–µ–ª—å –≤–∏–¥–∏—Ç —è–≤–Ω—É—é —Å—Å—ã–ª–∫—É –∏ —Ç–æ—á–Ω–æ –ø–æ–Ω–∏–º–∞–µ—Ç, –≥–¥–µ –∏—Å–∫–∞—Ç—å –ø–æ–ª–Ω—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é.

# –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ description –¥–ª—è tool –≤ —Å–∏–º–≤–æ–ª–∞—Ö.
# –û–ø–∏—Å–∞–Ω–∏—è –¥–ª–∏–Ω–Ω–µ–µ —ç—Ç–æ–≥–æ –ª–∏–º–∏—Ç–∞ –±—É–¥—É—Ç –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω—ã –≤ system prompt.
# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ 0 –¥–ª—è –æ—Ç–∫–ª—é—á–µ–Ω–∏—è (–Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è - –≤—ã–∑–æ–≤–µ—Ç –æ—à–∏–±–∫–∏ Kiro API).
TOOL_DESCRIPTION_MAX_LENGTH: int = int(os.getenv("TOOL_DESCRIPTION_MAX_LENGTH", "10000"))

# ==================================================================================================
# Logging Settings
# ==================================================================================================

# Log level for the application
# Available levels: TRACE, DEBUG, INFO, WARNING, ERROR, CRITICAL
# Default: INFO (recommended for production)
# Set to DEBUG for detailed troubleshooting
LOG_LEVEL: str = os.getenv("LOG_LEVEL", "INFO").upper()

# ==================================================================================================
# First Token Timeout Settings (Streaming Retry)
# ==================================================================================================

# Timeout for waiting for the first token from the model (in seconds).
# If the model doesn't respond within this time, the request will be cancelled and retried.
# This helps handle "stuck" requests when the model takes too long to think.
# Default: 30 seconds (recommended for production)
# Set a lower value (e.g., 10-15) for more aggressive retry.
FIRST_TOKEN_TIMEOUT: float = float(os.getenv("FIRST_TOKEN_TIMEOUT", "15"))

# Read timeout for streaming responses (in seconds).
# This is the maximum time to wait for data between chunks during streaming.
# Should be longer than FIRST_TOKEN_TIMEOUT since the model may pause between chunks
# while "thinking" (especially for tool calls or complex reasoning).
# Default: 300 seconds (5 minutes) - generous timeout to avoid premature disconnects.
STREAMING_READ_TIMEOUT: float = float(os.getenv("STREAMING_READ_TIMEOUT", "300"))

# Maximum number of attempts on first token timeout.
# After exhausting all attempts, an error will be returned.
# Default: 3 attempts
FIRST_TOKEN_MAX_RETRIES: int = int(os.getenv("FIRST_TOKEN_MAX_RETRIES", "3"))

# ==================================================================================================
# Debug Settings
# ==================================================================================================

# Legacy option (deprecated, will be removed in future releases)
# Use DEBUG_MODE instead
_DEBUG_LAST_REQUEST_RAW: str = os.getenv("DEBUG_LAST_REQUEST", "").lower()
DEBUG_LAST_REQUEST: bool = _DEBUG_LAST_REQUEST_RAW in ("true", "1", "yes")

# Debug logging mode:
# - off: disabled (default)
# - errors: save logs only for failed requests (4xx, 5xx)
# - all: save logs for every request (overwrites on each request)
_DEBUG_MODE_RAW: str = os.getenv("DEBUG_MODE", "").lower()

# Priority logic:
# 1. If DEBUG_MODE is explicitly set ‚Üí use it
# 2. If DEBUG_MODE is not set but DEBUG_LAST_REQUEST=true ‚Üí mode "all" (backward compatibility)
# 3. Otherwise ‚Üí mode "off"
if _DEBUG_MODE_RAW in ("off", "errors", "all"):
    DEBUG_MODE: str = _DEBUG_MODE_RAW
elif DEBUG_LAST_REQUEST:
    DEBUG_MODE: str = "all"
else:
    DEBUG_MODE: str = "off"

# Directory for debug log files
DEBUG_DIR: str = os.getenv("DEBUG_DIR", "debug_logs")


def _warn_deprecated_debug_setting():
    """
    Print warning if deprecated DEBUG_LAST_REQUEST is used.
    Called at application startup.
    """
    if _DEBUG_LAST_REQUEST_RAW and not _DEBUG_MODE_RAW:
        import sys
        # ANSI escape codes: yellow text
        YELLOW = "\033[93m"
        RESET = "\033[0m"
        
        warning_text = f"""
{YELLOW}‚ö†Ô∏è  DEPRECATED: DEBUG_LAST_REQUEST will be removed in future releases.
    Please use DEBUG_MODE instead:
      - DEBUG_MODE=off     (disabled, default)
      - DEBUG_MODE=errors  (save logs only for failed requests)
      - DEBUG_MODE=all     (save logs for every request)
    
    DEBUG_LAST_REQUEST=true is equivalent to DEBUG_MODE=all
    See .env.example for more details.{RESET}
"""
        print(warning_text, file=sys.stderr)


def _warn_timeout_configuration():
    """
    Print warning if timeout configuration is suboptimal.
    Called at application startup.
    
    FIRST_TOKEN_TIMEOUT should be less than STREAMING_READ_TIMEOUT:
    - FIRST_TOKEN_TIMEOUT: time to wait for model to START responding
    - STREAMING_READ_TIMEOUT: time to wait BETWEEN chunks during streaming
    """
    if FIRST_TOKEN_TIMEOUT >= STREAMING_READ_TIMEOUT:
        import sys
        YELLOW = "\033[93m"
        RESET = "\033[0m"
        
        warning_text = f"""
{YELLOW}‚ö†Ô∏è  WARNING: Suboptimal timeout configuration detected.
    
    FIRST_TOKEN_TIMEOUT ({FIRST_TOKEN_TIMEOUT}s) >= STREAMING_READ_TIMEOUT ({STREAMING_READ_TIMEOUT}s)
    
    These timeouts serve different purposes:
      - FIRST_TOKEN_TIMEOUT: time to wait for model to START responding (default: 15s)
      - STREAMING_READ_TIMEOUT: time to wait BETWEEN chunks during streaming (default: 300s)
    
    Recommendation: FIRST_TOKEN_TIMEOUT should be LESS than STREAMING_READ_TIMEOUT.
    
    Example configuration:
      FIRST_TOKEN_TIMEOUT=15
      STREAMING_READ_TIMEOUT=300{RESET}
"""
        print(warning_text, file=sys.stderr)

# ==================================================================================================
# Application Version
# ==================================================================================================

APP_VERSION: str = "1.0.7"
APP_TITLE: str = "Kiro API Gateway"
APP_DESCRIPTION: str = "OpenAI-compatible interface for Kiro API (AWS CodeWhisperer). Made by @jwadow"


def get_kiro_refresh_url(region: str) -> str:
    """Return token refresh URL for the specified region."""
    return KIRO_REFRESH_URL_TEMPLATE.format(region=region)


def get_kiro_api_host(region: str) -> str:
    """Return API host for the specified region."""
    return KIRO_API_HOST_TEMPLATE.format(region=region)


def get_kiro_q_host(region: str) -> str:
    """Return Q API host for the specified region."""
    return KIRO_Q_HOST_TEMPLATE.format(region=region)


def get_internal_model_id(external_model: str) -> str:
    """
    Convert external model name to internal Kiro ID.
    
    Args:
        external_model: External model name (e.g., "claude-sonnet-4-5")
    
    Returns:
        Internal model ID for Kiro API
    """
    return MODEL_MAPPING.get(external_model, external_model)


================================================
FILE: kiro_gateway/converters.py
================================================
# -*- coding: utf-8 -*-

# Kiro OpenAI Gateway
# Copyright (C) 2025 Jwadow
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

"""
–ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä—ã –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ñ–æ—Ä–º–∞—Ç–æ–≤ OpenAI <-> Kiro.

–°–æ–¥–µ—Ä–∂–∏—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è:
- –ò–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤
- –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Å–æ—Å–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
- –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –¥–ª—è Kiro API
- –°–±–æ—Ä–∫–∏ –ø–æ–ª–Ω–æ–≥–æ payload –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
"""

import json
from typing import Any, Dict, List, Optional, Tuple

from loguru import logger

from kiro_gateway.config import get_internal_model_id, TOOL_DESCRIPTION_MAX_LENGTH
from kiro_gateway.models import ChatMessage, ChatCompletionRequest, Tool


def extract_text_content(content: Any) -> str:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤.
    
    OpenAI API –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–æ—Ä–º–∞—Ç–æ–≤ content:
    - –°—Ç—Ä–æ–∫–∞: "Hello, world!"
    - –°–ø–∏—Å–æ–∫: [{"type": "text", "text": "Hello"}]
    - None: –ø—É—Å—Ç–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    
    Args:
        content: –ö–æ–Ω—Ç–µ–Ω—Ç –≤ –ª—é–±–æ–º –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
    
    Returns:
        –ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–ª–∏ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
    
    Example:
        >>> extract_text_content("Hello")
        'Hello'
        >>> extract_text_content([{"type": "text", "text": "World"}])
        'World'
        >>> extract_text_content(None)
        ''
    """
    if content is None:
        return ""
    if isinstance(content, str):
        return content
    if isinstance(content, list):
        text_parts = []
        for item in content:
            if isinstance(item, dict):
                if item.get("type") == "text":
                    text_parts.append(item.get("text", ""))
                elif "text" in item:
                    text_parts.append(item["text"])
            elif isinstance(item, str):
                text_parts.append(item)
        return "".join(text_parts)
    return str(content)


def merge_adjacent_messages(messages: List[ChatMessage]) -> List[ChatMessage]:
    """
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç —Å–æ—Å–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Å –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π —Ä–æ–ª—å—é –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç tool messages.
    
    Kiro API –Ω–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ–¥—Ä—è–¥ –æ—Ç –æ–¥–Ω–æ–≥–æ role.
    –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç —Ç–∞–∫–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –æ–¥–Ω–æ.
    
    Tool messages (role="tool") –ø—Ä–µ–æ–±—Ä–∞–∑—É—é—Ç—Å—è –≤ user messages —Å tool_results.
    
    Args:
        messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
    
    Returns:
        –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π —Å –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–º–∏ —Å–æ—Å–µ–¥–Ω–∏–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏
    
    Example:
        >>> msgs = [
        ...     ChatMessage(role="user", content="Hello"),
        ...     ChatMessage(role="user", content="World")
        ... ]
        >>> merged = merge_adjacent_messages(msgs)
        >>> len(merged)
        1
        >>> merged[0].content
        'Hello\\nWorld'
    """
    if not messages:
        return []
    
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º tool messages –≤ user messages —Å tool_results
    processed = []
    pending_tool_results = []
    
    for msg in messages:
        if msg.role == "tool":
            # –°–æ–±–∏—Ä–∞–µ–º tool results
            tool_result = {
                "type": "tool_result",
                "tool_use_id": msg.tool_call_id or "",
                "content": extract_text_content(msg.content) or "(empty result)"
            }
            pending_tool_results.append(tool_result)
            logger.debug(f"Collected tool result for tool_call_id={msg.tool_call_id}")
        else:
            # –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ tool results, —Å–æ–∑–¥–∞—ë–º user message —Å –Ω–∏–º–∏
            if pending_tool_results:
                # –°–æ–∑–¥–∞—ë–º user message —Å tool_results
                tool_results_msg = ChatMessage(
                    role="user",
                    content=pending_tool_results.copy()
                )
                processed.append(tool_results_msg)
                pending_tool_results.clear()
                logger.debug(f"Created user message with {len(tool_results_msg.content)} tool results")
            
            processed.append(msg)
    
    # –ï—Å–ª–∏ –æ—Å—Ç–∞–ª–∏—Å—å tool results –≤ –∫–æ–Ω—Ü–µ
    if pending_tool_results:
        tool_results_msg = ChatMessage(
            role="user",
            content=pending_tool_results.copy()
        )
        processed.append(tool_results_msg)
        logger.debug(f"Created final user message with {len(pending_tool_results)} tool results")
    
    # –¢–µ–ø–µ—Ä—å –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Å–æ—Å–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Å –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π —Ä–æ–ª—å—é
    merged = []
    for msg in processed:
        if not merged:
            merged.append(msg)
            continue
        
        last = merged[-1]
        if msg.role == last.role:
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç
            # –ï—Å–ª–∏ –æ–±–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ - —Å–ø–∏—Å–∫–∏, –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Å–ø–∏—Å–∫–∏
            if isinstance(last.content, list) and isinstance(msg.content, list):
                last.content = last.content + msg.content
            elif isinstance(last.content, list):
                last.content = last.content + [{"type": "text", "text": extract_text_content(msg.content)}]
            elif isinstance(msg.content, list):
                last.content = [{"type": "text", "text": extract_text_content(last.content)}] + msg.content
            else:
                last_text = extract_text_content(last.content)
                current_text = extract_text_content(msg.content)
                last.content = f"{last_text}\n{current_text}"
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º tool_calls –¥–ª—è assistant —Å–æ–æ–±—â–µ–Ω–∏–π
            # –ö—Ä–∏—Ç–∏—á–Ω–æ: –±–µ–∑ —ç—Ç–æ–≥–æ —Ç–µ—Ä—è—é—Ç—Å—è tool_calls –∏–∑ –≤—Ç–æ—Ä–æ–≥–æ –∏ –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π,
            # —á—Ç–æ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –æ—à–∏–±–∫–µ 400 –æ—Ç Kiro API (toolResult –±–µ–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ toolUse)
            if msg.role == "assistant" and msg.tool_calls:
                if last.tool_calls is None:
                    last.tool_calls = []
                last.tool_calls = list(last.tool_calls) + list(msg.tool_calls)
                logger.debug(f"Merged tool_calls: added {len(msg.tool_calls)} tool calls, total now: {len(last.tool_calls)}")
            
            logger.debug(f"Merged adjacent messages with role {msg.role}")
        else:
            merged.append(msg)
    
    return merged


def build_kiro_history(messages: List[ChatMessage], model_id: str) -> List[Dict[str, Any]]:
    """
    –°—Ç—Ä–æ–∏—Ç –º–∞—Å—Å–∏–≤ history –¥–ª—è Kiro API –∏–∑ OpenAI messages.
    
    Kiro API –æ–∂–∏–¥–∞–µ—Ç —á–µ—Ä–µ–¥–æ–≤–∞–Ω–∏–µ userInputMessage –∏ assistantResponseMessage.
    –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç OpenAI —Ñ–æ—Ä–º–∞—Ç –≤ Kiro —Ñ–æ—Ä–º–∞—Ç.
    
    Args:
        messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI
        model_id: –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π ID –º–æ–¥–µ–ª–∏ Kiro
    
    Returns:
        –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π –¥–ª—è –ø–æ–ª—è history –≤ Kiro API
    
    Example:
        >>> msgs = [ChatMessage(role="user", content="Hello")]
        >>> history = build_kiro_history(msgs, "claude-sonnet-4")
        >>> history[0]["userInputMessage"]["content"]
        'Hello'
    """
    history = []
    
    for msg in messages:
        if msg.role == "user":
            content = extract_text_content(msg.content)
            
            user_input = {
                "content": content,
                "modelId": model_id,
                "origin": "AI_EDITOR",
            }
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ tool_results (–æ—Ç–≤–µ—Ç—ã –Ω–∞ tool calls)
            tool_results = _extract_tool_results(msg.content)
            if tool_results:
                user_input["userInputMessageContext"] = {"toolResults": tool_results}
            
            history.append({"userInputMessage": user_input})
            
        elif msg.role == "assistant":
            content = extract_text_content(msg.content)
            
            assistant_response = {"content": content}
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ tool_calls
            tool_uses = _extract_tool_uses(msg)
            if tool_uses:
                assistant_response["toolUses"] = tool_uses
            
            history.append({"assistantResponseMessage": assistant_response})
            
        elif msg.role == "system":
            # System prompt –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ –≤ build_kiro_payload
            pass
    
    return history


def _extract_tool_results(content: Any) -> List[Dict[str, Any]]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç tool results –∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å–æ–æ–±—â–µ–Ω–∏—è.
    
    Args:
        content: –ö–æ–Ω—Ç–µ–Ω—Ç —Å–æ–æ–±—â–µ–Ω–∏—è (–º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º)
    
    Returns:
        –°–ø–∏—Å–æ–∫ tool results –≤ —Ñ–æ—Ä–º–∞—Ç–µ Kiro
    """
    tool_results = []
    
    if isinstance(content, list):
        for item in content:
            if isinstance(item, dict) and item.get("type") == "tool_result":
                tool_results.append({
                    "content": [{"text": extract_text_content(item.get("content", ""))}],
                    "status": "success",
                    "toolUseId": item.get("tool_use_id", "")
                })
    
    return tool_results


def process_tools_with_long_descriptions(
    tools: Optional[List[Tool]]
) -> Tuple[Optional[List[Tool]], str]:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç tools —Å –¥–ª–∏–Ω–Ω—ã–º–∏ descriptions.
    
    Kiro API –∏–º–µ–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ –¥–ª–∏–Ω—É description –≤ toolSpecification.
    –ï—Å–ª–∏ description –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏–º–∏—Ç, –ø–æ–ª–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø–µ—Ä–µ–Ω–æ—Å–∏—Ç—Å—è –≤ system prompt,
    –∞ –≤ tool –æ—Å—Ç–∞—ë—Ç—Å—è —Å—Å—ã–ª–∫–∞ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é.
    
    Args:
        tools: –°–ø–∏—Å–æ–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞ OpenAI
    
    Returns:
        Tuple –∏–∑:
        - –°–ø–∏—Å–æ–∫ tools —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ descriptions (–∏–ª–∏ None –µ—Å–ª–∏ tools –ø—É—Å—Ç)
        - –°—Ç—Ä–æ–∫–∞ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–µ–π –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ system prompt (–ø—É—Å—Ç–∞—è –µ—Å–ª–∏ –≤—Å–µ descriptions –∫–æ—Ä–æ—Ç–∫–∏–µ)
    
    Example:
        >>> tools = [Tool(type="function", function=ToolFunction(name="bash", description="Very long..."))]
        >>> processed_tools, doc = process_tools_with_long_descriptions(tools)
        >>> "## Tool: bash" in doc
        True
    """
    if not tools:
        return None, ""
    
    # –ï—Å–ª–∏ –ª–∏–º–∏—Ç –æ—Ç–∫–ª—é—á–µ–Ω (0), –≤–æ–∑–≤—Ä–∞—â–∞–µ–º tools –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
    if TOOL_DESCRIPTION_MAX_LENGTH <= 0:
        return tools, ""
    
    tool_documentation_parts = []
    processed_tools = []
    
    for tool in tools:
        if tool.type != "function":
            processed_tools.append(tool)
            continue
        
        description = tool.function.description or ""
        
        if len(description) <= TOOL_DESCRIPTION_MAX_LENGTH:
            # Description –∫–æ—Ä–æ—Ç–∫–∏–π - –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
            processed_tools.append(tool)
        else:
            # Description —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π - –ø–µ—Ä–µ–Ω–æ—Å–∏–º –≤ system prompt
            tool_name = tool.function.name
            
            logger.debug(
                f"Tool '{tool_name}' has long description ({len(description)} chars > {TOOL_DESCRIPTION_MAX_LENGTH}), "
                f"moving to system prompt"
            )
            
            # –°–æ–∑–¥–∞—ë–º –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –¥–ª—è system prompt
            tool_documentation_parts.append(f"## Tool: {tool_name}\n\n{description}")
            
            # –°–æ–∑–¥–∞—ë–º –∫–æ–ø–∏—é tool —Å reference description
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å Tool –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ–π –∫–æ–ø–∏–∏
            from kiro_gateway.models import ToolFunction
            
            reference_description = f"[Full documentation in system prompt under '## Tool: {tool_name}']"
            
            processed_tool = Tool(
                type=tool.type,
                function=ToolFunction(
                    name=tool.function.name,
                    description=reference_description,
                    parameters=tool.function.parameters
                )
            )
            processed_tools.append(processed_tool)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é
    tool_documentation = ""
    if tool_documentation_parts:
        tool_documentation = (
            "\n\n---\n"
            "# Tool Documentation\n"
            "The following tools have detailed documentation that couldn't fit in the tool definition.\n\n"
            + "\n\n---\n\n".join(tool_documentation_parts)
        )
    
    return processed_tools if processed_tools else None, tool_documentation


def _extract_tool_uses(msg: ChatMessage) -> List[Dict[str, Any]]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç tool uses –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è assistant.
    
    Args:
        msg: –°–æ–æ–±—â–µ–Ω–∏–µ assistant
    
    Returns:
        –°–ø–∏—Å–æ–∫ tool uses –≤ —Ñ–æ—Ä–º–∞—Ç–µ Kiro
    """
    tool_uses = []
    
    # –ò–∑ –ø–æ–ª—è tool_calls
    if msg.tool_calls:
        for tc in msg.tool_calls:
            if isinstance(tc, dict):
                tool_uses.append({
                    "name": tc.get("function", {}).get("name", ""),
                    "input": json.loads(tc.get("function", {}).get("arguments", "{}")),
                    "toolUseId": tc.get("id", "")
                })
    
    # –ò–∑ content (–µ—Å–ª–∏ —Ç–∞–º –µ—Å—Ç—å tool_use)
    if isinstance(msg.content, list):
        for item in msg.content:
            if isinstance(item, dict) and item.get("type") == "tool_use":
                tool_uses.append({
                    "name": item.get("name", ""),
                    "input": item.get("input", {}),
                    "toolUseId": item.get("id", "")
                })
    
    return tool_uses


def build_kiro_payload(
    request_data: ChatCompletionRequest,
    conversation_id: str,
    profile_arn: str
) -> dict:
    """
    –°—Ç—Ä–æ–∏—Ç –ø–æ–ª–Ω—ã–π payload –¥–ª—è Kiro API.
    
    –í–∫–ª—é—á–∞–µ—Ç:
    - –ü–æ–ª–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é —Å–æ–æ–±—â–µ–Ω–∏–π
    - System prompt (–¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –∫ –ø–µ—Ä–≤–æ–º—É user —Å–æ–æ–±—â–µ–Ω–∏—é)
    - Tools definitions (—Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –¥–ª–∏–Ω–Ω—ã—Ö descriptions)
    - –¢–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    
    –ï—Å–ª–∏ tools —Å–æ–¥–µ—Ä–∂–∞—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ descriptions, –æ–Ω–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
    –ø–µ—Ä–µ–Ω–æ—Å—è—Ç—Å—è –≤ system prompt, –∞ –≤ tool –æ—Å—Ç–∞—ë—Ç—Å—è —Å—Å—ã–ª–∫–∞ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é.
    
    Args:
        request_data: –ó–∞–ø—Ä–æ—Å –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI
        conversation_id: –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
        profile_arn: ARN –ø—Ä–æ—Ñ–∏–ª—è AWS CodeWhisperer
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å payload –¥–ª—è POST –∑–∞–ø—Ä–æ—Å–∞ –∫ Kiro API
    
    Raises:
        ValueError: –ï—Å–ª–∏ –Ω–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏
    """
    messages = list(request_data.messages)
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º tools —Å –¥–ª–∏–Ω–Ω—ã–º–∏ descriptions
    processed_tools, tool_documentation = process_tools_with_long_descriptions(request_data.tools)
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º system prompt
    system_prompt = ""
    non_system_messages = []
    for msg in messages:
        if msg.role == "system":
            system_prompt += extract_text_content(msg.content) + "\n"
        else:
            non_system_messages.append(msg)
    system_prompt = system_prompt.strip()
    
    # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –ø–æ tools –≤ system prompt –µ—Å–ª–∏ –µ—Å—Ç—å
    if tool_documentation:
        system_prompt = system_prompt + tool_documentation if system_prompt else tool_documentation.strip()
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–æ—Å–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Å –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π —Ä–æ–ª—å—é
    merged_messages = merge_adjacent_messages(non_system_messages)
    
    if not merged_messages:
        raise ValueError("No messages to send")
    
    # –ü–æ–ª—É—á–∞–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π ID –º–æ–¥–µ–ª–∏
    model_id = get_internal_model_id(request_data.model)
    
    # –°—Ç—Ä–æ–∏–º –∏—Å—Ç–æ—Ä–∏—é (–≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ)
    history_messages = merged_messages[:-1] if len(merged_messages) > 1 else []
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å system prompt, –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ –∫ –ø–µ—Ä–≤–æ–º—É user —Å–æ–æ–±—â–µ–Ω–∏—é –≤ –∏—Å—Ç–æ—Ä–∏–∏
    if system_prompt and history_messages:
        first_msg = history_messages[0]
        if first_msg.role == "user":
            original_content = extract_text_content(first_msg.content)
            first_msg.content = f"{system_prompt}\n\n{original_content}"
    
    history = build_kiro_history(history_messages, model_id)
    
    # –¢–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ (–ø–æ—Å–ª–µ–¥–Ω–µ–µ)
    current_message = merged_messages[-1]
    current_content = extract_text_content(current_message.content)
    
    # –ï—Å–ª–∏ system prompt –µ—Å—Ç—å, –Ω–æ –∏—Å—Ç–æ—Ä–∏—è –ø—É—Å—Ç–∞ - –¥–æ–±–∞–≤–ª—è–µ–º –∫ —Ç–µ–∫—É—â–µ–º—É —Å–æ–æ–±—â–µ–Ω–∏—é
    if system_prompt and not history:
        current_content = f"{system_prompt}\n\n{current_content}"
    
    # –ï—Å–ª–∏ —Ç–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ - assistant, –Ω—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –µ–≥–æ –≤ –∏—Å—Ç–æ—Ä–∏—é
    # –∏ —Å–æ–∑–¥–∞—Ç—å user —Å–æ–æ–±—â–µ–Ω–∏–µ "Continue"
    if current_message.role == "assistant":
        history.append({
            "assistantResponseMessage": {
                "content": current_content
            }
        })
        current_content = "Continue"
    
    # –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–Ω—Ç –ø—É—Å—Ç–æ–π
    if not current_content:
        current_content = "Continue"
    
    # –°—Ç—Ä–æ–∏–º userInputMessage
    user_input_message = {
        "content": current_content,
        "modelId": model_id,
        "origin": "AI_EDITOR",
    }
    
    # –î–æ–±–∞–≤–ª—è–µ–º tools –∏ tool_results –µ—Å–ª–∏ –µ—Å—Ç—å
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ tools (—Å –∫–æ—Ä–æ—Ç–∫–∏–º–∏ descriptions)
    user_input_context = _build_user_input_context(request_data, current_message, processed_tools)
    if user_input_context:
        user_input_message["userInputMessageContext"] = user_input_context
    
    # –°–æ–±–∏—Ä–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π payload
    payload = {
        "conversationState": {
            "chatTriggerType": "MANUAL",
            "conversationId": conversation_id,
            "currentMessage": {
                "userInputMessage": user_input_message
            }
        }
    }
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ –ø—É—Å—Ç–∞
    if history:
        payload["conversationState"]["history"] = history
    
    # –î–æ–±–∞–≤–ª—è–µ–º profileArn
    if profile_arn:
        payload["profileArn"] = profile_arn
    
    return payload


def _sanitize_json_schema(schema: Optional[Dict[str, Any]]) -> Dict[str, Any]:
    """
    –û—á–∏—â–∞–µ—Ç JSON Schema –æ—Ç –ø–æ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ Kiro API –Ω–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç.
    
    Kiro API –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—à–∏–±–∫—É 400 "Improperly formed request" –µ—Å–ª–∏:
    - required —è–≤–ª—è–µ—Ç—Å—è –ø—É—Å—Ç—ã–º –º–∞—Å—Å–∏–≤–æ–º []
    - additionalProperties –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ —Å—Ö–µ–º–µ
    
    –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å—Ö–µ–º—É –∏ —É–¥–∞–ª—è–µ—Ç –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –ø–æ–ª—è.
    
    Args:
        schema: JSON Schema –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
    
    Returns:
        –û—á–∏—â–µ–Ω–Ω–∞—è –∫–æ–ø–∏—è —Å—Ö–µ–º—ã
    """
    if not schema:
        return {}
    
    # –°–æ–∑–¥–∞—ë–º –∫–æ–ø–∏—é —á—Ç–æ–±—ã –Ω–µ –º—É—Ç–∏—Ä–æ–≤–∞—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª
    result = {}
    
    for key, value in schema.items():
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ required –º–∞—Å—Å–∏–≤—ã
        if key == "required" and isinstance(value, list) and len(value) == 0:
            continue
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º additionalProperties - Kiro API –µ–≥–æ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç
        if key == "additionalProperties":
            continue
        
        # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–ª–æ–∂–µ–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
        if key == "properties" and isinstance(value, dict):
            result[key] = {
                prop_name: _sanitize_json_schema(prop_value) if isinstance(prop_value, dict) else prop_value
                for prop_name, prop_value in value.items()
            }
        elif isinstance(value, dict):
            result[key] = _sanitize_json_schema(value)
        elif isinstance(value, list):
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ø–∏—Å–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, anyOf, oneOf)
            result[key] = [
                _sanitize_json_schema(item) if isinstance(item, dict) else item
                for item in value
            ]
        else:
            result[key] = value
    
    return result


def _build_user_input_context(
    request_data: ChatCompletionRequest,
    current_message: ChatMessage,
    processed_tools: Optional[List[Tool]] = None
) -> Dict[str, Any]:
    """
    –°—Ç—Ä–æ–∏—Ç userInputMessageContext –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è.
    
    –í–∫–ª—é—á–∞–µ—Ç tools definitions –∏ tool_results.
    
    Args:
        request_data: –ó–∞–ø—Ä–æ—Å —Å tools
        current_message: –¢–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        processed_tools: –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ tools —Å –∫–æ—Ä–æ—Ç–∫–∏–º–∏ descriptions (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ).
                        –ï—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è tools –∏–∑ request_data.
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏–ª–∏ –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å
    """
    context = {}
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ tools –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω—ã, –∏–Ω–∞—á–µ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ
    tools_to_use = processed_tools if processed_tools is not None else request_data.tools
    
    # –î–æ–±–∞–≤–ª—è–µ–º tools –µ—Å–ª–∏ –µ—Å—Ç—å
    if tools_to_use:
        tools_list = []
        for tool in tools_to_use:
            if tool.type == "function":
                # –û—á–∏—â–∞–µ–º parameters –æ—Ç –ø–æ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ Kiro API –Ω–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç
                sanitized_params = _sanitize_json_schema(tool.function.parameters)
                
                # Kiro API —Ç—Ä–µ–±—É–µ—Ç –Ω–µ–ø—É—Å—Ç–æ–µ description
                # –ï—Å–ª–∏ description –ø—É—Å—Ç–æ–µ –∏–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ–º placeholder
                description = tool.function.description
                if not description or not description.strip():
                    description = f"Tool: {tool.function.name}"
                    logger.debug(f"Tool '{tool.function.name}' has empty description, using placeholder")
                
                tools_list.append({
                    "toolSpecification": {
                        "name": tool.function.name,
                        "description": description,
                        "inputSchema": {"json": sanitized_params}
                    }
                })
        if tools_list:
            context["tools"] = tools_list
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ tool_results –≤ —Ç–µ–∫—É—â–µ–º —Å–æ–æ–±—â–µ–Ω–∏–∏
    tool_results = _extract_tool_results(current_message.content)
    if tool_results:
        context["toolResults"] = tool_results
    
    return context


================================================
FILE: kiro_gateway/debug_logger.py
================================================
# -*- coding: utf-8 -*-

# Kiro OpenAI Gateway
# Copyright (C) 2025 Jwadow
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

"""
–ú–æ–¥—É–ª—å –¥–ª—è –æ—Ç–ª–∞–¥–æ—á–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤.

–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç—Ä–∏ —Ä–µ–∂–∏–º–∞ (DEBUG_MODE):
- off: –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–∫–ª—é—á–µ–Ω–æ
- errors: –ª–æ–≥–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö (4xx, 5xx)
- all: –ª–æ–≥–∏ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞—é—Ç—Å—è –Ω–∞ –∫–∞–∂–¥—ã–π –∑–∞–ø—Ä–æ—Å

–í —Ä–µ–∂–∏–º–µ "errors" –¥–∞–Ω–Ω—ã–µ –±—É—Ñ–µ—Ä–∏–∑—É—é—Ç—Å—è –≤ –ø–∞–º—è—Ç–∏ –∏ —Å–±—Ä–∞—Å—ã–≤–∞—é—Ç—Å—è –≤ —Ñ–∞–π–ª—ã
—Ç–æ–ª—å–∫–æ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ flush_on_error().

–¢–∞–∫–∂–µ –∑–∞—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç –ª–æ–≥–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è (loguru) –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç
–∏—Ö –≤ —Ñ–∞–π–ª app_logs.txt –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –æ—Ç–ª–∞–¥–∫–∏.
"""

import io
import json
import shutil
from pathlib import Path
from typing import Optional
from loguru import logger

from kiro_gateway.config import DEBUG_MODE, DEBUG_DIR


class DebugLogger:
    """
    –°–∏–Ω–≥–ª—Ç–æ–Ω –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—Ç–ª–∞–¥–æ—á–Ω—ã–º–∏ –ª–æ–≥–∞–º–∏ –∑–∞–ø—Ä–æ—Å–æ–≤.
    
    –†–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã:
    - off: –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ—Ç
    - errors: –±—É—Ñ–µ—Ä–∏–∑—É–µ—Ç –¥–∞–Ω–Ω—ã–µ, —Å–±—Ä–∞—Å—ã–≤–∞–µ—Ç –≤ —Ñ–∞–π–ª—ã —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
    - all: –ø–∏—à–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å—Ä–∞–∑—É –≤ —Ñ–∞–π–ª—ã (–∫–∞–∫ —Ä–∞–Ω—å—à–µ)
    """
    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(DebugLogger, cls).__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if self._initialized:
            return
        self.debug_dir = Path(DEBUG_DIR)
        self._initialized = True
        
        # –ë—É—Ñ–µ—Ä—ã –¥–ª—è —Ä–µ–∂–∏–º–∞ "errors"
        self._request_body_buffer: Optional[bytes] = None
        self._kiro_request_body_buffer: Optional[bytes] = None
        self._raw_chunks_buffer: bytearray = bytearray()
        self._modified_chunks_buffer: bytearray = bytearray()
        
        # –ë—É—Ñ–µ—Ä –¥–ª—è –ª–æ–≥–æ–≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è (loguru)
        self._app_logs_buffer: io.StringIO = io.StringIO()
        self._loguru_sink_id: Optional[int] = None
    
    def _is_enabled(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –≤–∫–ª—é—á–µ–Ω–æ –ª–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ."""
        return DEBUG_MODE in ("errors", "all")
    
    def _is_immediate_write(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –ø–∏—Å–∞—Ç—å —Å—Ä–∞–∑—É –≤ —Ñ–∞–π–ª—ã (—Ä–µ–∂–∏–º all)."""
        return DEBUG_MODE == "all"
    
    def _clear_buffers(self):
        """–û—á–∏—â–∞–µ—Ç –≤—Å–µ –±—É—Ñ–µ—Ä—ã."""
        self._request_body_buffer = None
        self._kiro_request_body_buffer = None
        self._raw_chunks_buffer.clear()
        self._modified_chunks_buffer.clear()
        self._clear_app_logs_buffer()
    
    def _clear_app_logs_buffer(self):
        """–û—á–∏—â–∞–µ—Ç –±—É—Ñ–µ—Ä –ª–æ–≥–æ–≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –∏ —É–¥–∞–ª—è–µ—Ç sink."""
        # –£–¥–∞–ª—è–µ–º sink –∏–∑ loguru
        if self._loguru_sink_id is not None:
            try:
                logger.remove(self._loguru_sink_id)
            except ValueError:
                # Sink —É–∂–µ —É–¥–∞–ª—ë–Ω
                pass
            self._loguru_sink_id = None
        
        # –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä
        self._app_logs_buffer = io.StringIO()
    
    def _setup_app_logs_capture(self):
        """
        –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –∑–∞—Ö–≤–∞—Ç –ª–æ–≥–æ–≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –≤ –±—É—Ñ–µ—Ä.
        
        –î–æ–±–∞–≤–ª—è–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–π sink –≤ loguru, –∫–æ—Ç–æ—Ä—ã–π –ø–∏—à–µ—Ç –≤ StringIO –±—É—Ñ–µ—Ä.
        –ó–∞—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç –í–°–ï –ª–æ–≥–∏ –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏, —Ç–∞–∫ –∫–∞–∫ sink –∞–∫—Ç–∏–≤–µ–Ω —Ç–æ–ª—å–∫–æ
        –Ω–∞ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.
        """
        # –£–¥–∞–ª—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π sink –µ—Å–ª–∏ –µ—Å—Ç—å
        self._clear_app_logs_buffer()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π sink –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –í–°–ï–• –ª–æ–≥–æ–≤
        # –§–æ—Ä–º–∞—Ç: –≤—Ä–µ–º—è | —É—Ä–æ–≤–µ–Ω—å | –º–æ–¥—É–ª—å:—Ñ—É–Ω–∫—Ü–∏—è:—Å—Ç—Ä–æ–∫–∞ | —Å–æ–æ–±—â–µ–Ω–∏–µ
        self._loguru_sink_id = logger.add(
            self._app_logs_buffer,
            format="{time:YYYY-MM-DD HH:mm:ss.SSS} | {level: <8} | {name}:{function}:{line} | {message}",
            level="DEBUG",  # –ó–∞—Ö–≤–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ —É—Ä–æ–≤–Ω–∏ –æ—Ç DEBUG –∏ –≤—ã—à–µ
            colorize=False,  # –ë–µ–∑ ANSI —Ü–≤–µ—Ç–æ–≤ –≤ —Ñ–∞–π–ª–µ
            # –ë–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞ - –∑–∞—Ö–≤–∞—Ç—ã–≤–∞–µ–º –í–°–ï –ª–æ–≥–∏ –≤–æ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞
        )

    def prepare_new_request(self):
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –ª–æ–≥–≥–µ—Ä –¥–ª—è –Ω–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.
        
        –í —Ä–µ–∂–∏–º–µ "all": –æ—á–∏—â–∞–µ—Ç –ø–∞–ø–∫—É —Å –ª–æ–≥–∞–º–∏.
        –í —Ä–µ–∂–∏–º–µ "errors": –æ—á–∏—â–∞–µ—Ç –±—É—Ñ–µ—Ä—ã.
        –í –æ–±–æ–∏—Ö —Ä–µ–∂–∏–º–∞—Ö: –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –∑–∞—Ö–≤–∞—Ç –ª–æ–≥–æ–≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.
        """
        if not self._is_enabled():
            return
        
        # –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä—ã –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ
        self._clear_buffers()
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∑–∞—Ö–≤–∞—Ç –ª–æ–≥–æ–≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
        self._setup_app_logs_capture()

        if self._is_immediate_write():
            # –†–µ–∂–∏–º "all" - –æ—á–∏—â–∞–µ–º –ø–∞–ø–∫—É –∏ —Å–æ–∑–¥–∞—ë–º –∑–∞–Ω–æ–≤–æ
            try:
                if self.debug_dir.exists():
                    shutil.rmtree(self.debug_dir)
                self.debug_dir.mkdir(parents=True, exist_ok=True)
                logger.debug(f"[DebugLogger] Directory {self.debug_dir} cleared for new request.")
            except Exception as e:
                logger.error(f"[DebugLogger] Error preparing directory: {e}")

    def log_request_body(self, body: bytes):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–µ–ª–æ –∑–∞–ø—Ä–æ—Å–∞ (–æ—Ç –∫–ª–∏–µ–Ω—Ç–∞, OpenAI —Ñ–æ—Ä–º–∞—Ç).
        
        –í —Ä–µ–∂–∏–º–µ "all": –ø–∏—à–µ—Ç —Å—Ä–∞–∑—É –≤ —Ñ–∞–π–ª.
        –í —Ä–µ–∂–∏–º–µ "errors": –±—É—Ñ–µ—Ä–∏–∑—É–µ—Ç.
        """
        if not self._is_enabled():
            return

        if self._is_immediate_write():
            self._write_request_body_to_file(body)
        else:
            # –†–µ–∂–∏–º "errors" - –±—É—Ñ–µ—Ä–∏–∑—É–µ–º
            self._request_body_buffer = body

    def log_kiro_request_body(self, body: bytes):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ç–µ–ª–æ –∑–∞–ø—Ä–æ—Å–∞ (–∫ Kiro API).
        
        –í —Ä–µ–∂–∏–º–µ "all": –ø–∏—à–µ—Ç —Å—Ä–∞–∑—É –≤ —Ñ–∞–π–ª.
        –í —Ä–µ–∂–∏–º–µ "errors": –±—É—Ñ–µ—Ä–∏–∑—É–µ—Ç.
        """
        if not self._is_enabled():
            return

        if self._is_immediate_write():
            self._write_kiro_request_body_to_file(body)
        else:
            # –†–µ–∂–∏–º "errors" - –±—É—Ñ–µ—Ä–∏–∑—É–µ–º
            self._kiro_request_body_buffer = body

    def log_raw_chunk(self, chunk: bytes):
        """
        –î–æ–ø–∏—Å—ã–≤–∞–µ—Ç —Å—ã—Ä–æ–π —á–∞–Ω–∫ –æ—Ç–≤–µ—Ç–∞ (–æ—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞).
        
        –í —Ä–µ–∂–∏–º–µ "all": –ø–∏—à–µ—Ç —Å—Ä–∞–∑—É –≤ —Ñ–∞–π–ª.
        –í —Ä–µ–∂–∏–º–µ "errors": –±—É—Ñ–µ—Ä–∏–∑—É–µ—Ç.
        """
        if not self._is_enabled():
            return

        if self._is_immediate_write():
            self._append_raw_chunk_to_file(chunk)
        else:
            # –†–µ–∂–∏–º "errors" - –±—É—Ñ–µ—Ä–∏–∑—É–µ–º
            self._raw_chunks_buffer.extend(chunk)

    def log_modified_chunk(self, chunk: bytes):
        """
        –î–æ–ø–∏—Å—ã–≤–∞–µ—Ç –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —á–∞–Ω–∫ (–∫–ª–∏–µ–Ω—Ç—É).
        
        –í —Ä–µ–∂–∏–º–µ "all": –ø–∏—à–µ—Ç —Å—Ä–∞–∑—É –≤ —Ñ–∞–π–ª.
        –í —Ä–µ–∂–∏–º–µ "errors": –±—É—Ñ–µ—Ä–∏–∑—É–µ—Ç.
        """
        if not self._is_enabled():
            return

        if self._is_immediate_write():
            self._append_modified_chunk_to_file(chunk)
        else:
            # –†–µ–∂–∏–º "errors" - –±—É—Ñ–µ—Ä–∏–∑—É–µ–º
            self._modified_chunks_buffer.extend(chunk)
    
    def log_error_info(self, status_code: int, error_message: str = ""):
        """
        –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—à–∏–±–∫–µ –≤ —Ñ–∞–π–ª.
        
        –†–∞–±–æ—Ç–∞–µ—Ç –≤ –æ–±–æ–∏—Ö —Ä–µ–∂–∏–º–∞—Ö (errors –∏ all).
        –í —Ä–µ–∂–∏–º–µ "all" –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Å—Ä–∞–∑—É –≤ —Ñ–∞–π–ª.
        –í —Ä–µ–∂–∏–º–µ "errors" –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –∏–∑ flush_on_error().
        
        Args:
            status_code: HTTP —Å—Ç–∞—Ç—É—Å –∫–æ–¥ –æ—à–∏–±–∫–∏
            error_message: –°–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        """
        if not self._is_enabled():
            return
        
        try:
            # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            self.debug_dir.mkdir(parents=True, exist_ok=True)
            
            error_info = {
                "status_code": status_code,
                "error_message": error_message
            }
            error_file = self.debug_dir / "error_info.json"
            with open(error_file, "w", encoding="utf-8") as f:
                json.dump(error_info, f, indent=2, ensure_ascii=False)
            
            logger.debug(f"[DebugLogger] Error info saved (status={status_code})")
        except Exception as e:
            logger.error(f"[DebugLogger] Error writing error_info: {e}")

    def flush_on_error(self, status_code: int, error_message: str = ""):
        """
        –°–±—Ä–∞—Å—ã–≤–∞–µ—Ç –±—É—Ñ–µ—Ä—ã –≤ —Ñ–∞–π–ª—ã –ø—Ä–∏ –æ—à–∏–±–∫–µ.
        
        –í —Ä–µ–∂–∏–º–µ "errors": —Å–±—Ä–∞—Å—ã–≤–∞–µ—Ç –±—É—Ñ–µ—Ä—ã –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç error_info.
        –í —Ä–µ–∂–∏–º–µ "all": —Ç–æ–ª—å–∫–æ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç error_info (–¥–∞–Ω–Ω—ã–µ —É–∂–µ –∑–∞–ø–∏—Å–∞–Ω—ã).
        
        Args:
            status_code: HTTP —Å—Ç–∞—Ç—É—Å –∫–æ–¥ –æ—à–∏–±–∫–∏
            error_message: –°–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        """
        if not self._is_enabled():
            return
        
        # –í —Ä–µ–∂–∏–º–µ "all" –¥–∞–Ω–Ω—ã–µ —É–∂–µ –∑–∞–ø–∏—Å–∞–Ω—ã, –¥–æ–±–∞–≤–ª—è–µ–º error_info –∏ –ª–æ–≥–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
        if self._is_immediate_write():
            self.log_error_info(status_code, error_message)
            self._write_app_logs_to_file()
            self._clear_app_logs_buffer()
            return
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —á—Ç–æ —Å–±—Ä–∞—Å—ã–≤–∞—Ç—å
        if not any([
            self._request_body_buffer,
            self._kiro_request_body_buffer,
            self._raw_chunks_buffer,
            self._modified_chunks_buffer
        ]):
            return
        
        try:
            # –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            if self.debug_dir.exists():
                shutil.rmtree(self.debug_dir)
            self.debug_dir.mkdir(parents=True, exist_ok=True)
            
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –±—É—Ñ–µ—Ä—ã –≤ —Ñ–∞–π–ª—ã
            if self._request_body_buffer:
                self._write_request_body_to_file(self._request_body_buffer)
            
            if self._kiro_request_body_buffer:
                self._write_kiro_request_body_to_file(self._kiro_request_body_buffer)
            
            if self._raw_chunks_buffer:
                file_path = self.debug_dir / "response_stream_raw.txt"
                with open(file_path, "wb") as f:
                    f.write(self._raw_chunks_buffer)
            
            if self._modified_chunks_buffer:
                file_path = self.debug_dir / "response_stream_modified.txt"
                with open(file_path, "wb") as f:
                    f.write(self._modified_chunks_buffer)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—à–∏–±–∫–µ
            self.log_error_info(status_code, error_message)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–≥–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
            self._write_app_logs_to_file()
            
            logger.info(f"[DebugLogger] Error logs flushed to {self.debug_dir} (status={status_code})")
            
        except Exception as e:
            logger.error(f"[DebugLogger] Error flushing buffers: {e}")
        finally:
            # –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä—ã –ø–æ—Å–ª–µ —Å–±—Ä–æ—Å–∞
            self._clear_buffers()
    
    def discard_buffers(self):
        """
        –û—á–∏—â–∞–µ—Ç –±—É—Ñ–µ—Ä—ã –±–µ–∑ –∑–∞–ø–∏—Å–∏ –≤ —Ñ–∞–π–ª—ã.
        
        –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –∫–æ–≥–¥–∞ –∑–∞–ø—Ä–æ—Å –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —É—Å–ø–µ—à–Ω–æ –≤ —Ä–µ–∂–∏–º–µ "errors".
        –¢–∞–∫–∂–µ –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –≤ —Ä–µ–∂–∏–º–µ "all" –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ª–æ–≥–æ–≤ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.
        """
        if DEBUG_MODE == "errors":
            self._clear_buffers()
        elif DEBUG_MODE == "all":
            # –í —Ä–µ–∂–∏–º–µ "all" —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–≥–∏ –¥–∞–∂–µ –¥–ª—è —É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            self._write_app_logs_to_file()
            self._clear_app_logs_buffer()
    
    # ==================== –ü—Ä–∏–≤–∞—Ç–Ω—ã–µ –º–µ—Ç–æ–¥—ã –∑–∞–ø–∏—Å–∏ –≤ —Ñ–∞–π–ª—ã ====================
    
    def _write_request_body_to_file(self, body: bytes):
        """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Ç–µ–ª–æ –∑–∞–ø—Ä–æ—Å–∞ –≤ —Ñ–∞–π–ª."""
        try:
            file_path = self.debug_dir / "request_body.json"
            try:
                json_obj = json.loads(body)
                with open(file_path, "w", encoding="utf-8") as f:
                    json.dump(json_obj, f, indent=2, ensure_ascii=False)
            except json.JSONDecodeError:
                with open(file_path, "wb") as f:
                    f.write(body)
        except Exception as e:
            logger.error(f"[DebugLogger] Error writing request_body: {e}")
    
    def _write_kiro_request_body_to_file(self, body: bytes):
        """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Ç–µ–ª–æ –∑–∞–ø—Ä–æ—Å–∞ –∫ Kiro –≤ —Ñ–∞–π–ª."""
        try:
            file_path = self.debug_dir / "kiro_request_body.json"
            try:
                json_obj = json.loads(body)
                with open(file_path, "w", encoding="utf-8") as f:
                    json.dump(json_obj, f, indent=2, ensure_ascii=False)
            except json.JSONDecodeError:
                with open(file_path, "wb") as f:
                    f.write(body)
        except Exception as e:
            logger.error(f"[DebugLogger] Error writing kiro_request_body: {e}")
    
    def _append_raw_chunk_to_file(self, chunk: bytes):
        """–î–æ–ø–∏—Å—ã–≤–∞–µ—Ç —Å—ã—Ä–æ–π —á–∞–Ω–∫ –≤ —Ñ–∞–π–ª."""
        try:
            file_path = self.debug_dir / "response_stream_raw.txt"
            with open(file_path, "ab") as f:
                f.write(chunk)
        except Exception:
            pass
    
    def _append_modified_chunk_to_file(self, chunk: bytes):
        """–î–æ–ø–∏—Å—ã–≤–∞–µ—Ç –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —á–∞–Ω–∫ –≤ —Ñ–∞–π–ª."""
        try:
            file_path = self.debug_dir / "response_stream_modified.txt"
            with open(file_path, "ab") as f:
                f.write(chunk)
        except Exception:
            pass
    
    def _write_app_logs_to_file(self):
        """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –∑–∞—Ö–≤–∞—á–µ–Ω–Ω—ã–µ –ª–æ–≥–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –≤ —Ñ–∞–π–ª."""
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –±—É—Ñ–µ—Ä–∞
            logs_content = self._app_logs_buffer.getvalue()
            
            if not logs_content.strip():
                return
            
            # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            self.debug_dir.mkdir(parents=True, exist_ok=True)
            
            file_path = self.debug_dir / "app_logs.txt"
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(logs_content)
            
            logger.debug(f"[DebugLogger] App logs saved to {file_path}")
        except Exception as e:
            # –ù–µ –ª–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É —á–µ—Ä–µ–∑ logger —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Ä–µ–∫—É—Ä—Å–∏–∏
            pass


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
debug_logger = DebugLogger()


================================================
FILE: kiro_gateway/exceptions.py
================================================
# -*- coding: utf-8 -*-

# Kiro OpenAI Gateway
# Copyright (C) 2025 Jwadow
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

"""
–û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∏—Å–∫–ª—é—á–µ–Ω–∏–π –¥–ª—è Kiro Gateway.

–°–æ–¥–µ—Ä–∂–∏—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ –¥—Ä—É–≥–∏—Ö –∏—Å–∫–ª—é—á–µ–Ω–∏–π
–≤ —Ñ–æ—Ä–º–∞—Ç–µ, —Å–æ–≤–º–µ—Å—Ç–∏–º–æ–º —Å JSON-—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–µ–π.
"""

from typing import Any, List, Dict

from fastapi import Request
from fastapi.exceptions import RequestValidationError
from fastapi.responses import JSONResponse
from loguru import logger


def sanitize_validation_errors(errors: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –æ—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤ JSON-—Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç.
    
    Pydantic –º–æ–∂–µ—Ç –≤–∫–ª—é—á–∞—Ç—å bytes –æ–±—ä–µ–∫—Ç—ã –≤ –ø–æ–ª–µ 'input', –∫–æ—Ç–æ—Ä—ã–µ
    –Ω–µ —Å–µ—Ä–∏–∞–ª–∏–∑—É—é—Ç—Å—è –≤ JSON. –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∏—Ö –≤ —Å—Ç—Ä–æ–∫–∏.
    
    Args:
        errors: –°–ø–∏—Å–æ–∫ –æ—à–∏–±–æ–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –æ—Ç Pydantic
    
    Returns:
        –°–ø–∏—Å–æ–∫ –æ—à–∏–±–æ–∫ —Å bytes –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–º–∏ –≤ —Å—Ç—Ä–æ–∫–∏
    """
    sanitized = []
    for error in errors:
        sanitized_error = {}
        for key, value in error.items():
            if isinstance(value, bytes):
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º bytes –≤ —Å—Ç—Ä–æ–∫—É
                sanitized_error[key] = value.decode("utf-8", errors="replace")
            elif isinstance(value, (list, tuple)):
                # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ø–∏—Å–∫–∏
                sanitized_error[key] = [
                    v.decode("utf-8", errors="replace") if isinstance(v, bytes) else v
                    for v in value
                ]
            else:
                sanitized_error[key] = value
        sanitized.append(sanitized_error)
    return sanitized


async def validation_exception_handler(request: Request, exc: RequestValidationError) -> JSONResponse:
    """
    –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ Pydantic.
    
    –õ–æ–≥–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –æ—Ç–≤–µ—Ç.
    –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç bytes –æ–±—ä–µ–∫—Ç—ã –≤ –æ—à–∏–±–∫–∞—Ö, –ø—Ä–µ–æ–±—Ä–∞–∑—É—è –∏—Ö –≤ —Å—Ç—Ä–æ–∫–∏.
    
    Args:
        request: FastAPI Request –æ–±—ä–µ–∫—Ç
        exc: –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –æ—Ç Pydantic
    
    Returns:
        JSONResponse —Å –¥–µ—Ç–∞–ª—è–º–∏ –æ—à–∏–±–∫–∏ –∏ —Å—Ç–∞—Ç—É—Å–æ–º 422
    """
    body = await request.body()
    body_str = body.decode("utf-8", errors="replace")
    
    # –°–∞–Ω–∏—Ç–∏–∑–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –¥–ª—è JSON-—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏
    sanitized_errors = sanitize_validation_errors(exc.errors())
    
    logger.error(f"Validation error (422): {sanitized_errors}")
    logger.error(f"Request body: {body_str[:500]}...")
    
    return JSONResponse(
        status_code=422,
        content={"detail": sanitized_errors, "body": body_str[:500]},
    )


================================================
FILE: kiro_gateway/http_client.py
================================================
# -*- coding: utf-8 -*-

# Kiro OpenAI Gateway
# https://github.com/jwadow/kiro-openai-gateway
# Copyright (C) 2025 Jwadow
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

"""
HTTP client for Kiro API with retry logic support.

Handles:
- 403: automatic token refresh and retry
- 429: exponential backoff
- 5xx: exponential backoff
- Timeouts: exponential backoff
"""

import asyncio
from typing import Optional

import httpx
from fastapi import HTTPException
from loguru import logger

from kiro_gateway.config import MAX_RETRIES, BASE_RETRY_DELAY, FIRST_TOKEN_MAX_RETRIES, STREAMING_READ_TIMEOUT
from kiro_gateway.auth import KiroAuthManager
from kiro_gateway.utils import get_kiro_headers


class KiroHttpClient:
    """
    HTTP client for Kiro API with retry logic support.
    
    Automatically handles errors and retries requests:
    - 403: refreshes token and retries
    - 429: waits with exponential backoff
    - 5xx: waits with exponential backoff
    - Timeouts: waits with exponential backoff
    Attributes:
        auth_manager: Authentication manager for obtaining tokens
        client: httpx HTTP client
    
    Example:
        >>> client = KiroHttpClient(auth_manager)
        >>> response = await client.request_with_retry(
        ...     "POST",
        ...     "https://api.example.com/endpoint",
        ...     {"data": "value"},
        ...     stream=True
        ... )
    """
    
    def __init__(self, auth_manager: KiroAuthManager):
        """
        Initializes the HTTP client.
        
        Args:
            auth_manager: Authentication manager
        """
        self.auth_manager = auth_manager
        self.client: Optional[httpx.AsyncClient] = None
    
    async def _get_client(self, stream: bool = False) -> httpx.AsyncClient:
        """
        Returns or creates an HTTP client with proper timeouts.
        
        httpx timeouts:
        - connect: TCP handshake (DNS + TCP SYN/ACK)
        - read: waiting for data from server between chunks
        - write: sending data to server
        - pool: waiting for free connection from pool
        
        IMPORTANT: FIRST_TOKEN_TIMEOUT is NOT used here!
        It is applied in streaming.py via asyncio.wait_for() to control
        the wait time for the first token from the model (retry business logic).
        
        Args:
            stream: If True, uses STREAMING_READ_TIMEOUT for read
        
        Returns:
            Active HTTP client
        """
        if self.client is None or self.client.is_closed:
            if stream:
                # For streaming:
                # - connect: 30 sec (TCP connection, usually < 1 sec)
                # - read: STREAMING_READ_TIMEOUT (300 sec) - model may "think" between chunks
                # - write/pool: standard values
                timeout_config = httpx.Timeout(
                    connect=30.0,
                    read=STREAMING_READ_TIMEOUT,
                    write=30.0,
                    pool=30.0
                )
                logger.debug(f"Creating streaming HTTP client (read_timeout={STREAMING_READ_TIMEOUT}s)")
            else:
                # For regular requests: single timeout of 300 sec
                timeout_config = httpx.Timeout(timeout=300.0)
                logger.debug("Creating non-streaming HTTP client (timeout=300s)")
            
            self.client = httpx.AsyncClient(timeout=timeout_config, follow_redirects=True)
        return self.client
    
    async def close(self) -> None:
        """Closes the HTTP client."""
        if self.client and not self.client.is_closed:
            await self.client.aclose()
    
    async def request_with_retry(
        self,
        method: str,
        url: str,
        json_data: dict,
        stream: bool = False
    ) -> httpx.Response:
        """
        Executes an HTTP request with retry logic.
        
        Automatically handles various error types:
        - 403: refreshes token via auth_manager.force_refresh() and retries
        - 429: waits with exponential backoff (1s, 2s, 4s)
        - 5xx: waits with exponential backoff
        - Timeouts: waits with exponential backoff
        
        For streaming, STREAMING_READ_TIMEOUT is used for waiting between chunks.
        First token timeout is controlled separately in streaming.py via asyncio.wait_for().
        
        Args:
            method: HTTP method (GET, POST, etc.)
            url: Request URL
            json_data: Request body (JSON)
            stream: Use streaming (default False)
        
        Returns:
            httpx.Response with successful response
        
        Raises:
            HTTPException: On failure after all attempts (502/504)
        """
        # Determine the number of retry attempts
        # FIRST_TOKEN_TIMEOUT is used in streaming.py, not here
        max_retries = FIRST_TOKEN_MAX_RETRIES if stream else MAX_RETRIES
        
        client = await self._get_client(stream=stream)
        last_error = None
        
        for attempt in range(max_retries):
            try:
                # Get current token
                token = await self.auth_manager.get_access_token()
                headers = get_kiro_headers(self.auth_manager, token)
                
                if stream:
                    req = client.build_request(method, url, json=json_data, headers=headers)
                    response = await client.send(req, stream=True)
                else:
                    response = await client.request(method, url, json=json_data, headers=headers)
                
                # Check status
                if response.status_code == 200:
                    return response
                
                # 403 - token expired, refresh and retry
                if response.status_code == 403:
                    logger.warning(f"Received 403, refreshing token (attempt {attempt + 1}/{MAX_RETRIES})")
                    await self.auth_manager.force_refresh()
                    continue
                
                # 429 - rate limit, wait and retry
                if response.status_code == 429:
                    delay = BASE_RETRY_DELAY * (2 ** attempt)
                    logger.warning(f"Received 429, waiting {delay}s (attempt {attempt + 1}/{MAX_RETRIES})")
                    await asyncio.sleep(delay)
                    continue
                
                # 5xx - server error, wait and retry
                if 500 <= response.status_code < 600:
                    delay = BASE_RETRY_DELAY * (2 ** attempt)
                    logger.warning(f"Received {response.status_code}, waiting {delay}s (attempt {attempt + 1}/{MAX_RETRIES})")
                    await asyncio.sleep(delay)
                    continue
                
                # Other errors - return as is
                return response
                
            except httpx.TimeoutException as e:
                last_error = e
                # Determine timeout type for logging
                timeout_type = type(e).__name__
                
                if stream:
                    # For streaming this could be:
                    # - ConnectTimeout: TCP connection issue
                    # - ReadTimeout: server not responding (STREAMING_READ_TIMEOUT)
                    if isinstance(e, httpx.ConnectTimeout):
                        logger.warning(
                            f"[{timeout_type}] Connection timeout (attempt {attempt + 1}/{max_retries})"
                        )
                    elif isinstance(e, httpx.ReadTimeout):
                        logger.warning(
                            f"[{timeout_type}] Read timeout after {STREAMING_READ_TIMEOUT}s - "
                            f"server stopped responding (attempt {attempt + 1}/{max_retries})"
                        )
                    else:
                        logger.warning(
                            f"[{timeout_type}] Timeout during streaming (attempt {attempt + 1}/{max_retries})"
                        )
                else:
                    delay = BASE_RETRY_DELAY * (2 ** attempt)
                    logger.warning(
                        f"[{timeout_type}] Request timeout, waiting {delay}s (attempt {attempt + 1}/{max_retries})"
                    )
                    await asyncio.sleep(delay)
                
            except httpx.RequestError as e:
                last_error = e
                delay = BASE_RETRY_DELAY * (2 ** attempt)
                logger.warning(f"Request error: {e}, waiting {delay}s (attempt {attempt + 1}/{max_retries})")
                await asyncio.sleep(delay)
        
        # All attempts exhausted
        if stream:
            raise HTTPException(
                status_code=504,
                detail=f"Streaming failed after {max_retries} attempts. Last error: {type(last_error).__name__}"
            )
        else:
            raise HTTPException(
                status_code=502,
                detail=f"Failed to complete request after {max_retries} attempts: {last_error}"
            )
    
    async def __aenter__(self) -> "KiroHttpClient":
        """Async context manager support."""
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:
        """Closes the client when exiting context."""
        await self.close()


================================================
FILE: kiro_gateway/models.py
================================================
# -*- coding: utf-8 -*-

# Kiro OpenAI Gateway
# Copyright (C) 2025 Jwadow
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

"""
Pydantic –º–æ–¥–µ–ª–∏ –¥–ª—è OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º–æ–≥–æ API.

–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ö–µ–º—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –æ—Ç–≤–µ—Ç–æ–≤,
–æ–±–µ—Å–ø–µ—á–∏–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—é –∏ —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—é.
"""

import time
from typing import Any, Dict, List, Optional, Union
from typing_extensions import Annotated
from pydantic import BaseModel, Field


# ==================================================================================================
# –ú–æ–¥–µ–ª–∏ –¥–ª—è /v1/models endpoint
# ==================================================================================================

class OpenAIModel(BaseModel):
    """
    –ú–æ–¥–µ–ª—å –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–ø–∏—Å–∞–Ω–∏—è AI –º–æ–¥–µ–ª–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –æ—Ç–≤–µ—Ç–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞ /v1/models.
    """
    id: str
    object: str = "model"
    created: int = Field(default_factory=lambda: int(time.time()))
    owned_by: str = "anthropic"
    description: Optional[str] = None


class ModelList(BaseModel):
    """
    –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI.
    
    –û—Ç–≤–µ—Ç —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞ GET /v1/models.
    """
    object: str = "list"
    data: List[OpenAIModel]


# ==================================================================================================
# –ú–æ–¥–µ–ª–∏ –¥–ª—è /v1/chat/completions endpoint
# ==================================================================================================

class ChatMessage(BaseModel):
    """
    –°–æ–æ–±—â–µ–Ω–∏–µ –≤ —á–∞—Ç–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI.
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ä–æ–ª–∏ (user, assistant, system, tool)
    –∏ —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (—Å—Ç—Ä–æ–∫–∞, —Å–ø–∏—Å–æ–∫, –æ–±—ä–µ–∫—Ç).
    
    Attributes:
        role: –†–æ–ª—å –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è (user, assistant, system, tool)
        content: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–æ–æ–±—â–µ–Ω–∏—è (–º–æ–∂–µ—Ç –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π, —Å–ø–∏—Å–∫–æ–º –∏–ª–∏ None)
        name: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –∏–º—è –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è
        tool_calls: –°–ø–∏—Å–æ–∫ –≤—ã–∑–æ–≤–æ–≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ (–¥–ª—è assistant)
        tool_call_id: ID –≤—ã–∑–æ–≤–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ (–¥–ª—è tool)
    """
    role: str
    content: Optional[Union[str, List[Any], Any]] = None
    name: Optional[str] = None
    tool_calls: Optional[List[Any]] = None
    tool_call_id: Optional[str] = None
    
    model_config = {"extra": "allow"}


class ToolFunction(BaseModel):
    """
    –û–ø–∏—Å–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞.
    
    Attributes:
        name: –ò–º—è —Ñ—É–Ω–∫—Ü–∏–∏
        description: –û–ø–∏—Å–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏
        parameters: JSON Schema –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏
    """
    name: str
    description: Optional[str] = None
    parameters: Optional[Dict[str, Any]] = None


class Tool(BaseModel):
    """
    –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç (tool) –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI.
    
    Attributes:
        type: –¢–∏–ø –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ (–æ–±—ã—á–Ω–æ "function")
        function: –û–ø–∏—Å–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏
    """
    type: str = "function"
    function: ToolFunction


class ChatCompletionRequest(BaseModel):
    """
    –ó–∞–ø—Ä–æ—Å –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –æ—Ç–≤–µ—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI Chat Completions API.
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤—Å–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–æ–ª—è OpenAI API, –≤–∫–ª—é—á–∞—è:
    - –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (model, messages, stream)
    - –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (temperature, top_p, max_tokens)
    - Tools (function calling)
    - –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–∏–≥–Ω–æ—Ä–∏—Ä—É—é—Ç—Å—è, –Ω–æ –ø—Ä–∏–Ω–∏–º–∞—é—Ç—Å—è –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
    
    Attributes:
        model: ID –º–æ–¥–µ–ª–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π —á–∞—Ç–∞
        stream: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å streaming (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é False)
        temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (0-2)
        top_p: Top-p sampling
        n: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –æ—Ç–≤–µ—Ç–∞
        max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ
        max_completion_tokens: –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ –ø–æ–ª–µ –¥–ª—è max_tokens
        stop: –°—Ç–æ–ø-–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        presence_penalty: –®—Ç—Ä–∞—Ñ –∑–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ —Ç–µ–º
        frequency_penalty: –®—Ç—Ä–∞—Ñ –∑–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ —Å–ª–æ–≤
        tools: –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        tool_choice: –°—Ç—Ä–∞—Ç–µ–≥–∏—è –≤—ã–±–æ—Ä–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
    """
    model: str
    messages: Annotated[List[ChatMessage], Field(min_length=1)]
    stream: bool = False
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
    temperature: Optional[float] = None
    top_p: Optional[float] = None
    n: Optional[int] = 1
    max_tokens: Optional[int] = None
    max_completion_tokens: Optional[int] = None
    stop: Optional[Union[str, List[str]]] = None
    presence_penalty: Optional[float] = None
    frequency_penalty: Optional[float] = None
    
    # Tools (function calling)
    tools: Optional[List[Tool]] = None
    tool_choice: Optional[Union[str, Dict]] = None
    
    # –ü–æ–ª—è –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ (–∏–≥–Ω–æ—Ä–∏—Ä—É—é—Ç—Å—è)
    stream_options: Optional[Dict[str, Any]] = None
    logit_bias: Optional[Dict[str, float]] = None
    logprobs: Optional[bool] = None
    top_logprobs: Optional[int] = None
    user: Optional[str] = None
    seed: Optional[int] = None
    parallel_tool_calls: Optional[bool] = None
    
    model_config = {"extra": "allow"}


# ==================================================================================================
# –ú–æ–¥–µ–ª–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤
# ==================================================================================================

class ChatCompletionChoice(BaseModel):
    """
    –û–¥–∏–Ω –≤–∞—Ä–∏–∞–Ω—Ç –æ—Ç–≤–µ—Ç–∞ –≤ Chat Completion.
    
    Attributes:
        index: –ò–Ω–¥–µ–∫—Å –≤–∞—Ä–∏–∞–Ω—Ç–∞
        message: –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
        finish_reason: –ü—Ä–∏—á–∏–Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è (stop, tool_calls, length)
    """
    index: int = 0
    message: Dict[str, Any]
    finish_reason: Optional[str] = None


class ChatCompletionUsage(BaseModel):
    """
    –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤.
    
    Attributes:
        prompt_tokens: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∑–∞–ø—Ä–æ—Å–µ
        completion_tokens: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ
        total_tokens: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
        credits_used: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –∫—Ä–µ–¥–∏—Ç—ã (—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ –¥–ª—è Kiro)
    """
    prompt_tokens: int = 0
    completion_tokens: int = 0
    total_tokens: int = 0
    credits_used: Optional[float] = None


class ChatCompletionResponse(BaseModel):
    """
    –ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç Chat Completion (non-streaming).
    
    Attributes:
        id: –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –æ—Ç–≤–µ—Ç–∞
        object: –¢–∏–ø –æ–±—ä–µ–∫—Ç–∞ ("chat.completion")
        created: Timestamp —Å–æ–∑–¥–∞–Ω–∏—è
        model: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        choices: –°–ø–∏—Å–æ–∫ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –æ—Ç–≤–µ—Ç–∞
        usage: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ —Ç–æ–∫–µ–Ω–æ–≤
    """
    id: str
    object: str = "chat.completion"
    created: int = Field(default_factory=lambda: int(time.time()))
    model: str
    choices: List[ChatCompletionChoice]
    usage: ChatCompletionUsage


class ChatCompletionChunkDelta(BaseModel):
    """
    –î–µ–ª—å—Ç–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ streaming chunk.
    
    Attributes:
        role: –†–æ–ª—å (—Ç–æ–ª—å–∫–æ –≤ –ø–µ—Ä–≤–æ–º chunk)
        content: –ù–æ–≤—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
        tool_calls: –ù–æ–≤—ã–µ tool calls
    """
    role: Optional[str] = None
    content: Optional[str] = None
    tool_calls: Optional[List[Dict[str, Any]]] = None


class ChatCompletionChunkChoice(BaseModel):
    """
    –û–¥–∏–Ω –≤–∞—Ä–∏–∞–Ω—Ç –≤ streaming chunk.
    
    Attributes:
        index: –ò–Ω–¥–µ–∫—Å –≤–∞—Ä–∏–∞–Ω—Ç–∞
        delta: –î–µ–ª—å—Ç–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π
        finish_reason: –ü—Ä–∏—á–∏–Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è (—Ç–æ–ª—å–∫–æ –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–º chunk)
    """
    index: int = 0
    delta: ChatCompletionChunkDelta
    finish_reason: Optional[str] = None


class ChatCompletionChunk(BaseModel):
    """
    Streaming chunk –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI.
    
    Attributes:
        id: –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID –æ—Ç–≤–µ—Ç–∞
        object: –¢–∏–ø –æ–±—ä–µ–∫—Ç–∞ ("chat.completion.chunk")
        created: Timestamp —Å–æ–∑–¥–∞–Ω–∏—è
        model: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        choices: –°–ø–∏—Å–æ–∫ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
        usage: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ (—Ç–æ–ª—å–∫–æ –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–º chunk)
    """
    id: str
    object: str = "chat.completion.chunk"
    created: int = Field(default_factory=lambda: int(time.time()))
    model: str
    choices: List[ChatCompletionChunkChoice]
    usage: Optional[ChatCompletionUsage] = None


================================================
FILE: kiro_gateway/parsers.py
================================================
# -*- coding: utf-8 -*-

# Kiro OpenAI Gateway
# Copyright (C) 2025 Jwadow
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

"""
–ü–∞—Ä—Å–µ—Ä—ã –¥–ª—è AWS Event Stream —Ñ–æ—Ä–º–∞—Ç–∞.

–°–æ–¥–µ—Ä–∂–∏—Ç –∫–ª–∞—Å—Å—ã –∏ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è:
- –ü–∞—Ä—Å–∏–Ω–≥–∞ –±–∏–Ω–∞—Ä–Ω–æ–≥–æ AWS SSE –ø–æ—Ç–æ–∫–∞
- –ò–∑–≤–ª–µ—á–µ–Ω–∏—è JSON —Å–æ–±—ã—Ç–∏–π
- –û–±—Ä–∞–±–æ—Ç–∫–∏ tool calls
- –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
"""

import json
import re
from typing import Any, Dict, List, Optional

from loguru import logger

from kiro_gateway.utils import generate_tool_call_id


def find_matching_brace(text: str, start_pos: int) -> int:
    """
    –ù–∞—Ö–æ–¥–∏—Ç –ø–æ–∑–∏—Ü–∏—é –∑–∞–∫—Ä—ã–≤–∞—é—â–µ–π —Å–∫–æ–±–∫–∏ —Å —É—á—ë—Ç–æ–º –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏ –∏ —Å—Ç—Ä–æ–∫.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç bracket counting –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö JSON.
    –£—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ç—Ä–æ–∫–∏ –≤ –∫–∞–≤—ã—á–∫–∞—Ö –∏ escape-–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.
    
    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞
        start_pos: –ü–æ–∑–∏—Ü–∏—è –æ—Ç–∫—Ä—ã–≤–∞—é—â–µ–π —Å–∫–æ–±–∫–∏ '{'
    
    Returns:
        –ü–æ–∑–∏—Ü–∏—è –∑–∞–∫—Ä—ã–≤–∞—é—â–µ–π —Å–∫–æ–±–∫–∏ –∏–ª–∏ -1 –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞
    
    Example:
        >>> find_matching_brace('{"a": {"b": 1}}', 0)
        14
        >>> find_matching_brace('{"a": "{}"}', 0)
        10
    """
    if start_pos >= len(text) or text[start_pos] != '{':
        return -1
    
    brace_count = 0
    in_string = False
    escape_next = False
    
    for i in range(start_pos, len(text)):
        char = text[i]
        
        if escape_next:
            escape_next = False
            continue
        
        if char == '\\' and in_string:
            escape_next = True
            continue
        
        if char == '"' and not escape_next:
            in_string = not in_string
            continue
        
        if not in_string:
            if char == '{':
                brace_count += 1
            elif char == '}':
                brace_count -= 1
                if brace_count == 0:
                    return i
    
    return -1


def parse_bracket_tool_calls(response_text: str) -> List[Dict[str, Any]]:
    """
    –ü–∞—Ä—Å–∏—Ç tool calls –≤ —Ñ–æ—Ä–º–∞—Ç–µ [Called func_name with args: {...}].
    
    –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª–∏ –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç tool calls –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ –≤–º–µ—Å—Ç–æ
    —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ JSON. –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∏—Ö.
    
    Args:
        response_text: –¢–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞ –º–æ–¥–µ–ª–∏
    
    Returns:
        –°–ø–∏—Å–æ–∫ tool calls –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI
    
    Example:
        >>> text = "[Called get_weather with args: {\"city\": \"London\"}]"
        >>> calls = parse_bracket_tool_calls(text)
        >>> calls[0]["function"]["name"]
        'get_weather'
    """
    if not response_text or "[Called" not in response_text:
        return []
    
    tool_calls = []
    pattern = r'\[Called\s+(\w+)\s+with\s+args:\s*'
    
    for match in re.finditer(pattern, response_text, re.IGNORECASE):
        func_name = match.group(1)
        args_start = match.end()
        
        # –ò—â–µ–º –Ω–∞—á–∞–ª–æ JSON
        json_start = response_text.find('{', args_start)
        if json_start == -1:
            continue
        
        # –ò—â–µ–º –∫–æ–Ω–µ—Ü JSON —Å —É—á—ë—Ç–æ–º –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏
        json_end = find_matching_brace(response_text, json_start)
        if json_end == -1:
            continue
        
        json_str = response_text[json_start:json_end + 1]
        
        try:
            args = json.loads(json_str)
            tool_call_id = generate_tool_call_id()
            # index –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω –ø–æ–∑–∂–µ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
            tool_calls.append({
                "id": tool_call_id,
                "type": "function",
                "function": {
                    "name": func_name,
                    "arguments": json.dumps(args)
                }
            })
        except json.JSONDecodeError:
            logger.warning(f"Failed to parse tool call arguments: {json_str[:100]}")
    
    return tool_calls


def deduplicate_tool_calls(tool_calls: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    –£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã tool calls.
    
    –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø–æ –¥–≤—É–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º:
    1. –ü–æ id - –µ—Å–ª–∏ –µ—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ tool calls —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º id, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ—Ç —É –∫–æ—Ç–æ—Ä–æ–≥–æ
       –±–æ–ª—å—à–µ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ (–Ω–µ –ø—É—Å—Ç–æ–π "{}")
    2. –ü–æ name+arguments - —É–¥–∞–ª—è–µ–º –ø–æ–ª–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã
    
    Args:
        tool_calls: –°–ø–∏—Å–æ–∫ tool calls
    
    Returns:
        –°–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö tool calls
    """
    # –°–Ω–∞—á–∞–ª–∞ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ id - –æ—Å—Ç–∞–≤–ª—è–µ–º tool call —Å –Ω–µ–ø—É—Å—Ç—ã–º–∏ –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏
    by_id: Dict[str, Dict[str, Any]] = {}
    for tc in tool_calls:
        tc_id = tc.get("id", "")
        if not tc_id:
            # –ë–µ–∑ id - –¥–æ–±–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å (–±—É–¥–µ—Ç –¥–µ–¥—É–ø–ª–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ –ø–æ name+args)
            continue
        
        existing = by_id.get(tc_id)
        if existing is None:
            by_id[tc_id] = tc
        else:
            # –ï—Å—Ç—å –¥—É–±–ª–∏–∫–∞—Ç –ø–æ id - –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ—Ç —É –∫–æ—Ç–æ—Ä–æ–≥–æ –±–æ–ª—å—à–µ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
            existing_args = existing.get("function", {}).get("arguments", "{}")
            current_args = tc.get("function", {}).get("arguments", "{}")
            
            # –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º –Ω–µ–ø—É—Å—Ç—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã
            if current_args != "{}" and (existing_args == "{}" or len(current_args) > len(existing_args)):
                logger.debug(f"Replacing tool call {tc_id} with better arguments: {len(existing_args)} -> {len(current_args)}")
                by_id[tc_id] = tc
    
    # –°–æ–±–∏—Ä–∞–µ–º tool calls: —Å–Ω–∞—á–∞–ª–∞ —Ç–µ —á—Ç–æ —Å id, –ø–æ—Ç–æ–º –±–µ–∑ id
    result_with_id = list(by_id.values())
    result_without_id = [tc for tc in tool_calls if not tc.get("id")]
    
    # –¢–µ–ø–µ—Ä—å –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ name+arguments –¥–ª—è –≤—Å–µ—Ö
    seen = set()
    unique = []
    
    for tc in result_with_id + result_without_id:
        # –ó–∞—â–∏—Ç–∞ –æ—Ç None –≤ function
        func = tc.get("function") or {}
        func_name = func.get("name") or ""
        func_args = func.get("arguments") or "{}"
        key = f"{func_name}-{func_args}"
        if key not in seen:
            seen.add(key)
            unique.append(tc)
    
    if len(tool_calls) != len(unique):
        logger.debug(f"Deduplicated tool calls: {len(tool_calls)} -> {len(unique)}")
    
    return unique


class AwsEventStreamParser:
    """
    –ü–∞—Ä—Å–µ—Ä –¥–ª—è AWS Event Stream —Ñ–æ—Ä–º–∞—Ç–∞.
    
    AWS –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–æ–±—ã—Ç–∏—è –≤ –±–∏–Ω–∞—Ä–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏ :message-type...event.
    –≠—Ç–æ—Ç –∫–ª–∞—Å—Å –∏–∑–≤–ª–µ–∫–∞–µ—Ç JSON —Å–æ–±—ã—Ç–∏—è –∏–∑ –ø–æ—Ç–æ–∫–∞ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∏—Ö –≤ —É–¥–æ–±–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç.
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ç–∏–ø—ã —Å–æ–±—ã—Ç–∏–π:
    - content: –¢–µ–∫—Å—Ç–æ–≤—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –æ—Ç–≤–µ—Ç–∞
    - tool_start: –ù–∞—á–∞–ª–æ tool call (name, toolUseId)
    - tool_input: –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ input –¥–ª—è tool call
    - tool_stop: –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ tool call
    - usage: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–∏ –∫—Ä–µ–¥–∏—Ç–æ–≤
    - context_usage: –ü—Ä–æ—Ü–µ–Ω—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    
    Attributes:
        buffer: –ë—É—Ñ–µ—Ä –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
        last_content: –ü–æ—Å–ª–µ–¥–Ω–∏–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç (–¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏)
        current_tool_call: –¢–µ–∫—É—â–∏–π –Ω–µ–∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã–π tool call
        tool_calls: –°–ø–∏—Å–æ–∫ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã—Ö tool calls
    
    Example:
        >>> parser = AwsEventStreamParser()
        >>> events = parser.feed(chunk)
        >>> for event in events:
        ...     if event["type"] == "content":
        ...         print(event["data"])
    """
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ JSON —Å–æ–±—ã—Ç–∏–π
    EVENT_PATTERNS = [
        ('{"content":', 'content'),
        ('{"name":', 'tool_start'),
        ('{"input":', 'tool_input'),
        ('{"stop":', 'tool_stop'),
        ('{"followupPrompt":', 'followup'),
        ('{"usage":', 'usage'),
        ('{"contextUsagePercentage":', 'context_usage'),
    ]
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–∞—Ä—Å–µ—Ä."""
        self.buffer = ""
        self.last_content: Optional[str] = None  # –î–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –ø–æ–≤—Ç–æ—Ä—è—é—â–µ–≥–æ—Å—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        self.current_tool_call: Optional[Dict[str, Any]] = None
        self.tool_calls: List[Dict[str, Any]] = []
    
    def feed(self, chunk: bytes) -> List[Dict[str, Any]]:
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç chunk –≤ –±—É—Ñ–µ—Ä –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è.
        
        Args:
            chunk: –ë–∞–π—Ç—ã –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ø–æ—Ç–æ–∫–∞
        
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–æ–±—ã—Ç–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ {"type": str, "data": Any}
        """
        try:
            self.buffer += chunk.decode('utf-8', errors='ignore')
        except Exception:
            return []
        
        events = []
        
        while True:
            # –ù–∞—Ö–æ–¥–∏–º –±–ª–∏–∂–∞–π—à–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω
            earliest_pos = -1
            earliest_type = None
            
            for pattern, event_type in self.EVENT_PATTERNS:
                pos = self.buffer.find(pattern)
                if pos != -1 and (earliest_pos == -1 or pos < earliest_pos):
                    earliest_pos = pos
                    earliest_type = event_type
            
            if earliest_pos == -1:
                break
            
            # –ò—â–µ–º –∫–æ–Ω–µ—Ü JSON
            json_end = find_matching_brace(self.buffer, earliest_pos)
            if json_end == -1:
                # JSON –Ω–µ –ø–æ–ª–Ω—ã–π, –∂–¥—ë–º –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö
                break
            
            json_str = self.buffer[earliest_pos:json_end + 1]
            self.buffer = self.buffer[json_end + 1:]
            
            try:
                data = json.loads(json_str)
                event = self._process_event(data, earliest_type)
                if event:
                    events.append(event)
            except json.JSONDecodeError:
                logger.warning(f"Failed to parse JSON: {json_str[:100]}")
        
        return events
    
    def _process_event(self, data: dict, event_type: str) -> Optional[Dict[str, Any]]:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω–æ–µ —Å–æ–±—ã—Ç–∏–µ.
        
        Args:
            data: –†–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–π JSON
            event_type: –¢–∏–ø —Å–æ–±—ã—Ç–∏—è
        
        Returns:
            –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ —Å–æ–±—ã—Ç–∏–µ –∏–ª–∏ None
        """
        if event_type == 'content':
            return self._process_content_event(data)
        elif event_type == 'tool_start':
            return self._process_tool_start_event(data)
        elif event_type == 'tool_input':
            return self._process_tool_input_event(data)
        elif event_type == 'tool_stop':
            return self._process_tool_stop_event(data)
        elif event_type == 'usage':
            return {"type": "usage", "data": data.get('usage', 0)}
        elif event_type == 'context_usage':
            return {"type": "context_usage", "data": data.get('contextUsagePercentage', 0)}
        
        return None
    
    def _process_content_event(self, data: dict) -> Optional[Dict[str, Any]]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–æ–±—ã—Ç–∏–µ —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º."""
        content = data.get('content', '')
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º followupPrompt
        if data.get('followupPrompt'):
            return None
        
        # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ–≤—Ç–æ—Ä—è—é—â–µ–≥–æ—Å—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        if content == self.last_content:
            return None
        
        self.last_content = content
        
        return {"type": "content", "data": content}
    
    def _process_tool_start_event(self, data: dict) -> Optional[Dict[str, Any]]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–∞—á–∞–ª–æ tool call."""
        # –ó–∞–≤–µ—Ä—à–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π tool call –µ—Å–ª–∏ –µ—Å—Ç—å
        if self.current_tool_call:
            self._finalize_tool_call()
        
        # input –º–æ–∂–µ—Ç –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π –∏–ª–∏ –æ–±—ä–µ–∫—Ç–æ–º
        input_data = data.get('input', '')
        if isinstance(input_data, dict):
            input_str = json.dumps(input_data)
        else:
            input_str = str(input_data) if input_data else ''
        
        self.current_tool_call = {
            "id": data.get('toolUseId', generate_tool_call_id()),
            "type": "function",
            "function": {
                "name": data.get('name', ''),
                "arguments": input_str
            }
        }
        
        if data.get('stop'):
            self._finalize_tool_call()
        
        return None
    
    def _process_tool_input_event(self, data: dict) -> Optional[Dict[str, Any]]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ input –¥–ª—è tool call."""
        if self.current_tool_call:
            # input –º–æ–∂–µ—Ç –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π –∏–ª–∏ –æ–±—ä–µ–∫—Ç–æ–º
            input_data = data.get('input', '')
            if isinstance(input_data, dict):
                input_str = json.dumps(input_data)
            else:
                input_str = str(input_data) if input_data else ''
            self.current_tool_call['function']['arguments'] += input_str
        return None
    
    def _process_tool_stop_event(self, data: dict) -> Optional[Dict[str, Any]]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ tool call."""
        if self.current_tool_call and data.get('stop'):
            self._finalize_tool_call()
        return None
    
    def _finalize_tool_call(self) -> None:
        """–ó–∞–≤–µ—Ä—à–∞–µ—Ç —Ç–µ–∫—É—â–∏–π tool call –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –≤ —Å–ø–∏—Å–æ–∫."""
        if not self.current_tool_call:
            return
        
        # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å arguments –∫–∞–∫ JSON
        args = self.current_tool_call['function']['arguments']
        tool_name = self.current_tool_call['function'].get('name', 'unknown')
        
        logger.debug(f"Finalizing tool call '{tool_name}' with raw arguments: {repr(args)[:200]}")
        
        if isinstance(args, str):
            if args.strip():
                try:
                    parsed = json.loads(args)
                    # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç - —Å—Ç—Ä–æ–∫–∞ JSON
                    self.current_tool_call['function']['arguments'] = json.dumps(parsed)
                    logger.debug(f"Tool '{tool_name}' arguments parsed successfully: {list(parsed.keys()) if isinstance(parsed, dict) else type(parsed)}")
                except json.JSONDecodeError as e:
                    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å, –æ—Å—Ç–∞–≤–ª—è–µ–º –ø—É—Å—Ç–æ–π –æ–±—ä–µ–∫—Ç
                    logger.warning(f"Failed to parse tool '{tool_name}' arguments: {e}. Raw: {args[:200]}")
                    self.current_tool_call['function']['arguments'] = "{}"
            else:
                # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—É—Å—Ç–æ–π –æ–±—ä–µ–∫—Ç
                # –≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ –¥–ª—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ tool calls –æ—Ç Kiro
                logger.debug(f"Tool '{tool_name}' has empty arguments string (will be deduplicated)")
                self.current_tool_call['function']['arguments'] = "{}"
        elif isinstance(args, dict):
            # –ï—Å–ª–∏ —É–∂–µ –æ–±—ä–µ–∫—Ç - —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º –≤ —Å—Ç—Ä–æ–∫—É
            self.current_tool_call['function']['arguments'] = json.dumps(args)
            logger.debug(f"Tool '{tool_name}' arguments already dict with keys: {list(args.keys())}")
        else:
            # –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø - –ø—É—Å—Ç–æ–π –æ–±—ä–µ–∫—Ç
            logger.warning(f"Tool '{tool_name}' has unexpected arguments type: {type(args)}")
            self.current_tool_call['function']['arguments'] = "{}"
        
        self.tool_calls.append(self.current_tool_call)
        self.current_tool_call = None
    
    def get_tool_calls(self) -> List[Dict[str, Any]]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ —Å–æ–±—Ä–∞–Ω–Ω—ã–µ tool calls.
        
        –ó–∞–≤–µ—Ä—à–∞–µ—Ç —Ç–µ–∫—É—â–∏–π tool call –µ—Å–ª–∏ –æ–Ω –Ω–µ –∑–∞–≤–µ—Ä—à—ë–Ω.
        –£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã.
        
        Returns:
            –°–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö tool calls
        """
        if self.current_tool_call:
            self._finalize_tool_call()
        return deduplicate_tool_calls(self.tool_calls)
    
    def reset(self) -> None:
        """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–∞—Ä—Å–µ—Ä–∞."""
        self.buffer = ""
        self.last_content = None
        self.current_tool_call = None
        self.tool_calls = []


================================================
FILE: kiro_gateway/routes.py
================================================
# -*- coding: utf-8 -*-

# Kiro OpenAI Gateway
# https://github.com/jwadow/kiro-openai-gateway
# Copyright (C) 2025 Jwadow
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

"""
FastAPI routes for Kiro Gateway.

Contains all API endpoints:
- / and /health: Health check
- /v1/models: Models list
- /v1/chat/completions: Chat completions
"""

import json
from datetime import datetime, timezone

import httpx
from fastapi import APIRouter, Depends, HTTPException, Request, Response, Security
from fastapi.responses import JSONResponse, StreamingResponse
from fastapi.security import APIKeyHeader
from loguru import logger

from kiro_gateway.config import (
    PROXY_API_KEY,
    AVAILABLE_MODELS,
    APP_VERSION,
)
from kiro_gateway.models import (
    OpenAIModel,
    ModelList,
    ChatCompletionRequest,
)
from kiro_gateway.auth import KiroAuthManager
from kiro_gateway.cache import ModelInfoCache
from kiro_gateway.converters import build_kiro_payload
from kiro_gateway.streaming import stream_kiro_to_openai, collect_stream_response, stream_with_first_token_retry
from kiro_gateway.http_client import KiroHttpClient
from kiro_gateway.utils import get_kiro_headers, generate_conversation_id

# Import debug_logger
try:
    from kiro_gateway.debug_logger import debug_logger
except ImportError:
    debug_logger = None


# --- Security scheme ---
api_key_header = APIKeyHeader(name="Authorization", auto_error=False)


async def verify_api_key(auth_header: str = Security(api_key_header)) -> bool:
    """
    Verify API key in Authorization header.
    
    Expects format: "Bearer {PROXY_API_KEY}"
    
    Args:
        auth_header: Authorization header value
    
    Returns:
        True if key is valid
    
    Raises:
        HTTPException: 401 if key is invalid or missing
    """
    if not auth_header or auth_header != f"Bearer {PROXY_API_KEY}":
        logger.warning("Access attempt with invalid API key.")
        raise HTTPException(status_code=401, detail="Invalid or missing API Key")
    return True


# --- Router ---
router = APIRouter()


@router.get("/")
async def root():
    """
    Health check endpoint.
    
    Returns:
        Status and application version
    """
    return {
        "status": "ok",
        "message": "Kiro API Gateway is running",
        "version": APP_VERSION
    }


@router.get("/health")
async def health():
    """
    Detailed health check.
    
    Returns:
        Status, timestamp and version
    """
    return {
        "status": "healthy",
        "timestamp": datetime.now(timezone.utc).isoformat(),
        "version": APP_VERSION
    }


@router.get("/v1/models", response_model=ModelList, dependencies=[Depends(verify_api_key)])
async def get_models(request: Request):
    """
    Return list of available models.
    
    Uses static model list with ability to update from API.
    Caches results to reduce API load.
    
    Args:
        request: FastAPI Request for accessing app.state
    
    Returns:
        ModelList with available models
    """
    logger.info("Request to /v1/models")
    
    auth_manager: KiroAuthManager = request.app.state.auth_manager
    model_cache: ModelInfoCache = request.app.state.model_cache
    
    # Try to get models from API if cache is empty or stale
    if model_cache.is_empty() or model_cache.is_stale():
        try:
            token = await auth_manager.get_access_token()
            headers = get_kiro_headers(auth_manager, token)
            
            async with httpx.AsyncClient(timeout=30) as client:
                response = await client.get(
                    f"{auth_manager.q_host}/ListAvailableModels",
                    headers=headers,
                    params={
                        "origin": "AI_EDITOR",
                        "profileArn": auth_manager.profile_arn or ""
                    }
                )
                
                if response.status_code == 200:
                    data = response.json()
                    models_list = data.get("models", [])
                    await model_cache.update(models_list)
                    logger.info(f"Received {len(models_list)} models from API")
        except Exception as e:
            logger.warning(f"Failed to fetch models from API: {e}")
    
    # Return static model list
    openai_models = [
        OpenAIModel(
            id=model_id,
            owned_by="anthropic",
            description="Claude model via Kiro API"
        )
        for model_id in AVAILABLE_MODELS
    ]
    
    return ModelList(data=openai_models)


@router.post("/v1/chat/completions", dependencies=[Depends(verify_api_key)])
async def chat_completions(request: Request, request_data: ChatCompletionRequest):
    """
    Chat completions endpoint - compatible with OpenAI API.
    
    Accepts requests in OpenAI format and translates them to Kiro API.
    Supports streaming and non-streaming modes.
    
    Args:
        request: FastAPI Request for accessing app.state
        request_data: Request in OpenAI ChatCompletionRequest format
    
    Returns:
        StreamingResponse for streaming mode
        JSONResponse for non-streaming mode
    
    Raises:
        HTTPException: On validation or API errors
    """
    logger.info(f"Request to /v1/chat/completions (model={request_data.model}, stream={request_data.stream})")
    
    auth_manager: KiroAuthManager = request.app.state.auth_manager
    model_cache: ModelInfoCache = request.app.state.model_cache
    
    # Prepare debug logs
    if debug_logger:
        debug_logger.prepare_new_request()
    
    # Log incoming request
    try:
        request_body = json.dumps(request_data.model_dump(), ensure_ascii=False, indent=2).encode('utf-8')
        if debug_logger:
            debug_logger.log_request_body(request_body)
    except Exception as e:
        logger.warning(f"Failed to log request body: {e}")
    
    # Lazy model cache population
    if model_cache.is_empty():
        logger.debug("Model cache is empty, skipping forced population")
    
    # Generate conversation ID
    conversation_id = generate_conversation_id()
    
    # Build payload for Kiro
    try:
        kiro_payload = build_kiro_payload(
            request_data,
            conversation_id,
            auth_manager.profile_arn or ""
        )
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    
    # Log Kiro payload
    try:
        kiro_request_body = json.dumps(kiro_payload, ensure_ascii=False, indent=2).encode('utf-8')
        if debug_logger:
            debug_logger.log_kiro_request_body(kiro_request_body)
    except Exception as e:
        logger.warning(f"Failed to log Kiro request: {e}")
    
    # Create HTTP client with retry logic
    http_client = KiroHttpClient(auth_manager)
    url = f"{auth_manager.api_host}/generateAssistantResponse"
    try:
        # Make request to Kiro API (for both streaming and non-streaming modes)
        # Important: we wait for Kiro response BEFORE returning StreamingResponse,
        # so that 200 OK means Kiro accepted the request and started responding
        response = await http_client.request_with_retry(
            "POST",
            url,
            kiro_payload,
            stream=True
        )
        
        if response.status_code != 200:
            try:
                error_content = await response.aread()
            except Exception:
                error_content = b"Unknown error"
            
            await http_client.close()
            error_text = error_content.decode('utf-8', errors='replace')
            logger.error(f"Error from Kiro API: {response.status_code} - {error_text}")
            
            # Try to parse JSON response from Kiro to extract error message
            error_message = error_text
            try:
                error_json = json.loads(error_text)
                if "message" in error_json:
                    error_message = error_json["message"]
                    if "reason" in error_json:
                        error_message = f"{error_message} (reason: {error_json['reason']})"
            except (json.JSONDecodeError, KeyError):
                pass
            
            # Log access log for error (before flush, so it gets into app_logs)
            logger.warning(
                f"HTTP {response.status_code} - POST /v1/chat/completions - {error_message[:100]}"
            )
            
            # Flush debug logs on error ("errors" mode)
            if debug_logger:
                debug_logger.flush_on_error(response.status_code, error_message)
            
            # Return error in OpenAI API format
            return JSONResponse(
                status_code=response.status_code,
                content={
                    "error": {
                        "message": error_message,
                        "type": "kiro_api_error",
                        "code": response.status_code
                    }
                }
            )
        
        # Prepare data for fallback token counting
        # Convert Pydantic models to dicts for tokenizer
        messages_for_tokenizer = [msg.model_dump() for msg in request_data.messages]
        tools_for_tokenizer = [tool.model_dump() for tool in request_data.tools] if request_data.tools else None
        
        if request_data.stream:
            # Streaming mode
            async def stream_wrapper():
                streaming_error = None
                client_disconnected = False
                try:
                    async for chunk in stream_kiro_to_openai(
                        http_client.client,
                        response,
                        request_data.model,
                        model_cache,
                        auth_manager,
                        request_messages=messages_for_tokenizer,
                        request_tools=tools_for_tokenizer
                    ):
                        yield chunk
                except GeneratorExit:
                    # Client disconnected - this is normal
                    client_disconnected = True
                    logger.debug("Client disconnected during streaming (GeneratorExit in routes)")
                except Exception as e:
                    streaming_error = e
                    # Try to send [DONE] to client before finishing
                    # so client doesn't "hang" waiting for data
                    try:
                        yield "data: [DONE]\n\n"
                    except Exception:
                        pass  # Client already disconnected
                    raise
                finally:
                    await http_client.close()
                    # Log access log for streaming (success or error)
                    if streaming_error:
                        error_type = type(streaming_error).__name__
                        error_msg = str(streaming_error) if str(streaming_error) else "(empty message)"
                        logger.error(f"HTTP 500 - POST /v1/chat/completions (streaming) - [{error_type}] {error_msg[:100]}")
                    elif client_disconnected:
                        logger.info(f"HTTP 200 - POST /v1/chat/completions (streaming) - client disconnected")
                    else:
                        logger.info(f"HTTP 200 - POST /v1/chat/completions (streaming) - completed")
                    # Write debug logs AFTER streaming completes
                    if debug_logger:
                        if streaming_error:
                            debug_logger.flush_on_error(500, str(streaming_error))
                        else:
                            debug_logger.discard_buffers()
            
            return StreamingResponse(stream_wrapper(), media_type="text/event-stream")
        
        else:
            
            # Non-streaming mode - collect entire response
            openai_response = await collect_stream_response(
                http_client.client,
                response,
                request_data.model,
                model_cache,
                auth_manager,
                request_messages=messages_for_tokenizer,
                request_tools=tools_for_tokenizer
            )
            
            await http_client.close()
            
            # Log access log for non-streaming success
            logger.info(f"HTTP 200 - POST /v1/chat/completions (non-streaming) - completed")
            
            # Write debug logs after non-streaming request completes
            if debug_logger:
                debug_logger.discard_buffers()
            
            return JSONResponse(content=openai_response)
    
    except HTTPException as e:
        await http_client.close()
        # Log access log for HTTP error
        logger.warning(f"HTTP {e.status_code} - POST /v1/chat/completions - {e.detail}")
        # Flush debug logs on HTTP error ("errors" mode)
        if debug_logger:
            debug_logger.flush_on_error(e.status_code, str(e.detail))
        raise
    except Exception as e:
        await http_client.close()
        logger.error(f"Internal error: {e}", exc_info=True)
        # Log access log for internal error
        logger.error(f"HTTP 500 - POST /v1/chat/completions - {str(e)[:100]}")
        # Flush debug logs on internal error ("errors" mode)
        if debug_logger:
            debug_logger.flush_on_error(500, str(e))
        raise HTTPException(status_code=500, detail=f"Internal Server Error: {str(e)}")


================================================
FILE: kiro_gateway/streaming.py
================================================
# -*- coding: utf-8 -*-

# Kiro OpenAI Gateway
# https://github.com/jwadow/kiro-openai-gateway
# Copyright (C) 2025 Jwadow
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

"""
Streaming logic for converting Kiro stream to OpenAI format.

Contains generators for:
- Converting AWS SSE to OpenAI SSE
- Forming streaming chunks
- Processing tool calls in stream
"""

import asyncio
import json
import time
from typing import TYPE_CHECKING, AsyncGenerator, Callable, Awaitable, Optional

import httpx
from fastapi import HTTPException
from loguru import logger

from kiro_gateway.parsers import AwsEventStreamParser, parse_bracket_tool_calls, deduplicate_tool_calls
from kiro_gateway.utils import generate_completion_id
from kiro_gateway.config import FIRST_TOKEN_TIMEOUT, FIRST_TOKEN_MAX_RETRIES
from kiro_gateway.tokenizer import count_tokens, count_message_tokens, count_tools_tokens

if TYPE_CHECKING:
    from kiro_gateway.auth import KiroAuthManager
    from kiro_gateway.cache import ModelInfoCache

# Import debug_logger for logging
try:
    from kiro_gateway.debug_logger import debug_logger
except ImportError:
    debug_logger = None


class FirstTokenTimeoutError(Exception):
    """Exception raised when first token timeout occurs."""
    pass


async def stream_kiro_to_openai_internal(
    client: httpx.AsyncClient,
    response: httpx.Response,
    model: str,
    model_cache: "ModelInfoCache",
    auth_manager: "KiroAuthManager",
    first_token_timeout: float = FIRST_TOKEN_TIMEOUT,
    request_messages: Optional[list] = None,
    request_tools: Optional[list] = None
) -> AsyncGenerator[str, None]:
    """
    Internal generator for converting Kiro stream to OpenAI format.
    
    Parses AWS SSE stream and converts events to OpenAI chat.completion.chunk.
    Supports tool calls and usage calculation.
    
    IMPORTANT: This function raises FirstTokenTimeoutError if first token
    is not received within first_token_timeout seconds.
    
    Args:
        client: HTTP client (for connection management)
        response: HTTP response with data stream
        model: Model name to include in response
        model_cache: Model cache for getting token limits
        auth_manager: Authentication manager
        first_token_timeout: First token wait timeout (seconds)
        request_messages: Original request messages (for fallback token counting)
        request_tools: Original request tools (for fallback token counting)
    
    Yields:
        Strings in SSE format: "data: {...}\\n\\n" or "data: [DONE]\\n\\n"
    
    Raises:
        FirstTokenTimeoutError: If first token not received within timeout
    
    Example:
        >>> async for chunk in stream_kiro_to_openai_internal(client, response, "claude-sonnet-4", cache, auth):
        ...     print(chunk)
        data: {"id":"chatcmpl-...","object":"chat.completion.chunk",...}
        
        data: [DONE]
    """
    completion_id = generate_completion_id()
    created_time = int(time.time())
    first_chunk = True
    first_token_received = False
    
    parser = AwsEventStreamParser()
    metering_data = None
    context_usage_percentage = None
    full_content = ""
    
    streaming_error_occurred = False
    
    try:
        # Create iterator for reading bytes
        byte_iterator = response.aiter_bytes()
        
        # Wait for first chunk with timeout (FIRST_TOKEN_TIMEOUT)
        # This is our business logic for detecting "stuck" requests
        # where the model takes too long to start responding
        try:
            logger.debug(f"Waiting for first token (timeout={first_token_timeout}s)...")
            first_byte_chunk = await asyncio.wait_for(
                byte_iterator.__anext__(),
                timeout=first_token_timeout
            )
            logger.debug("First token received")
        except asyncio.TimeoutError:
            logger.warning(f"[FirstTokenTimeout] Model did not respond within {first_token_timeout}s")
            raise FirstTokenTimeoutError(f"No response within {first_token_timeout} seconds")
        except StopAsyncIteration:
            # Empty response - this is normal, just finish
            logger.debug("Empty response from Kiro API")
            yield "data: [DONE]\n\n"
            return
        
        # Process first chunk
        if debug_logger:
            debug_logger.log_raw_chunk(first_byte_chunk)
        
        events = parser.feed(first_byte_chunk)
        for event in events:
            if event["type"] == "content":
                first_token_received = True
                content = event["data"]
                full_content += content
                
                delta = {"content": content}
                if first_chunk:
                    delta["role"] = "assistant"
                    first_chunk = False
                
                openai_chunk = {
                    "id": completion_id,
                    "object": "chat.completion.chunk",
                    "created": created_time,
                    "model": model,
                    "choices": [{"index": 0, "delta": delta, "finish_reason": None}]
                }
                
                chunk_text = f"data: {json.dumps(openai_chunk, ensure_ascii=False)}\n\n"
                
                if debug_logger:
                    debug_logger.log_modified_chunk(chunk_text.encode('utf-8'))
                
                yield chunk_text
            
            elif event["type"] == "usage":
                metering_data = event["data"]
            
            elif event["type"] == "context_usage":
                context_usage_percentage = event["data"]
        
        # Continue reading remaining chunks (no longer with first token timeout)
        async for chunk in byte_iterator:
            # Log raw chunk
            if debug_logger:
                debug_logger.log_raw_chunk(chunk)
            
            events = parser.feed(chunk)
            
            for event in events:
                if event["type"] == "content":
                    content = event["data"]
                    full_content += content
                    
                    # Form delta
                    delta = {"content": content}
                    if first_chunk:
                        delta["role"] = "assistant"
                        first_chunk = False
                    
                    # Form OpenAI chunk
                    openai_chunk = {
                        "id": completion_id,
                        "object": "chat.completion.chunk",
                        "created": created_time,
                        "model": model,
                        "choices": [{"index": 0, "delta": delta, "finish_reason": None}]
                    }
                    
                    chunk_text = f"data: {json.dumps(openai_chunk, ensure_ascii=False)}\n\n"
                    
                    # Log modified chunk
                    if debug_logger:
                        debug_logger.log_modified_chunk(chunk_text.encode('utf-8'))
                    
                    yield chunk_text
                
                elif event["type"] == "usage":
                    metering_data = event["data"]
                
                elif event["type"] == "context_usage":
                    context_usage_percentage = event["data"]
        
        # Check bracket-style tool calls in full content
        bracket_tool_calls = parse_bracket_tool_calls(full_content)
        all_tool_calls = parser.get_tool_calls() + bracket_tool_calls
        all_tool_calls = deduplicate_tool_calls(all_tool_calls)
        
        # Determine finish_reason
        finish_reason = "tool_calls" if all_tool_calls else "stop"
        
        # Count completion_tokens (output) using tiktoken
        completion_tokens = count_tokens(full_content)
        
        # Calculate total_tokens based on context_usage_percentage from Kiro API
        # context_usage shows TOTAL percentage of context usage (input + output)
        total_tokens_from_api = 0
        if context_usage_percentage is not None and context_usage_percentage > 0:
            max_input_tokens = model_cache.get_max_input_tokens(model)
            total_tokens_from_api = int((context_usage_percentage / 100) * max_input_tokens)
        
        # Determine data source and calculate tokens
        if total_tokens_from_api > 0:
            # Use data from Kiro API
            # prompt_tokens (input) = total_tokens - completion_tokens
            prompt_tokens = max(0, total_tokens_from_api - completion_tokens)
            total_tokens = total_tokens_from_api
            prompt_source = "subtraction"
            total_source = "API Kiro"
        else:
            # Fallback: Kiro API didn't return context_usage, use tiktoken
            # Count prompt_tokens from original messages
            # IMPORTANT: Don't apply correction coefficient for prompt_tokens,
            # as it was calibrated for completion_tokens
            prompt_tokens = 0
            if request_messages:
                prompt_tokens += count_message_tokens(request_messages, apply_claude_correction=False)
            if request_tools:
                prompt_tokens += count_tools_tokens(request_tools, apply_claude_correction=False)
            total_tokens = prompt_tokens + completion_tokens
            prompt_source = "tiktoken"
            total_source = "tiktoken"
        
        # Send tool calls if present
        if all_tool_calls:
            logger.debug(f"Processing {len(all_tool_calls)} tool calls for streaming response")
            
            # Add required index field to each tool_call
            # according to OpenAI API specification for streaming
            indexed_tool_calls = []
            for idx, tc in enumerate(all_tool_calls):
                # Extract function with None protection
                func = tc.get("function") or {}
                # Use "or" for protection against explicit None in values
                tool_name = func.get("name") or ""
                tool_args = func.get("arguments") or "{}"
                
                logger.debug(f"Tool call [{idx}] '{tool_name}': id={tc.get('id')}, args_length={len(tool_args)}")
                
                indexed_tc = {
                    "index": idx,
                    "id": tc.get("id"),
                    "type": tc.get("type", "function"),
                    "function": {
                        "name": tool_name,
                        "arguments": tool_args
                    }
                }
                indexed_tool_calls.append(indexed_tc)
            
            tool_calls_chunk = {
                "id": completion_id,
                "object": "chat.completion.chunk",
                "created": created_time,
                "model": model,
                "choices": [{
                    "index": 0,
                    "delta": {"tool_calls": indexed_tool_calls},
                    "finish_reason": None
                }]
            }
            yield f"data: {json.dumps(tool_calls_chunk, ensure_ascii=False)}\n\n"
        
        # Final chunk with usage
        final_chunk = {
            "id": completion_id,
            "object": "chat.completion.chunk",
            "created": created_time,
            "model": model,
            "choices": [{"index": 0, "delta": {}, "finish_reason": finish_reason}],
            "usage": {
                "prompt_tokens": prompt_tokens,
                "completion_tokens": completion_tokens,
                "total_tokens": total_tokens,
            }
        }
        
        if metering_data:
            final_chunk["usage"]["credits_used"] = metering_data
        
        # Log final token values being sent to client
        logger.debug(
            f"[Usage] {model}: "
            f"prompt_tokens={prompt_tokens} ({prompt_source}), "
            f"completion_tokens={completion_tokens} (tiktoken), "
            f"total_tokens={total_tokens} ({total_source})"
        )
        
        yield f"data: {json.dumps(final_chunk, ensure_ascii=False)}\n\n"
        yield "data: [DONE]\n\n"
        
    except FirstTokenTimeoutError:
        # Propagate timeout up for retry
        raise
    except GeneratorExit:
        # Client disconnected - this is normal, don't log as error
        logger.debug("Client disconnected (GeneratorExit)")
        streaming_error_occurred = True
    except Exception as e:
        streaming_error_occurred = True
        # Log exception type and message for better diagnostics
        error_type = type(e).__name__
        error_msg = str(e) if str(e) else "(empty message)"
        logger.error(
            f"Error during streaming: [{error_type}] {error_msg}",
            exc_info=True
        )
        # Propagate error up for proper handling in routes.py
        raise
    finally:
        # Always close response
        try:
            await response.aclose()
        except Exception as close_error:
            logger.debug(f"Error closing response: {close_error}")
        
        if streaming_error_occurred:
            logger.debug("Streaming completed with error")
        else:
            logger.debug("Streaming completed successfully")


async def stream_kiro_to_openai(
    client: httpx.AsyncClient,
    response: httpx.Response,
    model: str,
    model_cache: "ModelInfoCache",
    auth_manager: "KiroAuthManager",
    request_messages: Optional[list] = None,
    request_tools: Optional[list] = None
) -> AsyncGenerator[str, None]:
    """
    Generator for converting Kiro stream to OpenAI format.
    
    This is a wrapper over stream_kiro_to_openai_internal that does NOT retry.
    Retry logic is implemented in stream_with_first_token_retry.
    
    Args:
        client: HTTP client (for connection management)
        response: HTTP response with data stream
        model: Model name to include in response
        model_cache: Model cache for getting token limits
        auth_manager: Authentication manager
        request_messages: Original request messages (for fallback token counting)
        request_tools: Original request tools (for fallback token counting)
    
    Yields:
        Strings in SSE format: "data: {...}\\n\\n" or "data: [DONE]\\n\\n"
    """
    async for chunk in stream_kiro_to_openai_internal(
        client, response, model, model_cache, auth_manager,
        request_messages=request_messages,
        request_tools=request_tools
    ):
        yield chunk


async def stream_with_first_token_retry(
    make_request: Callable[[], Awaitable[httpx.Response]],
    client: httpx.AsyncClient,
    model: str,
    model_cache: "ModelInfoCache",
    auth_manager: "KiroAuthManager",
    max_retries: int = FIRST_TOKEN_MAX_RETRIES,
    first_token_timeout: float = FIRST_TOKEN_TIMEOUT,
    request_messages: Optional[list] = None,
    request_tools: Optional[list] = None
) -> AsyncGenerator[str, None]:
    """
    Streaming with automatic retry on first token timeout.
    
    If model doesn't respond within first_token_timeout seconds,
    request is cancelled and a new one is made. Maximum max_retries attempts.
    
    This is seamless for user - they just see a delay,
    but eventually get a response (or error after all attempts).
    
    Args:
        make_request: Function to create new HTTP request
        client: HTTP client
        model: Model name
        model_cache: Model cache
        auth_manager: Authentication manager
        max_retries: Maximum number of attempts
        first_token_timeout: First token wait timeout (seconds)
        request_messages: Original request messages (for fallback token counting)
        request_tools: Original request tools (for fallback token counting)
    
    Yields:
        Strings in SSE format
    
    Raises:
        HTTPException: After exhausting all attempts
    
    Example:
        >>> async def make_req():
        ...     return await http_client.request_with_retry("POST", url, payload, stream=True)
        >>> async for chunk in stream_with_first_token_retry(make_req, client, model, cache, auth):
        ...     print(chunk)
    """
    last_error: Optional[Exception] = None
    
    for attempt in range(max_retries):
        response: Optional[httpx.Response] = None
        try:
            # Make request
            if attempt > 0:
                logger.warning(f"Retry attempt {attempt + 1}/{max_retries} after first token timeout")
            
            response = await make_request()
            
            if response.status_code != 200:
                # Error from API - close response and raise exception
                try:
                    error_content = await response.aread()
                    error_text = error_content.decode('utf-8', errors='replace')
                except Exception:
                    error_text = "Unknown error"
                
                try:
                    await response.aclose()
                except Exception:
                    pass
                
                logger.error(f"Error from Kiro API: {response.status_code} - {error_text}")
                raise HTTPException(
                    status_code=response.status_code,
                    detail=f"Upstream API error: {error_text}"
                )
            
            # Try to stream with first token timeout
            async for chunk in stream_kiro_to_openai_internal(
                client,
                response,
                model,
                model_cache,
                auth_manager,
                first_token_timeout=first_token_timeout,
                request_messages=request_messages,
                request_tools=request_tools
            ):
                yield chunk
            
            # Successfully completed - exit
            return
            
        except FirstTokenTimeoutError as e:
            last_error = e
            logger.warning(
                f"[FirstTokenTimeout] Attempt {attempt + 1}/{max_retries} failed - "
                f"model did not respond within {first_token_timeout}s"
            )
            
            # Close current response if open
            if response:
                try:
                    await response.aclose()
                except Exception:
                    pass
            
            # Continue to next attempt
            continue
            
        except Exception as e:
            # Other errors - no retry, propagate
            logger.error(f"Unexpected error during streaming: {e}", exc_info=True)
            if response:
                try:
                    await response.aclose()
                except Exception:
                    pass
            raise
    
    # All attempts exhausted - raise HTTP error
    logger.error(
        f"[FirstTokenTimeout] All {max_retries} attempts exhausted - "
        f"model never responded within {first_token_timeout}s per attempt"
    )
    raise HTTPException(
        status_code=504,
        detail=f"Model did not respond within {first_token_timeout}s after {max_retries} attempts. Please try again."
    )


async def collect_stream_response(
    client: httpx.AsyncClient,
    response: httpx.Response,
    model: str,
    model_cache: "ModelInfoCache",
    auth_manager: "KiroAuthManager",
    request_messages: Optional[list] = None,
    request_tools: Optional[list] = None
) -> dict:
    """
    Collect full response from streaming stream.
    
    Used for non-streaming mode - collects all chunks
    and forms a single response.
    
    Args:
        client: HTTP client
        response: HTTP response with stream
        model: Model name
        model_cache: Model cache
        auth_manager: Authentication manager
        request_messages: Original request messages (for fallback token counting)
        request_tools: Original request tools (for fallback token counting)
    
    Returns:
        Dictionary with full response in OpenAI chat.completion format
    """
    full_content = ""
    final_usage = None
    tool_calls = []
    completion_id = generate_completion_id()
    
    async for chunk_str in stream_kiro_to_openai(
        client,
        response,
        model,
        model_cache,
        auth_manager,
        request_messages=request_messages,
        request_tools=request_tools
    ):
        if not chunk_str.startswith("data:"):
            continue
        
        data_str = chunk_str[len("data:"):].strip()
        if not data_str or data_str == "[DONE]":
            continue
        
        try:
            chunk_data = json.loads(data_str)
            
            # Extract data from chunk
            delta = chunk_data.get("choices", [{}])[0].get("delta", {})
            if "content" in delta:
                full_content += delta["content"]
            if "tool_calls" in delta:
                tool_calls.extend(delta["tool_calls"])
            
            # Save usage from last chunk
            if "usage" in chunk_data:
                final_usage = chunk_data["usage"]
                
        except (json.JSONDecodeError, IndexError):
            continue
    
    # Form final response
    message = {"role": "assistant", "content": full_content}
    if tool_calls:
        # For non-streaming response remove index field from tool_calls,
        # as it's only required for streaming chunks
        cleaned_tool_calls = []
        for tc in tool_calls:
            # Extract function with None protection
            func = tc.get("function") or {}
            cleaned_tc = {
                "id": tc.get("id"),
                "type": tc.get("type", "function"),
                "function": {
                    "name": func.get("name", ""),
                    "arguments": func.get("arguments", "{}")
                }
            }
            cleaned_tool_calls.append(cleaned_tc)
        message["tool_calls"] = cleaned_tool_calls
    
    finish_reason = "tool_calls" if tool_calls else "stop"
    
    # Form usage for response
    usage = final_usage or {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}
    
    # Log token info for debugging (non-streaming uses same logs from streaming)
    
    return {
        "id": completion_id,
        "object": "chat.completion",
        "created": int(time.time()),
        "model": model,
        "choices": [{
            "index": 0,
            "message": message,
            "finish_reason": finish_reason
        }],
        "usage": usage
    }


================================================
FILE: kiro_gateway/tokenizer.py
================================================
# -*- coding: utf-8 -*-

# Kiro OpenAI Gateway
# Copyright (C) 2025 Jwadow
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

"""
–ú–æ–¥—É–ª—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–¥—Å—á—ë—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤.

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç tiktoken (–±–∏–±–ª–∏–æ—Ç–µ–∫–∞ OpenAI –Ω–∞ Rust) –¥–ª—è –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ–≥–æ
–ø–æ–¥—Å—á—ë—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤. –ö–æ–¥–∏—Ä–æ–≤–∫–∞ cl100k_base –±–ª–∏–∑–∫–∞ –∫ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ Claude.

–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –≠—Ç–æ –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–π –ø–æ–¥—Å—á—ë—Ç, —Ç–∞–∫ –∫–∞–∫ —Ç–æ—á–Ω—ã–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
Claude –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ø—É–±–ª–∏—á–Ω—ã–º. Anthropic –Ω–µ –ø—É–±–ª–∏–∫—É–µ—Ç —Å–≤–æ–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä,
–ø–æ—ç—Ç–æ–º—É –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è tiktoken —Å –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–º –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏.

–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ CLAUDE_CORRECTION_FACTOR = 1.15 –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞
—ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏—Ö –Ω–∞–±–ª—é–¥–µ–Ω–∏—è—Ö: Claude —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –ø—Ä–∏–º–µ—Ä–Ω–æ –Ω–∞ 15%
–±–æ–ª—å—à–µ —á–µ–º GPT-4 (cl100k_base). –≠—Ç–æ —Å–≤—è–∑–∞–Ω–æ —Å —Ä–∞–∑–ª–∏—á–∏—è–º–∏ –≤ BPE —Å–ª–æ–≤–∞—Ä—è—Ö.
"""

from typing import List, Dict, Any, Optional
from loguru import logger

# –õ–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ tiktoken –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –∏–º–ø–æ—Ä—Ç–∞
_encoding = None

# –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –¥–ª—è Claude –º–æ–¥–µ–ª–µ–π
# Claude —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –ø—Ä–∏–º–µ—Ä–Ω–æ –Ω–∞ 15% –±–æ–ª—å—à–µ —á–µ–º GPT-4 (cl100k_base)
# –≠—Ç–æ —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, –æ—Å–Ω–æ–≤–∞–Ω–Ω–æ–µ –Ω–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ —Å context_usage –æ—Ç API
CLAUDE_CORRECTION_FACTOR = 1.15


def _get_encoding():
    """
    –õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç cl100k_base - –∫–æ–¥–∏—Ä–æ–≤–∫—É –¥–ª—è GPT-4/ChatGPT,
    –∫–æ—Ç–æ—Ä–∞—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±–ª–∏–∑–∫–∞ –∫ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ Claude.
    
    Returns:
        tiktoken.Encoding –∏–ª–∏ None –µ—Å–ª–∏ tiktoken –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
    """
    global _encoding
    if _encoding is None:
        try:
            import tiktoken
            _encoding = tiktoken.get_encoding("cl100k_base")
            logger.debug("[Tokenizer] Initialized tiktoken with cl100k_base encoding")
        except ImportError:
            logger.warning(
                "[Tokenizer] tiktoken not installed. "
                "Token counting will use fallback estimation. "
                "Install with: pip install tiktoken"
            )
            _encoding = False  # –ú–∞—Ä–∫–µ—Ä —á—Ç–æ –∏–º–ø–æ—Ä—Ç –Ω–µ —É–¥–∞–ª—Å—è
        except Exception as e:
            logger.error(f"[Tokenizer] Failed to initialize tiktoken: {e}")
            _encoding = False
    return _encoding if _encoding else None


def count_tokens(text: str, apply_claude_correction: bool = True) -> int:
    """
    –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ.
    
    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è –ø–æ–¥—Å—á—ë—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤
        apply_claude_correction: –ü—Ä–∏–º–µ–Ω—è—Ç—å –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –¥–ª—è Claude (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é True)
    
    Returns:
        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ–µ, —Å –∫–æ—Ä—Ä–µ–∫—Ü–∏–µ–π –¥–ª—è Claude)
    """
    if not text:
        return 0
    
    encoding = _get_encoding()
    if encoding:
        try:
            base_tokens = len(encoding.encode(text))
            if apply_claude_correction:
                return int(base_tokens * CLAUDE_CORRECTION_FACTOR)
            return base_tokens
        except Exception as e:
            logger.warning(f"[Tokenizer] Error encoding text: {e}")
    
    # Fallback: –≥—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞ ~4 —Å–∏–º–≤–æ–ª–∞ –Ω–∞ —Ç–æ–∫–µ–Ω –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ,
    # ~2-3 —Å–∏–º–≤–æ–ª–∞ –¥–ª—è –¥—Ä—É–≥–∏—Ö —è–∑—ã–∫–æ–≤ (–±–µ—Ä—ë–º —Å—Ä–µ–¥–Ω–µ–µ ~3.5)
    # –î–ª—è Claude –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ü–∏—é
    base_estimate = len(text) // 4 + 1
    if apply_claude_correction:
        return int(base_estimate * CLAUDE_CORRECTION_FACTOR)
    return base_estimate


def count_message_tokens(messages: List[Dict[str, Any]], apply_claude_correction: bool = True) -> int:
    """
    –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ç–æ–∫–µ–Ω—ã –≤ —Å–ø–∏—Å–∫–µ —Å–æ–æ–±—â–µ–Ω–∏–π —á–∞—Ç–∞.
    
    –£—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å–æ–æ–±—â–µ–Ω–∏–π OpenAI/Claude:
    - role: ~1 —Ç–æ–∫–µ–Ω
    - content: —Ç–æ–∫–µ–Ω—ã —Ç–µ–∫—Å—Ç–∞
    - –°–ª—É–∂–µ–±–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –º–µ–∂–¥—É —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏: ~3-4 —Ç–æ–∫–µ–Ω–∞
    
    Args:
        messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI
        apply_claude_correction: –ü—Ä–∏–º–µ–Ω—è—Ç—å –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –¥–ª—è Claude
    
    Returns:
        –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ (—Å –∫–æ—Ä—Ä–µ–∫—Ü–∏–µ–π –¥–ª—è Claude)
    """
    if not messages:
        return 0
    
    total_tokens = 0
    
    for message in messages:
        # –ë–∞–∑–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ (role, —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏)
        total_tokens += 4  # ~4 —Ç–æ–∫–µ–Ω–∞ –Ω–∞ —Å–ª—É–∂–µ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        
        # –¢–æ–∫–µ–Ω—ã —Ä–æ–ª–∏ (–±–µ–∑ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏, —ç—Ç–æ –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏)
        role = message.get("role", "")
        total_tokens += count_tokens(role, apply_claude_correction=False)
        
        # –¢–æ–∫–µ–Ω—ã –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        content = message.get("content")
        if content:
            if isinstance(content, str):
                total_tokens += count_tokens(content, apply_claude_correction=False)
            elif isinstance(content, list):
                # –ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç (—Ç–µ–∫—Å—Ç + –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
                for item in content:
                    if isinstance(item, dict):
                        if item.get("type") == "text":
                            total_tokens += count_tokens(item.get("text", ""), apply_claude_correction=False)
                        elif item.get("type") == "image_url":
                            # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∑–∞–Ω–∏–º–∞—é—Ç ~85-170 —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞
                            total_tokens += 100  # –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞
        
        # –¢–æ–∫–µ–Ω—ã tool_calls (–µ—Å–ª–∏ –µ—Å—Ç—å)
        tool_calls = message.get("tool_calls")
        if tool_calls:
            for tc in tool_calls:
                total_tokens += 4  # –°–ª—É–∂–µ–±–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
                func = tc.get("function", {})
                total_tokens += count_tokens(func.get("name", ""), apply_claude_correction=False)
                total_tokens += count_tokens(func.get("arguments", ""), apply_claude_correction=False)
        
        # –¢–æ–∫–µ–Ω—ã tool_call_id (–¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤)
        if message.get("tool_call_id"):
            total_tokens += count_tokens(message["tool_call_id"], apply_claude_correction=False)
    
    # –§–∏–Ω–∞–ª—å–Ω—ã–µ —Å–ª—É–∂–µ–±–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
    total_tokens += 3
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ü–∏—é –∫ –æ–±—â–µ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É
    if apply_claude_correction:
        return int(total_tokens * CLAUDE_CORRECTION_FACTOR)
    return total_tokens


def count_tools_tokens(tools: Optional[List[Dict[str, Any]]], apply_claude_correction: bool = True) -> int:
    """
    –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ç–æ–∫–µ–Ω—ã –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤.
    
    Args:
        tools: –°–ø–∏—Å–æ–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI
        apply_claude_correction: –ü—Ä–∏–º–µ–Ω—è—Ç—å –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –¥–ª—è Claude
    
    Returns:
        –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ (—Å –∫–æ—Ä—Ä–µ–∫—Ü–∏–µ–π –¥–ª—è Claude)
    """
    if not tools:
        return 0
    
    total_tokens = 0
    
    for tool in tools:
        total_tokens += 4  # –°–ª—É–∂–µ–±–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
        
        if tool.get("type") == "function":
            func = tool.get("function", {})
            
            # –ò–º—è —Ñ—É–Ω–∫—Ü–∏–∏
            total_tokens += count_tokens(func.get("name", ""), apply_claude_correction=False)
            
            # –û–ø–∏—Å–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏
            total_tokens += count_tokens(func.get("description", ""), apply_claude_correction=False)
            
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã (JSON schema)
            params = func.get("parameters")
            if params:
                import json
                params_str = json.dumps(params, ensure_ascii=False)
                total_tokens += count_tokens(params_str, apply_claude_correction=False)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ü–∏—é –∫ –æ–±—â–µ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É
    if apply_claude_correction:
        return int(total_tokens * CLAUDE_CORRECTION_FACTOR)
    return total_tokens


def estimate_request_tokens(
    messages: List[Dict[str, Any]],
    tools: Optional[List[Dict[str, Any]]] = None,
    system_prompt: Optional[str] = None
) -> Dict[str, int]:
    """
    –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∑–∞–ø—Ä–æ—Å–µ.
    
    Args:
        messages: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
        tools: –°–ø–∏—Å–æ–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        system_prompt: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –µ—Å–ª–∏ –Ω–µ –≤ messages)
    
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–µ–π —Ç–æ–∫–µ–Ω–æ–≤:
        - messages_tokens: —Ç–æ–∫–µ–Ω—ã —Å–æ–æ–±—â–µ–Ω–∏–π
        - tools_tokens: —Ç–æ–∫–µ–Ω—ã –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        - system_tokens: —Ç–æ–∫–µ–Ω—ã —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
        - total_tokens: –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    """
    messages_tokens = count_message_tokens(messages)
    tools_tokens = count_tools_tokens(tools)
    system_tokens = count_tokens(system_prompt) if system_prompt else 0
    
    return {
        "messages_tokens": messages_tokens,
        "tools_tokens": tools_tokens,
        "system_tokens": system_tokens,
        "total_tokens": messages_tokens + tools_tokens + system_tokens
    }


================================================
FILE: kiro_gateway/utils.py
================================================
# -*- coding: utf-8 -*-

# Kiro OpenAI Gateway
# https://github.com/jwadow/kiro-openai-gateway
# Copyright (C) 2025 Jwadow
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

"""
Utility functions for Kiro Gateway.

Contains functions for fingerprint generation, header formatting,
and other common utilities.
"""

import hashlib
import uuid
from typing import TYPE_CHECKING

from loguru import logger

if TYPE_CHECKING:
    from kiro_gateway.auth import KiroAuthManager


def get_machine_fingerprint() -> str:
    """
    Generates a unique machine fingerprint based on hostname and username.
    
    Used for User-Agent formation to identify a specific gateway installation.
    
    Returns:
        SHA256 hash of the string "{hostname}-{username}-kiro-gateway"
    """
    try:
        import socket
        import getpass
        
        hostname = socket.gethostname()
        username = getpass.getuser()
        unique_string = f"{hostname}-{username}-kiro-gateway"
        
        return hashlib.sha256(unique_string.encode()).hexdigest()
    except Exception as e:
        logger.warning(f"Failed to get machine fingerprint: {e}")
        return hashlib.sha256(b"default-kiro-gateway").hexdigest()


def get_kiro_headers(auth_manager: "KiroAuthManager", token: str) -> dict:
    """
    Builds headers for Kiro API requests.
    
    Includes all necessary headers for authentication and identification:
    - Authorization with Bearer token
    - User-Agent with fingerprint
    - AWS CodeWhisperer specific headers
    
    Args:
        auth_manager: Authentication manager for obtaining fingerprint
        token: Access token for authorization
    
    Returns:
        Dictionary with headers for HTTP request
    """
    fingerprint = auth_manager.fingerprint
    
    return {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json",
        "User-Agent": f"aws-sdk-js/1.0.27 ua/2.1 os/win32#10.0.19044 lang/js md/nodejs#22.21.1 api/codewhispererstreaming#1.0.27 m/E KiroIDE-0.7.45-{fingerprint}",
        "x-amz-user-agent": f"aws-sdk-js/1.0.27 KiroIDE-0.7.45-{fingerprint}",
        "x-amzn-codewhisperer-optout": "true",
        "x-amzn-kiro-agent-mode": "vibe",
        "amz-sdk-invocation-id": str(uuid.uuid4()),
        "amz-sdk-request": "attempt=1; max=3",
    }


def generate_completion_id() -> str:
    """
    Generates a unique ID for chat completion.
    
    Returns:
        ID in format "chatcmpl-{uuid_hex}"
    """
    return f"chatcmpl-{uuid.uuid4().hex}"


def generate_conversation_id() -> str:
    """
    Generates a unique ID for conversation.
    
    Returns:
        UUID in string format
    """
    return str(uuid.uuid4())


def generate_tool_call_id() -> str:
    """
    Generates a unique ID for tool call.
    
    Returns:
        ID in format "call_{uuid_hex[:8]}"
    """
    return f"call_{uuid.uuid4().hex[:8]}"


================================================
FILE: tests/README.md
================================================
# Tests for Kiro OpenAI Gateway

A comprehensive set of unit and integration tests for Kiro OpenAI Gateway, providing full coverage of all system components.

## Testing Philosophy: Complete Network Isolation

**The key principle of this test suite is 100% isolation from real network requests.**

This is achieved through a global, automatically applied fixture `block_all_network_calls` in `tests/conftest.py`. It intercepts and blocks any attempts by `httpx.AsyncClient` to establish connections at the application level.

**Benefits:**
1.  **Reliability**: Tests don't depend on external API availability or network state.
2.  **Speed**: Absence of real network delays makes test execution instant.
3.  **Security**: Guarantees that test runs never use real credentials.

Any attempt to make an unauthorized network call will result in immediate test failure with an error, ensuring strict isolation control.

## Running Tests

### Installing Dependencies

```bash
# Main project dependencies
pip install -r requirements.txt

# Additional testing dependencies
pip install pytest pytest-asyncio hypothesis
```

### Running All Tests

```bash
# Run the entire test suite
pytest

# Run with verbose output
pytest -v

# Run with verbose output and coverage
pytest -v -s --tb=short

# Run only unit tests
pytest tests/unit/ -v

# Run only integration tests
pytest tests/integration/ -v

# Run a specific file
pytest tests/unit/test_auth_manager.py -v

# Run a specific test
pytest tests/unit/test_auth_manager.py::TestKiroAuthManagerInitialization::test_initialization_stores_credentials -v
```

### pytest Options

```bash
# Stop on first failure
pytest -x

# Show local variables on errors
pytest -l

# Run in parallel mode (requires pytest-xdist)
pip install pytest-xdist
pytest -n auto
```

## Test Structure

```
tests/
‚îú‚îÄ‚îÄ conftest.py                      # Shared fixtures and utilities
‚îú‚îÄ‚îÄ unit/                            # Unit tests for individual components
‚îÇ   ‚îú‚îÄ‚îÄ test_auth_manager.py        # KiroAuthManager tests
‚îÇ   ‚îú‚îÄ‚îÄ test_cache.py               # ModelInfoCache tests
‚îÇ   ‚îú‚îÄ‚îÄ test_config.py              # Configuration tests (LOG_LEVEL, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ test_converters.py          # OpenAI <-> Kiro converter tests
‚îÇ   ‚îú‚îÄ‚îÄ test_debug_logger.py        # DebugLogger tests (off/errors/all modes)
‚îÇ   ‚îú‚îÄ‚îÄ test_parsers.py             # AwsEventStreamParser tests
‚îÇ   ‚îú‚îÄ‚îÄ test_streaming.py           # Streaming function tests
‚îÇ   ‚îú‚îÄ‚îÄ test_tokenizer.py           # Tokenizer tests (tiktoken)
‚îÇ   ‚îú‚îÄ‚îÄ test_http_client.py         # KiroHttpClient tests
‚îÇ   ‚îî‚îÄ‚îÄ test_routes.py              # API endpoint tests
‚îú‚îÄ‚îÄ integration/                     # Integration tests for full flow
‚îÇ   ‚îî‚îÄ‚îÄ test_full_flow.py           # End-to-end tests
‚îî‚îÄ‚îÄ README.md                        # This file
```

## Test Coverage

### `conftest.py`

Shared fixtures and utilities for all tests:

**Environment Fixtures:**
- **`mock_env_vars()`**: Mocks environment variables (REFRESH_TOKEN, PROXY_API_KEY)
  - **What it does**: Isolates tests from real credentials
  - **Purpose**: Security and test reproducibility

**Data Fixtures:**
- **`valid_kiro_token()`**: Returns a mock Kiro access token
  - **What it does**: Provides a predictable token for tests
  - **Purpose**: Testing without real Kiro requests

- **`mock_kiro_token_response()`**: Factory for creating mock refreshToken responses
  - **What it does**: Generates Kiro auth endpoint response structure
  - **Purpose**: Testing various token refresh scenarios

- **`temp_creds_file()`**: Creates a temporary JSON file with credentials
  - **What it does**: Provides a file for testing credentials loading
  - **Purpose**: Testing credentials file operations

- **`sample_openai_chat_request()`**: Factory for creating OpenAI requests
  - **What it does**: Generates valid chat completion requests
  - **Purpose**: Convenient creation of test requests with different parameters

**Security Fixtures:**
- **`valid_proxy_api_key()`**: Valid proxy API key
- **`invalid_proxy_api_key()`**: Invalid key for negative tests
- **`auth_headers()`**: Factory for creating Authorization headers

**HTTP Fixtures:**
- **`mock_httpx_client()`**: Mocked httpx.AsyncClient
  - **What it does**: Isolates tests from real HTTP requests
  - **Purpose**: Test speed and reliability

- **`mock_httpx_response()`**: Factory for creating mock HTTP responses
  - **What it does**: Creates configurable httpx.Response objects
  - **Purpose**: Testing various HTTP scenarios

**Application Fixtures:**
- **`clean_app()`**: Clean FastAPI app instance
  - **What it does**: Returns a "clean" application instance
  - **Purpose**: Ensure application state isolation between tests

- **`test_client()`**: Synchronous FastAPI TestClient
- **`async_test_client()`**: Asynchronous test client for async endpoints

---

### `tests/unit/test_auth_manager.py`

Unit tests for **KiroAuthManager** (Kiro token management).

#### `TestKiroAuthManagerInitialization`

- **`test_initialization_stores_credentials()`**:
  - **What it does**: Verifies correct credential storage during creation
  - **Purpose**: Ensure all constructor parameters are stored in private fields

- **`test_initialization_sets_correct_urls_for_region()`**:
  - **What it does**: Verifies URL formation based on region
  - **Purpose**: Ensure URLs are dynamically formed with the correct region

- **`test_initialization_generates_fingerprint()`**:
  - **What it does**: Verifies unique fingerprint generation
  - **Purpose**: Ensure fingerprint is generated and has correct format

#### `TestKiroAuthManagerCredentialsFile`

- **`test_load_credentials_from_file()`**:
  - **What it does**: Verifies credentials loading from JSON file
  - **Purpose**: Ensure data is correctly read from file

- **`test_load_credentials_file_not_found()`**:
  - **What it does**: Verifies handling of missing credentials file
  - **Purpose**: Ensure application doesn't crash when file is missing

#### `TestKiroAuthManagerTokenExpiration`

- **`test_is_token_expiring_soon_returns_true_when_no_expires_at()`**:
  - **What it does**: Verifies that without expires_at, token is considered expiring
  - **Purpose**: Ensure safe behavior when time information is missing

- **`test_is_token_expiring_soon_returns_true_when_expired()`**:
  - **What it does**: Verifies that expired token is correctly identified
  - **Purpose**: Ensure token in the past is considered expiring

- **`test_is_token_expiring_soon_returns_true_within_threshold()`**:
  - **What it does**: Verifies that token within threshold is considered expiring
  - **Purpose**: Ensure token is refreshed in advance (10 minutes before expiration)

- **`test_is_token_expiring_soon_returns_false_when_valid()`**:
  - **What it does**: Verifies that valid token is not considered expiring
  - **Purpose**: Ensure token far in the future doesn't require refresh

#### `TestKiroAuthManagerTokenRefresh`

- **`test_refresh_token_successful()`**:
  - **What it does**: Tests successful token refresh via Kiro API
  - **Purpose**: Verify correct setting of access_token and expires_at

- **`test_refresh_token_updates_refresh_token()`**:
  - **What it does**: Verifies refresh_token update from response
  - **Purpose**: Ensure new refresh_token is saved

- **`test_refresh_token_missing_access_token_raises()`**:
  - **What it does**: Verifies handling of response without accessToken
  - **Purpose**: Ensure exception is thrown for incorrect response

- **`test_refresh_token_no_refresh_token_raises()`**:
  - **What it does**: Verifies handling of missing refresh_token
  - **Purpose**: Ensure exception is thrown without refresh_token

#### `TestKiroAuthManagerGetAccessToken`

- **`test_get_access_token_refreshes_when_expired()`**:
  - **What it does**: Verifies automatic refresh of expired token
  - **Purpose**: Ensure stale token is refreshed before return

- **`test_get_access_token_returns_valid_without_refresh()`**:
  - **What it does**: Verifies return of valid token without extra requests
  - **Purpose**: Optimization - don't make requests if token is still valid

- **`test_get_access_token_thread_safety()`**:
  - **What it does**: Verifies thread safety via asyncio.Lock
  - **Purpose**: Prevent race conditions during parallel calls

#### `TestKiroAuthManagerForceRefresh`

- **`test_force_refresh_updates_token()`**:
  - **What it does**: Verifies forced token refresh
  - **Purpose**: Ensure force_refresh always refreshes token

#### `TestKiroAuthManagerProperties`

- **`test_profile_arn_property()`**:
  - **What it does**: Verifies profile_arn property
  - **Purpose**: Ensure profile_arn is accessible via property

- **`test_region_property()`**:
  - **What it does**: Verifies region property
  - **Purpose**: Ensure region is accessible via property

- **`test_api_host_property()`**:
  - **What it does**: Verifies api_host property
  - **Purpose**: Ensure api_host is formed correctly

- **`test_fingerprint_property()`**:
  - **What it does**: Verifies fingerprint property
  - **Purpose**: Ensure fingerprint is accessible via property

---

### `tests/unit/test_cache.py`

Unit tests for **ModelInfoCache** (model metadata cache). **23 tests.**

#### `TestModelInfoCacheInitialization`

- **`test_initialization_creates_empty_cache()`**:
  - **What it does**: Verifies that cache is created empty
  - **Purpose**: Ensure correct initialization

- **`test_initialization_with_custom_ttl()`**:
  - **What it does**: Verifies cache creation with custom TTL
  - **Purpose**: Ensure TTL can be configured

- **`test_initialization_last_update_is_none()`**:
  - **What it does**: Verifies that last_update_time is initially None
  - **Purpose**: Ensure update time is not set before first update

#### `TestModelInfoCacheUpdate`

- **`test_update_populates_cache()`**:
  - **What it does**: Verifies cache population with data
  - **Purpose**: Ensure update() correctly saves models

- **`test_update_sets_last_update_time()`**:
  - **What it does**: Verifies setting of last update time
  - **Purpose**: Ensure last_update_time is set after update

- **`test_update_replaces_existing_data()`**:
  - **What it does**: Verifies data replacement on repeated update
  - **Purpose**: Ensure old data is completely replaced

- **`test_update_with_empty_list()`**:
  - **What it does**: Verifies update with empty list
  - **Purpose**: Ensure cache is cleared on empty update

#### `TestModelInfoCacheGet`

- **`test_get_returns_model_info()`**:
  - **What it does**: Verifies retrieval of model information
  - **Purpose**: Ensure get() returns correct data

- **`test_get_returns_none_for_unknown_model()`**:
  - **What it does**: Verifies None return for unknown model
  - **Purpose**: Ensure get() doesn't crash when model is missing

- **`test_get_from_empty_cache()`**:
  - **What it does**: Verifies get() from empty cache
  - **Purpose**: Ensure empty cache doesn't cause errors

#### `TestModelInfoCacheGetMaxInputTokens`

- **`test_get_max_input_tokens_returns_value()`**:
  - **What it does**: Verifies retrieval of maxInputTokens for model
  - **Purpose**: Ensure value is extracted from tokenLimits

- **`test_get_max_input_tokens_returns_default_for_unknown()`**:
  - **What it does**: Verifies default return for unknown model
  - **Purpose**: Ensure DEFAULT_MAX_INPUT_TOKENS is returned

- **`test_get_max_input_tokens_returns_default_when_no_token_limits()`**:
  - **What it does**: Verifies default return when tokenLimits is missing
  - **Purpose**: Ensure model without tokenLimits doesn't break logic

- **`test_get_max_input_tokens_returns_default_when_max_input_is_none()`**:
  - **What it does**: Verifies default return when maxInputTokens=None
  - **Purpose**: Ensure None in tokenLimits is handled correctly

#### `TestModelInfoCacheIsEmpty` and `TestModelInfoCacheIsStale`

- **`test_is_empty_returns_true_for_new_cache()`**: Verifies is_empty() for new cache
- **`test_is_empty_returns_false_after_update()`**: Verifies is_empty() after population
- **`test_is_stale_returns_true_for_new_cache()`**: Verifies is_stale() for new cache
- **`test_is_stale_returns_false_after_recent_update()`**: Verifies is_stale() right after update
- **`test_is_stale_returns_true_after_ttl_expires()`**: Verifies is_stale() after TTL expiration

#### `TestModelInfoCacheGetAllModelIds`

- **`test_get_all_model_ids_returns_empty_for_new_cache()`**: Verifies get_all_model_ids() for empty cache
- **`test_get_all_model_ids_returns_all_ids()`**: Verifies get_all_model_ids() for populated cache

#### `TestModelInfoCacheThreadSafety`

- **`test_concurrent_updates_dont_corrupt_cache()`**:
  - **What it does**: Verifies thread safety during parallel updates
  - **Purpose**: Ensure asyncio.Lock protects against race conditions

- **`test_concurrent_reads_are_safe()`**:
  - **What it does**: Verifies safety of parallel reads
  - **Purpose**: Ensure multiple get() calls don't cause issues

---

### `tests/unit/test_config.py`

Unit tests for **configuration module** (loading settings from environment variables). **13 tests.**

#### `TestLogLevelConfig`

Tests for LOG_LEVEL configuration.

- **`test_default_log_level_is_info()`**:
  - **What it does**: Verifies that default LOG_LEVEL is INFO
  - **Purpose**: Ensure INFO is used without environment variable

- **`test_log_level_from_environment()`**:
  - **What it does**: Verifies LOG_LEVEL loading from environment variable
  - **Purpose**: Ensure value from environment is used

- **`test_log_level_uppercase_conversion()`**:
  - **What it does**: Verifies LOG_LEVEL conversion to uppercase
  - **Purpose**: Ensure lowercase value is converted to uppercase

- **`test_log_level_trace()`**:
  - **What it does**: Verifies LOG_LEVEL=TRACE setting
  - **Purpose**: Ensure TRACE level is supported

- **`test_log_level_error()`**:
  - **What it does**: Verifies LOG_LEVEL=ERROR setting
  - **Purpose**: Ensure ERROR level is supported

- **`test_log_level_critical()`**:
  - **What it does**: Verifies LOG_LEVEL=CRITICAL setting
  - **Purpose**: Ensure CRITICAL level is supported

#### `TestToolDescriptionMaxLengthConfig`

Tests for TOOL_DESCRIPTION_MAX_LENGTH configuration.

- **`test_default_tool_description_max_length()`**:
  - **What it does**: Verifies default value for TOOL_DESCRIPTION_MAX_LENGTH
  - **Purpose**: Ensure default is 10000

- **`test_tool_description_max_length_from_environment()`**:
  - **What it does**: Verifies TOOL_DESCRIPTION_MAX_LENGTH loading from environment
  - **Purpose**: Ensure value from environment is used

- **`test_tool_description_max_length_zero_disables()`**:
  - **What it does**: Verifies that 0 disables the feature
  - **Purpose**: Ensure TOOL_DESCRIPTION_MAX_LENGTH=0 works

#### `TestTimeoutConfigurationWarning`

Tests for `_warn_timeout_configuration()` function.

- **`test_no_warning_when_first_token_less_than_streaming()`**:
  - **What it does**: Verifies no warning when FIRST_TOKEN_TIMEOUT < STREAMING_READ_TIMEOUT
  - **Purpose**: Ensure correct configuration doesn't trigger warning

- **`test_warning_when_first_token_equals_streaming()`**:
  - **What it does**: Verifies warning when FIRST_TOKEN_TIMEOUT == STREAMING_READ_TIMEOUT
  - **Purpose**: Ensure equal timeouts trigger warning

- **`test_warning_when_first_token_greater_than_streaming()`**:
  - **What it does**: Verifies warning when FIRST_TOKEN_TIMEOUT > STREAMING_READ_TIMEOUT
  - **Purpose**: Ensure suboptimal configuration triggers warning with timeout values

- **`test_warning_contains_recommendation()`**:
  - **What it does**: Verifies warning contains recommendation text
  - **Purpose**: Ensure user gets helpful information about correct configuration

---

### `tests/unit/test_debug_logger.py`

Unit tests for **DebugLogger** (debug request logging). **26 tests.**

#### `TestDebugLoggerModeOff`

Tests for DEBUG_MODE=off mode.

- **`test_prepare_new_request_does_nothing()`**:
  - **What it does**: Verifies that prepare_new_request does nothing in off mode
  - **Purpose**: Ensure directory is not created in off mode

- **`test_log_request_body_does_nothing()`**:
  - **What it does**: Verifies that log_request_body does nothing in off mode
  - **Purpose**: Ensure data is not written

#### `TestDebugLoggerModeAll`

Tests for DEBUG_MODE=all mode.

- **`test_prepare_new_request_clears_directory()`**:
  - **What it does**: Verifies that prepare_new_request clears directory in all mode
  - **Purpose**: Ensure old logs are deleted

- **`test_log_request_body_writes_immediately()`**:
  - **What it does**: Verifies that log_request_body writes immediately to file in all mode
  - **Purpose**: Ensure data is written immediately

- **`test_log_kiro_request_body_writes_immediately()`**:
  - **What it does**: Verifies that log_kiro_request_body writes immediately to file in all mode
  - **Purpose**: Ensure Kiro payload is written immediately

- **`test_log_raw_chunk_appends_to_file()`**:
  - **What it does**: Verifies that log_raw_chunk appends to file in all mode
  - **Purpose**: Ensure chunks accumulate

#### `TestDebugLoggerModeErrors`

Tests for DEBUG_MODE=errors mode.

- **`test_log_request_body_buffers_data()`**:
  - **What it does**: Verifies that log_request_body buffers data in errors mode
  - **Purpose**: Ensure data is not written immediately

- **`test_flush_on_error_writes_buffers()`**:
  - **What it does**: Verifies that flush_on_error writes buffers to files
  - **Purpose**: Ensure data is saved on error

- **`test_flush_on_error_clears_buffers()`**:
  - **What it does**: Verifies that flush_on_error clears buffers after writing
  - **Purpose**: Ensure buffers don't accumulate between requests

- **`test_discard_buffers_clears_without_writing()`**:
  - **What it does**: Verifies that discard_buffers clears buffers without writing
  - **Purpose**: Ensure successful requests don't leave logs

- **`test_flush_on_error_writes_error_info_in_mode_all()`**:
  - **What it does**: Verifies that flush_on_error writes error_info.json in all mode
  - **Purpose**: Ensure error information is saved in both modes

#### `TestDebugLoggerLogErrorInfo`

Tests for log_error_info() method.

- **`test_log_error_info_writes_in_mode_all()`**:
  - **What it does**: Verifies that log_error_info writes file in all mode
  - **Purpose**: Ensure error_info.json is created on errors

- **`test_log_error_info_writes_in_mode_errors()`**:
  - **What it does**: Verifies that log_error_info writes file in errors mode
  - **Purpose**: Ensure method works in both modes

- **`test_log_error_info_does_nothing_in_mode_off()`**:
  - **What it does**: Verifies that log_error_info does nothing in off mode
  - **Purpose**: Ensure files are not created in off mode

#### `TestDebugLoggerHelperMethods`

Tests for DebugLogger helper methods.

- **`test_is_enabled_returns_true_for_errors()`**: Verifies _is_enabled() for errors mode
- **`test_is_enabled_returns_true_for_all()`**: Verifies _is_enabled() for all mode
- **`test_is_enabled_returns_false_for_off()`**: Verifies _is_enabled() for off mode
- **`test_is_immediate_write_returns_true_for_all()`**: Verifies _is_immediate_write() for all mode
- **`test_is_immediate_write_returns_false_for_errors()`**: Verifies _is_immediate_write() for errors mode

#### `TestDebugLoggerJsonHandling`

Tests for JSON handling in DebugLogger.

- **`test_log_request_body_formats_json_pretty()`**:
  - **What it does**: Verifies that JSON is formatted prettily
  - **Purpose**: Ensure JSON is readable in file

- **`test_log_request_body_handles_invalid_json()`**:
  - **What it does**: Verifies handling of invalid JSON
  - **Purpose**: Ensure invalid JSON is written as-is

#### `TestDebugLoggerAppLogsCapture`

Tests for application log capture (app_logs.txt).

- **`test_prepare_new_request_sets_up_log_capture()`**:
  - **What it does**: Verifies that prepare_new_request sets up log capture
  - **Purpose**: Ensure sink for logs is created

- **`test_flush_on_error_writes_app_logs_in_mode_errors()`**:
  - **What it does**: Verifies that flush_on_error writes app_logs.txt in errors mode
  - **Purpose**: Ensure application logs are saved on errors

- **`test_discard_buffers_saves_logs_in_mode_all()`**:
  - **What it does**: Verifies that discard_buffers saves logs in all mode
  - **Purpose**: Ensure even successful requests save logs in all mode

- **`test_discard_buffers_does_not_save_logs_in_mode_errors()`**:
  - **What it does**: Verifies that discard_buffers does NOT save logs in errors mode
  - **Purpose**: Ensure successful requests don't leave logs in errors mode

- **`test_clear_app_logs_buffer_removes_sink()`**:
  - **What it does**: Verifies that _clear_app_logs_buffer removes sink
  - **Purpose**: Ensure sink is correctly removed

- **`test_app_logs_not_saved_when_empty()`**:
  - **What it does**: Verifies that empty logs don't create file
  - **Purpose**: Ensure app_logs.txt is not created if there are no logs

---

### `tests/unit/test_converters.py`

Unit tests for **OpenAI <-> Kiro** converters. **68 tests.**

#### `TestExtractTextContent`

- **`test_extracts_from_string()`**: Verifies text extraction from string
- **`test_extracts_from_none()`**: Verifies None handling
- **`test_extracts_from_list_with_text_type()`**: Verifies extraction from list with type=text
- **`test_extracts_from_list_with_text_key()`**: Verifies extraction from list with text key
- **`test_extracts_from_list_with_strings()`**: Verifies extraction from list of strings
- **`test_extracts_from_mixed_list()`**: Verifies extraction from mixed list
- **`test_converts_other_types_to_string()`**: Verifies conversion of other types to string
- **`test_handles_empty_list()`**: Verifies empty list handling

#### `TestMergeAdjacentMessages`

- **`test_merges_adjacent_user_messages()`**: Verifies merging of adjacent user messages
- **`test_preserves_alternating_messages()`**: Verifies preservation of alternating messages
- **`test_handles_empty_list()`**: Verifies empty list handling
- **`test_handles_single_message()`**: Verifies single message handling
- **`test_merges_multiple_adjacent_groups()`**: Verifies merging of multiple groups

**New tests for tool message handling (role="tool"):**

- **`test_converts_tool_message_to_user_with_tool_result()`**:
  - **What it does**: Verifies conversion of tool message to user message with tool_result
  - **Purpose**: Ensure role="tool" is converted to user message with tool_results content

- **`test_converts_multiple_tool_messages_to_single_user_message()`**:
  - **What it does**: Verifies merging of multiple tool messages into single user message
  - **Purpose**: Ensure multiple tool results are merged into one user message

- **`test_tool_message_followed_by_user_message()`**:
  - **What it does**: Verifies tool message before user message
  - **Purpose**: Ensure tool results and user message are merged

- **`test_assistant_tool_user_sequence()`**:
  - **What it does**: Verifies assistant -> tool -> user sequence
  - **Purpose**: Ensure tool message is correctly inserted between assistant and user

- **`test_tool_message_with_empty_content()`**:
  - **What it does**: Verifies tool message with empty content
  - **Purpose**: Ensure empty result is replaced with "(empty result)"

- **`test_tool_message_with_none_tool_call_id()`**:
  - **What it does**: Verifies tool message without tool_call_id
  - **Purpose**: Ensure missing tool_call_id is replaced with empty string

- **`test_merges_list_contents_correctly()`**:
  - **What it does**: Verifies list contents merging
  - **Purpose**: Ensure lists are merged correctly

- **`test_merges_adjacent_assistant_tool_calls()`**:
  - **What it does**: Verifies tool_calls merging when merging adjacent assistant messages
  - **Purpose**: Ensure tool_calls from all assistant messages are preserved when merging

- **`test_merges_three_adjacent_assistant_tool_calls()`**:
  - **What it does**: Verifies tool_calls merging from three assistant messages
  - **Purpose**: Ensure all tool_calls are preserved when merging more than two messages

- **`test_merges_assistant_with_and_without_tool_calls()`**:
  - **What it does**: Verifies merging assistant with and without tool_calls
  - **Purpose**: Ensure tool_calls are correctly initialized when merging

#### `TestBuildKiroPayloadToolCallsIntegration`

Integration tests for full tool_calls flow from OpenAI to Kiro format.

- **`test_multiple_assistant_tool_calls_with_results()`**:
  - **What it does**: Verifies full scenario with multiple assistant tool_calls and their results
  - **Purpose**: Ensure all toolUses and toolResults are correctly linked in Kiro payload

#### `TestBuildKiroHistory`

- **`test_builds_user_message()`**: Verifies user message building
- **`test_builds_assistant_message()`**: Verifies assistant message building
- **`test_ignores_system_messages()`**: Verifies system message ignoring
- **`test_builds_conversation_history()`**: Verifies full conversation history building
- **`test_handles_empty_list()`**: Verifies empty list handling

#### `TestExtractToolResults` and `TestExtractToolUses`

- **`test_extracts_tool_results_from_list()`**: Verifies tool results extraction from list
- **`test_returns_empty_for_string_content()`**: Verifies empty list return for string
- **`test_extracts_from_tool_calls_field()`**: Verifies extraction from tool_calls field
- **`test_extracts_from_content_list()`**: Verifies extraction from content list

#### `TestProcessToolsWithLongDescriptions`

Tests for tools processing function with long descriptions (Tool Documentation Reference Pattern).

- **`test_returns_none_and_empty_string_for_none_tools()`**:
  - **What it does**: Verifies handling of None instead of tools list
  - **Purpose**: Ensure None returns (None, "")

- **`test_returns_none_and_empty_string_for_empty_list()`**:
  - **What it does**: Verifies handling of empty tools list
  - **Purpose**: Ensure empty list returns (None, "")

- **`test_short_description_unchanged()`**:
  - **What it does**: Verifies that short descriptions are not changed
  - **Purpose**: Ensure tools with short descriptions remain as-is

- **`test_long_description_moved_to_system_prompt()`**:
  - **What it does**: Verifies moving long description to system prompt
  - **Purpose**: Ensure long descriptions are moved correctly with reference in tool

- **`test_mixed_short_and_long_descriptions()`**:
  - **What it does**: Verifies handling of mixed tools list
  - **Purpose**: Ensure short ones stay, long ones are moved

- **`test_preserves_tool_parameters()`**:
  - **What it does**: Verifies parameters preservation when moving description
  - **Purpose**: Ensure parameters are not lost

- **`test_disabled_when_limit_is_zero()`**:
  - **What it does**: Verifies feature disabling when limit is 0
  - **Purpose**: Ensure tools are not changed when TOOL_DESCRIPTION_MAX_LENGTH=0

- **`test_non_function_tools_unchanged()`**:
  - **What it does**: Verifies that non-function tools are not changed
  - **Purpose**: Ensure only function tools are processed

- **`test_multiple_long_descriptions_all_moved()`**:
  - **What it does**: Verifies moving multiple long descriptions
  - **Purpose**: Ensure all long descriptions are moved

- **`test_empty_description_unchanged()`**:
  - **What it does**: Verifies handling of empty description
  - **Purpose**: Ensure empty description doesn't cause errors

- **`test_none_description_unchanged()`**:
  - **What it does**: Verifies handling of None description
  - **Purpose**: Ensure None description doesn't cause errors

#### `TestSanitizeJsonSchema`

Tests for `_sanitize_json_schema` function that cleans JSON Schema from fields not supported by Kiro API.

- **`test_returns_empty_dict_for_none()`**:
  - **What it does**: Verifies None handling
  - **Purpose**: Ensure None returns empty dict

- **`test_returns_empty_dict_for_empty_dict()`**:
  - **What it does**: Verifies empty dict handling
  - **Purpose**: Ensure empty dict is returned as-is

- **`test_removes_empty_required_array()`**:
  - **What it does**: Verifies removal of empty required array
  - **Purpose**: Ensure `required: []` is removed from schema (critical test for Cline bug)

- **`test_preserves_non_empty_required_array()`**:
  - **What it does**: Verifies preservation of non-empty required array
  - **Purpose**: Ensure required with elements is preserved

- **`test_removes_additional_properties()`**:
  - **What it does**: Verifies additionalProperties removal
  - **Purpose**: Ensure additionalProperties is removed from schema

- **`test_removes_both_empty_required_and_additional_properties()`**:
  - **What it does**: Verifies removal of both problematic fields
  - **Purpose**: Ensure both fields are removed simultaneously (real scenario from Cline)

- **`test_recursively_sanitizes_nested_properties()`**:
  - **What it does**: Verifies recursive cleaning of nested properties
  - **Purpose**: Ensure nested schemas are also cleaned

- **`test_recursively_sanitizes_dict_values()`**:
  - **What it does**: Verifies recursive cleaning of dict values
  - **Purpose**: Ensure any nested dicts are cleaned

- **`test_sanitizes_items_in_lists()`**:
  - **What it does**: Verifies cleaning of items in lists (anyOf, oneOf)
  - **Purpose**: Ensure list items are also cleaned

- **`test_preserves_non_dict_list_items()`**:
  - **What it does**: Verifies preservation of non-dict items in lists
  - **Purpose**: Ensure strings and other types in lists are preserved

- **`test_complex_real_world_schema()`**:
  - **What it does**: Verifies cleaning of real complex schema from Cline
  - **Purpose**: Ensure real schemas are processed correctly

#### `TestBuildUserInputContext`

- **`test_builds_tools_context()`**: Verifies context building with tools
- **`test_returns_empty_for_no_tools()`**: Verifies empty context return without tools

**New tests for empty description placeholder (Cline bug fix):**

- **`test_empty_description_replaced_with_placeholder()`**:
  - **What it does**: Verifies empty description replacement with placeholder
  - **Purpose**: Ensure empty description is replaced with "Tool: {name}" (critical test for Cline bug with focus_chain)

- **`test_whitespace_only_description_replaced_with_placeholder()`**:
  - **What it does**: Verifies whitespace-only description replacement with placeholder
  - **Purpose**: Ensure description with only spaces is replaced

- **`test_none_description_replaced_with_placeholder()`**:
  - **What it does**: Verifies None description replacement with placeholder
  - **Purpose**: Ensure None description is replaced with "Tool: {name}"

- **`test_non_empty_description_preserved()`**:
  - **What it does**: Verifies non-empty description preservation
  - **Purpose**: Ensure normal description is not changed

- **`test_sanitizes_tool_parameters()`**:
  - **What it does**: Verifies parameters cleaning from problematic fields
  - **Purpose**: Ensure _sanitize_json_schema is applied to parameters

- **`test_mixed_tools_with_empty_and_normal_descriptions()`**:
  - **What it does**: Verifies handling of mixed tools list
  - **Purpose**: Ensure empty descriptions are replaced while normal ones are preserved (real scenario from Cline)

#### `TestBuildKiroPayload`

- **`test_builds_simple_payload()`**: Verifies simple payload building
- **`test_includes_system_prompt_in_first_message()`**: Verifies system prompt addition
- **`test_builds_history_for_multi_turn()`**: Verifies history building for multi-turn
- **`test_handles_assistant_as_last_message()`**: Verifies handling of assistant as last message
- **`test_raises_for_empty_messages()`**: Verifies exception throwing for empty messages
- **`test_uses_continue_for_empty_content()`**: Verifies "Continue" usage for empty content
- **`test_maps_model_id_correctly()`**: Verifies external model ID mapping to internal
- **`test_long_tool_description_added_to_system_prompt()`**:
  - **What it does**: Verifies long tool descriptions integration in payload
  - **Purpose**: Ensure long descriptions are added to system prompt in payload

---

### `tests/unit/test_parsers.py`

Unit tests for **AwsEventStreamParser** and helper parsing functions. **52 tests.**

#### `TestFindMatchingBrace`

- **`test_simple_json_object()`**: Verifies closing brace search for simple JSON
- **`test_nested_json_object()`**: Verifies search for nested JSON
- **`test_json_with_braces_in_string()`**: Verifies ignoring braces inside strings
- **`test_json_with_escaped_quotes()`**: Verifies handling of escaped quotes
- **`test_incomplete_json()`**: Verifies handling of incomplete JSON
- **`test_invalid_start_position()`**: Verifies handling of invalid start position
- **`test_start_position_out_of_bounds()`**: Verifies handling of position beyond text

#### `TestParseBracketToolCalls`

- **`test_parses_single_tool_call()`**: Verifies parsing of single tool call
- **`test_parses_multiple_tool_calls()`**: Verifies parsing of multiple tool calls
- **`test_returns_empty_for_no_tool_calls()`**: Verifies empty list return without tool calls
- **`test_returns_empty_for_empty_string()`**: Verifies empty string handling
- **`test_returns_empty_for_none()`**: Verifies None handling
- **`test_handles_nested_json_in_args()`**: Verifies parsing of nested JSON in arguments
- **`test_generates_unique_ids()`**: Verifies unique ID generation for tool calls

#### `TestDeduplicateToolCalls`

- **`test_removes_duplicates()`**: Verifies duplicate removal
- **`test_preserves_first_occurrence()`**: Verifies first occurrence preservation
- **`test_handles_empty_list()`**: Verifies empty list handling

**New tests for improved deduplication by id:**

- **`test_deduplicates_by_id_keeps_one_with_arguments()`**:
  - **What it does**: Verifies deduplication by id keeping tool call with arguments
  - **Purpose**: Ensure when duplicates by id, the one with arguments is kept

- **`test_deduplicates_by_id_prefers_longer_arguments()`**:
  - **What it does**: Verifies that duplicates by id prefer longer arguments
  - **Purpose**: Ensure tool call with more complete arguments is kept

- **`test_deduplicates_empty_arguments_replaced_by_non_empty()`**:
  - **What it does**: Verifies empty arguments replacement with non-empty
  - **Purpose**: Ensure "{}" is replaced with real arguments

- **`test_handles_tool_calls_without_id()`**:
  - **What it does**: Verifies handling of tool calls without id
  - **Purpose**: Ensure tool calls without id are deduplicated by name+arguments

- **`test_mixed_with_and_without_id()`**:
  - **What it does**: Verifies mixed list with and without id
  - **Purpose**: Ensure both types are handled correctly

#### `TestAwsEventStreamParserInitialization`

- **`test_initialization_creates_empty_state()`**: Verifies initial parser state

#### `TestAwsEventStreamParserFeed`

- **`test_parses_content_event()`**: Verifies content event parsing
- **`test_parses_multiple_content_events()`**: Verifies multiple content events parsing
- **`test_deduplicates_repeated_content()`**: Verifies repeated content deduplication
- **`test_parses_usage_event()`**: Verifies usage event parsing
- **`test_parses_context_usage_event()`**: Verifies context_usage event parsing
- **`test_handles_incomplete_json()`**: Verifies incomplete JSON handling
- **`test_completes_json_across_chunks()`**: Verifies JSON assembly from multiple chunks
- **`test_decodes_escape_sequences()`**: Verifies escape sequence decoding
- **`test_handles_invalid_bytes()`**: Verifies invalid bytes handling

#### `TestAwsEventStreamParserToolCalls`

- **`test_parses_tool_start_event()`**: Verifies tool call start parsing
- **`test_parses_tool_input_event()`**: Verifies tool call input parsing
- **`test_parses_tool_stop_event()`**: Verifies tool call completion
- **`test_get_tool_calls_returns_all()`**: Verifies getting all tool calls
- **`test_get_tool_calls_finalizes_current()`**: Verifies incomplete tool call finalization

#### `TestAwsEventStreamParserReset`

- **`test_reset_clears_state()`**: Verifies parser state reset

#### `TestAwsEventStreamParserFinalizeToolCall`

**New tests for _finalize_tool_call method with different input types:**

- **`test_finalize_with_string_arguments()`**:
  - **What it does**: Verifies tool call finalization with string arguments
  - **Purpose**: Ensure JSON string is parsed and serialized back

- **`test_finalize_with_dict_arguments()`**:
  - **What it does**: Verifies tool call finalization with dict arguments
  - **Purpose**: Ensure dict is serialized to JSON string

- **`test_finalize_with_empty_string_arguments()`**:
  - **What it does**: Verifies tool call finalization with empty string arguments
  - **Purpose**: Ensure empty string is replaced with "{}"

- **`test_finalize_with_whitespace_only_arguments()`**:
  - **What it does**: Verifies tool call finalization with whitespace arguments
  - **Purpose**: Ensure whitespace string is replaced with "{}"

- **`test_finalize_with_invalid_json_arguments()`**:
  - **What it does**: Verifies tool call finalization with invalid JSON
  - **Purpose**: Ensure invalid JSON is replaced with "{}"

- **`test_finalize_with_none_current_tool_call()`**:
  - **What it does**: Verifies finalization when current_tool_call is None
  - **Purpose**: Ensure nothing happens with None

- **`test_finalize_clears_current_tool_call()`**:
  - **What it does**: Verifies that finalization clears current_tool_call
  - **Purpose**: Ensure current_tool_call = None after finalization

#### `TestAwsEventStreamParserEdgeCases`

- **`test_handles_followup_prompt()`**: Verifies followupPrompt ignoring
- **`test_handles_mixed_events()`**: Verifies mixed events parsing
- **`test_handles_garbage_between_events()`**: Verifies garbage handling between events
- **`test_handles_empty_chunk()`**: Verifies empty chunk handling

---

### `tests/unit/test_tokenizer.py`

Unit tests for **tokenizer module** (token counting with tiktoken). **32 tests.**

#### `TestCountTokens`

Tests for count_tokens function.

- **`test_empty_string_returns_zero()`**:
  - **What it does**: Verifies that empty string returns 0 tokens
  - **Purpose**: Ensure correct edge case handling

- **`test_none_returns_zero()`**:
  - **What it does**: Verifies that None returns 0 tokens
  - **Purpose**: Ensure correct None handling

- **`test_simple_text_returns_positive()`**:
  - **What it does**: Verifies that simple text returns positive token count
  - **Purpose**: Ensure basic counting functionality

- **`test_longer_text_returns_more_tokens()`**:
  - **What it does**: Verifies that longer text returns more tokens
  - **Purpose**: Ensure correct counting proportionality

- **`test_claude_correction_applied_by_default()`**:
  - **What it does**: Verifies that Claude correction factor is applied by default
  - **Purpose**: Ensure apply_claude_correction=True by default

- **`test_without_claude_correction()`**:
  - **What it does**: Verifies counting without correction factor
  - **Purpose**: Ensure apply_claude_correction=False works

- **`test_unicode_text()`**:
  - **What it does**: Verifies token counting for Unicode text
  - **Purpose**: Ensure correct non-ASCII character handling

- **`test_multiline_text()`**:
  - **What it does**: Verifies token counting for multiline text
  - **Purpose**: Ensure correct newline handling

- **`test_json_text()`**:
  - **What it does**: Verifies token counting for JSON string
  - **Purpose**: Ensure correct JSON handling

#### `TestCountTokensFallback`

Tests for fallback logic when tiktoken is unavailable.

- **`test_fallback_when_tiktoken_unavailable()`**:
  - **What it does**: Verifies fallback counting when tiktoken is unavailable
  - **Purpose**: Ensure system works without tiktoken

- **`test_fallback_without_correction()`**:
  - **What it does**: Verifies fallback without correction factor
  - **Purpose**: Ensure fallback works with apply_claude_correction=False

#### `TestCountMessageTokens`

Tests for count_message_tokens function.

- **`test_empty_list_returns_zero()`**:
  - **What it does**: Verifies that empty list returns 0 tokens
  - **Purpose**: Ensure correct empty list handling

- **`test_none_returns_zero()`**:
  - **What it does**: Verifies that None returns 0 tokens
  - **Purpose**: Ensure correct None handling

- **`test_single_user_message()`**:
  - **What it does**: Verifies token counting for single user message
  - **Purpose**: Ensure basic functionality

- **`test_multiple_messages()`**:
  - **What it does**: Verifies token counting for multiple messages
  - **Purpose**: Ensure tokens are summed correctly

- **`test_message_with_tool_calls()`**:
  - **What it does**: Verifies token counting for message with tool_calls
  - **Purpose**: Ensure tool_calls are counted

- **`test_message_with_tool_call_id()`**:
  - **What it does**: Verifies token counting for tool response message
  - **Purpose**: Ensure tool_call_id is counted

- **`test_message_with_list_content()`**:
  - **What it does**: Verifies token counting for multimodal content
  - **Purpose**: Ensure list content is handled

- **`test_without_claude_correction()`**:
  - **What it does**: Verifies counting without correction factor
  - **Purpose**: Ensure apply_claude_correction=False works

- **`test_message_with_empty_content()`**:
  - **What it does**: Verifies counting for message with empty content
  - **Purpose**: Ensure empty content doesn't break counting

- **`test_message_with_none_content()`**:
  - **What it does**: Verifies counting for message with None content
  - **Purpose**: Ensure None content doesn't break counting

#### `TestCountToolsTokens`

Tests for count_tools_tokens function.

- **`test_none_returns_zero()`**:
  - **What it does**: Verifies that None returns 0 tokens
  - **Purpose**: Ensure correct None handling

- **`test_empty_list_returns_zero()`**:
  - **What it does**: Verifies that empty list returns 0 tokens
  - **Purpose**: Ensure correct empty list handling

- **`test_single_tool()`**:
  - **What it does**: Verifies token counting for single tool
  - **Purpose**: Ensure basic functionality

- **`test_multiple_tools()`**:
  - **What it does**: Verifies token counting for multiple tools
  - **Purpose**: Ensure tokens are summed

- **`test_tool_with_complex_parameters()`**:
  - **What it does**: Verifies counting for tool with complex parameters
  - **Purpose**: Ensure JSON schema parameters are counted

- **`test_tool_without_parameters()`**:
  - **What it does**: Verifies counting for tool without parameters
  - **Purpose**: Ensure missing parameters doesn't break counting

- **`test_tool_with_empty_description()`**:
  - **What it does**: Verifies counting for tool with empty description
  - **Purpose**: Ensure empty description doesn't break counting

- **`test_non_function_tool_type()`**:
  - **What it does**: Verifies handling of tool with type != "function"
  - **Purpose**: Ensure non-function tools are handled

- **`test_without_claude_correction()`**:
  - **What it does**: Verifies counting without correction factor
  - **Purpose**: Ensure apply_claude_correction=False works

#### `TestEstimateRequestTokens`

Tests for estimate_request_tokens function.

- **`test_messages_only()`**:
  - **What it does**: Verifies token estimation for messages only
  - **Purpose**: Ensure basic functionality

- **`test_messages_with_tools()`**:
  - **What it does**: Verifies token estimation for messages with tools
  - **Purpose**: Ensure tools are counted

- **`test_messages_with_system_prompt()`**:
  - **What it does**: Verifies token estimation with separate system prompt
  - **Purpose**: Ensure system_prompt is counted

- **`test_full_request()`**:
  - **What it does**: Verifies token estimation for full request
  - **Purpose**: Ensure all components are summed

- **`test_empty_messages()`**:
  - **What it does**: Verifies estimation for empty message list
  - **Purpose**: Ensure correct edge case handling

#### `TestClaudeCorrectionFactor`

Tests for Claude correction factor.

- **`test_correction_factor_value()`**:
  - **What it does**: Verifies correction factor value
  - **Purpose**: Ensure factor equals 1.15

- **`test_correction_increases_token_count()`**:
  - **What it does**: Verifies that correction increases token count
  - **Purpose**: Ensure factor is applied correctly

#### `TestGetEncoding`

Tests for _get_encoding function.

- **`test_returns_encoding_when_tiktoken_available()`**:
  - **What it does**: Verifies that _get_encoding returns encoding when tiktoken is available
  - **Purpose**: Ensure correct tiktoken initialization

- **`test_caches_encoding()`**:
  - **What it does**: Verifies that encoding is cached
  - **Purpose**: Ensure lazy initialization

- **`test_handles_import_error()`**:
  - **What it does**: Verifies ImportError handling when tiktoken is missing
  - **Purpose**: Ensure system works without tiktoken

#### `TestTokenizerIntegration`

Integration tests for tokenizer.

- **`test_realistic_chat_request()`**:
  - **What it does**: Verifies token counting for realistic chat request
  - **Purpose**: Ensure correct operation on real data

- **`test_large_context()`**:
  - **What it does**: Verifies token counting for large context
  - **Purpose**: Ensure performance on large data

- **`test_consistency_across_calls()`**:
  - **What it does**: Verifies counting consistency across repeated calls
  - **Purpose**: Ensure results are deterministic

---

### `tests/unit/test_streaming.py`

Unit tests for **streaming module** (Kiro to OpenAI format stream conversion). **23 tests.**

#### `TestStreamingToolCallsIndex`

Tests for adding index to tool_calls in streaming responses.

- **`test_tool_calls_have_index_field()`**:
  - **What it does**: Verifies that tool_calls in streaming response contain index field
  - **Purpose**: Ensure OpenAI API spec is followed for streaming tool calls

- **`test_multiple_tool_calls_have_sequential_indices()`**:
  - **What it does**: Verifies that multiple tool_calls have sequential indices
  - **Purpose**: Ensure indices start from 0 and go sequentially

#### `TestStreamingToolCallsNoneProtection`

Tests for None value protection in tool_calls.

- **`test_handles_none_function_name()`**:
  - **What it does**: Verifies None handling in function.name
  - **Purpose**: Ensure None is replaced with empty string

- **`test_handles_none_function_arguments()`**:
  - **What it does**: Verifies None handling in function.arguments
  - **Purpose**: Ensure None is replaced with "{}"

- **`test_handles_none_function_object()`**:
  - **What it does**: Verifies None handling instead of function object
  - **Purpose**: Ensure None function is handled without errors

#### `TestCollectStreamResponseToolCalls`

Tests for collect_stream_response with tool_calls.

- **`test_collected_tool_calls_have_no_index()`**:
  - **What it does**: Verifies that collected tool_calls don't contain index field
  - **Purpose**: Ensure index is removed for non-streaming response

- **`test_collected_tool_calls_have_required_fields()`**:
  - **What it does**: Verifies that collected tool_calls contain all required fields
  - **Purpose**: Ensure id, type, function are present

- **`test_handles_none_in_collected_tool_calls()`**:
  - **What it does**: Verifies None value handling in collected tool_calls
  - **Purpose**: Ensure None values are replaced with defaults

#### `TestStreamingErrorHandling`

Tests for error handling in streaming module (bug #8 fix).

- **`test_generator_exit_handled_gracefully()`**:
  - **What it does**: Verifies that GeneratorExit is handled without logging as error
  - **Purpose**: Ensure client disconnect doesn't cause ERROR in logs

- **`test_exception_with_empty_message_logged_with_type()`**:
  - **What it does**: Verifies that exception with empty message is logged with type
  - **Purpose**: Ensure exception type is visible in logs even if str(e) is empty

- **`test_exception_propagated_to_caller()`**:
  - **What it does**: Verifies that exceptions are propagated up
  - **Purpose**: Ensure errors are not "swallowed" inside generator

- **`test_response_closed_on_error()`**:
  - **What it does**: Verifies that response is closed even on error
  - **Purpose**: Ensure resources are released in finally block

- **`test_response_closed_on_success()`**:
  - **What it does**: Verifies that response is closed on successful completion
  - **Purpose**: Ensure resources are released in finally block

- **`test_aclose_error_does_not_mask_original_error()`**:
  - **What it does**: Verifies that aclose() error doesn't mask original error
  - **Purpose**: Ensure original exception is propagated even if aclose() fails

#### `TestFirstTokenTimeoutError`

Tests for FirstTokenTimeoutError and first token timeout logging.

- **`test_first_token_timeout_not_caught_by_general_handler()`**:
  - **What it does**: Verifies that FirstTokenTimeoutError is propagated for retry
  - **Purpose**: Ensure first token timeout is not handled as regular error

- **`test_first_token_timeout_logged_with_correct_format()`**:
  - **What it does**: Verifies that first token timeout is logged with [FirstTokenTimeout] prefix
  - **Purpose**: Ensure consistent logging format for first token timeout

- **`test_first_token_timeout_includes_timeout_value()`**:
  - **What it does**: Verifies that first token timeout log includes the timeout value
  - **Purpose**: Ensure timeout value is visible in logs for debugging

- **`test_first_token_received_logged_on_success()`**:
  - **What it does**: Verifies that successful first token receipt is logged
  - **Purpose**: Ensure debug log shows when first token is received

#### `TestStreamWithFirstTokenRetry`

Tests for stream_with_first_token_retry function.

- **`test_retry_on_first_token_timeout()`**:
  - **What it does**: Verifies that request is retried on first token timeout
  - **Purpose**: Ensure retry logic works for first token timeout

- **`test_all_retries_exhausted_raises_504()`**:
  - **What it does**: Verifies that 504 is raised after all retries exhausted
  - **Purpose**: Ensure proper error handling when model never responds

- **`test_retry_logs_attempt_number()`**:
  - **What it does**: Verifies that retry attempts are logged with attempt number
  - **Purpose**: Ensure logs show which attempt failed (e.g., "1/3", "2/3", "3/3")

---

### `tests/unit/test_http_client.py`

Unit tests for **KiroHttpClient** (HTTP client with retry logic). **29 tests.**

#### `TestKiroHttpClientInitialization`

- **`test_initialization_stores_auth_manager()`**: Verifies auth_manager storage during initialization
- **`test_initialization_client_is_none()`**: Verifies that HTTP client is initially None

#### `TestKiroHttpClientGetClient`

- **`test_get_client_creates_new_client()`**: Verifies new HTTP client creation
- **`test_get_client_reuses_existing_client()`**: Verifies existing client reuse
- **`test_get_client_recreates_closed_client()`**: Verifies closed client recreation

#### `TestKiroHttpClientClose`

- **`test_close_closes_client()`**: Verifies HTTP client closing
- **`test_close_does_nothing_for_none_client()`**: Verifies close() doesn't crash for None client
- **`test_close_does_nothing_for_closed_client()`**: Verifies close() doesn't crash for closed client

#### `TestKiroHttpClientRequestWithRetry`

- **`test_successful_request_returns_response()`**: Verifies successful request
- **`test_403_triggers_token_refresh()`**: Verifies token refresh on 403
- **`test_429_triggers_backoff()`**: Verifies exponential backoff on 429
- **`test_5xx_triggers_backoff()`**: Verifies exponential backoff on 5xx
- **`test_timeout_triggers_backoff()`**: Verifies exponential backoff on timeout
- **`test_request_error_triggers_backoff()`**: Verifies exponential backoff on request error
- **`test_max_retries_exceeded_raises_502()`**: Verifies HTTPException after retries exhausted
- **`test_other_status_codes_returned_as_is()`**: Verifies other status codes return without retry
- **`test_streaming_request_uses_send()`**: Verifies send() usage for streaming

#### `TestKiroHttpClientContextManager`

- **`test_context_manager_returns_self()`**: Verifies __aenter__ returns self
- **`test_context_manager_closes_on_exit()`**: Verifies client closing on context exit

#### `TestKiroHttpClientExponentialBackoff`

- **`test_backoff_delay_increases_exponentially()`**: Verifies exponential delay increase

#### `TestKiroHttpClientStreamingTimeout`

Tests for streaming timeout logic (httpx timeouts, not FIRST_TOKEN_TIMEOUT).

- **`test_streaming_uses_streaming_read_timeout()`**:
  - **What it does**: Verifies that streaming requests use STREAMING_READ_TIMEOUT for read timeout
  - **Purpose**: Ensure httpx.Timeout is configured with connect=30s and read=STREAMING_READ_TIMEOUT

- **`test_streaming_uses_first_token_max_retries()`**:
  - **What it does**: Verifies that streaming requests use FIRST_TOKEN_MAX_RETRIES
  - **Purpose**: Ensure separate retry counter is used for stream=True

- **`test_streaming_timeout_retry_without_delay()`**:
  - **What it does**: Verifies that streaming timeout retry happens without delay
  - **Purpose**: Ensure no exponential backoff on streaming timeout

- **`test_non_streaming_uses_default_timeout()`**:
  - **What it does**: Verifies that non-streaming requests use httpx.Timeout(timeout=300)
  - **Purpose**: Ensure unified 300s timeout for all operations in non-streaming mode

- **`test_connect_timeout_logged_correctly()`**:
  - **What it does**: Verifies that ConnectTimeout is logged with [ConnectTimeout] prefix
  - **Purpose**: Ensure timeout type is visible in logs for debugging

- **`test_read_timeout_logged_correctly()`**:
  - **What it does**: Verifies that ReadTimeout is logged with [ReadTimeout] prefix and STREAMING_READ_TIMEOUT value
  - **Purpose**: Ensure timeout type and value are visible in logs

- **`test_streaming_timeout_returns_504_with_error_type()`**:
  - **What it does**: Verifies that streaming timeout returns 504 with error type in detail
  - **Purpose**: Ensure 504 Gateway Timeout includes error type (e.g., "ReadTimeout")

- **`test_non_streaming_timeout_returns_502()`**:
  - **What it does**: Verifies that non-streaming timeout returns 502
  - **Purpose**: Ensure old logic with 502 is used for non-streaming

---

### `tests/unit/test_routes.py`

Unit tests for **API endpoints** (/v1/models, /v1/chat/completions). **22 tests.**

#### `TestVerifyApiKey`

- **`test_valid_api_key_returns_true()`**: Verifies successful validation of correct key
- **`test_invalid_api_key_raises_401()`**: Verifies invalid key rejection
- **`test_missing_api_key_raises_401()`**: Verifies missing key rejection
- **`test_empty_api_key_raises_401()`**: Verifies empty key rejection
- **`test_wrong_format_raises_401()`**: Verifies key without Bearer rejection

#### `TestRootEndpoint`

- **`test_root_returns_status_ok()`**: Verifies root endpoint response
- **`test_root_returns_version()`**: Verifies version presence in response

#### `TestHealthEndpoint`

- **`test_health_returns_healthy()`**: Verifies health endpoint response
- **`test_health_returns_timestamp()`**: Verifies timestamp presence in response
- **`test_health_returns_version()`**: Verifies version presence in response

#### `TestModelsEndpoint`

- **`test_models_requires_auth()`**: Verifies authorization requirement
- **`test_models_returns_list()`**: Verifies model list return
- **`test_models_returns_available_models()`**: Verifies available models presence
- **`test_models_format_is_openai_compatible()`**: Verifies response format OpenAI compatibility

#### `TestChatCompletionsEndpoint`

- **`test_chat_completions_requires_auth()`**: Verifies authorization requirement
- **`test_chat_completions_validates_messages()`**: Verifies empty messages validation
- **`test_chat_completions_validates_model()`**: Verifies missing model validation

#### `TestChatCompletionsWithMockedKiro`

- **`test_chat_completions_accepts_valid_request_format()`**: Verifies valid request format acceptance

#### `TestChatCompletionsErrorHandling`

- **`test_invalid_json_returns_422()`**: Verifies invalid JSON handling
- **`test_missing_content_in_message_returns_200()`**: Verifies message without content handling

#### `TestRouterIntegration`

- **`test_router_has_all_endpoints()`**: Verifies all endpoints presence in router
- **`test_router_methods()`**: Verifies endpoint HTTP methods

---

### `tests/integration/test_full_flow.py`

Integration tests for **full end-to-end flow**. **12 tests (11 passed, 1 skipped).**

#### `TestFullChatCompletionFlow`

- **`test_full_flow_health_to_models_to_chat()`**: Verifies full flow from health check to chat completions
- **`test_authentication_flow()`**: Verifies authentication flow
- **`test_openai_compatibility_format()`**: Verifies response format compatibility with OpenAI API

#### `TestRequestValidationFlow`

- **`test_chat_completions_request_validation()`**: Verifies various request format validation
- **`test_complex_message_formats()`**: Verifies complex message format handling

#### `TestErrorHandlingFlow`

- **`test_invalid_json_handling()`**: Verifies invalid JSON handling
- **`test_wrong_content_type_handling()`**: SKIPPED - bug discovered in validation_exception_handler

#### `TestModelsEndpointIntegration`

- **`test_models_returns_all_available_models()`**: Verifies all models from config are returned
- **`test_models_caching_behavior()`**: Verifies model caching behavior

#### `TestStreamingFlagHandling`

- **`test_stream_true_accepted()`**: Verifies stream=true acceptance
- **`test_stream_false_accepted()`**: Verifies stream=false acceptance

#### `TestHealthEndpointIntegration`

- **`test_root_and_health_consistency()`**: Verifies / and /health consistency

---

## Testing Philosophy

### Principles

1. **Isolation**: Each test is completely isolated from external services through mocks
2. **Detail**: Abundant print() for understanding test flow during debugging
3. **Coverage**: Tests cover not only happy path, but also edge cases and errors
4. **Security**: All tests use mock credentials, never real ones

### Test Structure (Arrange-Act-Assert)

Each test follows the pattern:
1. **Arrange** (Setup): Prepare mocks and data
2. **Act** (Action): Execute the tested action
3. **Assert** (Verify): Verify result with explicit comparison

### Test Types

- **Unit tests**: Test individual functions/classes in isolation
- **Integration tests**: Verify component interactions
- **Security tests**: Verify security system
- **Edge case tests**: Paranoid edge case checks

## Adding New Tests

When adding new tests:

1. Follow existing class structure (`Test*Success`, `Test*Errors`, `Test*EdgeCases`)
2. Use descriptive names: `test_<what_it_does>_<expected_result>`
3. Add docstring with "What it does" and "Purpose"
4. Use print() for logging test steps
5. Update this README with new test description

## Troubleshooting

### Tests fail with ImportError

```bash
# Make sure you're in project root
cd /path/to/kiro-openai-gateway

# pytest.ini already contains pythonpath = .
# Just run pytest
pytest
```

### Tests pass locally but fail in CI

- Check dependency versions in requirements.txt
- Ensure all mocks correctly isolate external calls

### Async tests don't work

```bash
# Make sure pytest-asyncio is installed
pip install pytest-asyncio

# Check for @pytest.mark.asyncio decorator
```

## Coverage Metrics

To check code coverage:

```bash
# Install coverage
pip install pytest-cov

# Run with coverage report
pytest --cov=kiro_gateway --cov-report=html

# View report
open htmlcov/index.html  # macOS/Linux
start htmlcov/index.html  # Windows
```

## Contacts and Support

If you find bugs or have suggestions for test improvements, create an issue in the project repository.



================================================
FILE: tests/conftest.py
================================================
# -*- coding: utf-8 -*-

"""
–û–±—â–∏–µ —Ñ–∏–∫—Å—Ç—É—Ä—ã –∏ —É—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è Kiro OpenAI Gateway.

–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –∏–∑–æ–ª—è—Ü–∏—é —Ç–µ—Å—Ç–æ–≤ –æ—Ç –≤–Ω–µ—à–Ω–∏—Ö —Å–µ—Ä–≤–∏—Å–æ–≤ –∏ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è.
–í—Å–µ —Ç–µ—Å—Ç—ã –î–û–õ–ñ–ù–´ –±—ã—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω—ã –æ—Ç —Å–µ—Ç–∏.
"""

import asyncio
import json
import pytest
import time
from typing import AsyncGenerator, Dict, Any, List
from unittest.mock import AsyncMock, MagicMock, Mock, patch
from datetime import datetime, timezone

import httpx
from fastapi.testclient import TestClient


# =============================================================================
# Event Loop —Ñ–∏–∫—Å—Ç—É—Ä—ã
# =============================================================================

@pytest.fixture(scope="session")
def event_loop():
    """
    –°–æ–∑–¥–∞–µ—Ç event loop –¥–ª—è –≤—Å–µ–π —Å–µ—Å—Å–∏–∏ —Ç–µ—Å—Ç–æ–≤.
    –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã async —Ñ–∏–∫—Å—Ç—É—Ä.
    """
    print("–°–æ–∑–¥–∞–Ω–∏–µ event loop –¥–ª—è —Å–µ—Å—Å–∏–∏ —Ç–µ—Å—Ç–æ–≤...")
    loop = asyncio.get_event_loop_policy().new_event_loop()
    yield loop
    print("–ó–∞–∫—Ä—ã—Ç–∏–µ event loop...")
    loop.close()


# =============================================================================
# –§–∏–∫—Å—Ç—É—Ä—ã –æ–∫—Ä—É–∂–µ–Ω–∏—è
# =============================================================================

@pytest.fixture
def mock_env_vars(monkeypatch):
    """
    –ú–æ–∫–∏—Ä—É–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –∏–∑–æ–ª—è—Ü–∏–∏ –æ—Ç —Ä–µ–∞–ª—å–Ω—ã—Ö credentials.
    """
    print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è...")
    monkeypatch.setenv("REFRESH_TOKEN", "test_refresh_token_abcdef")
    monkeypatch.setenv("PROXY_API_KEY", "test_proxy_key_12345")
    monkeypatch.setenv("PROFILE_ARN", "arn:aws:codewhisperer:us-east-1:123456789:profile/test")
    monkeypatch.setenv("KIRO_REGION", "us-east-1")
    return {
        "REFRESH_TOKEN": "test_refresh_token_abcdef",
        "PROXY_API_KEY": "test_proxy_key_12345",
        "PROFILE_ARN": "arn:aws:codewhisperer:us-east-1:123456789:profile/test",
        "KIRO_REGION": "us-east-1"
    }


# =============================================================================
# –§–∏–∫—Å—Ç—É—Ä—ã —Ç–æ–∫–µ–Ω–æ–≤ –∏ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
# =============================================================================

@pytest.fixture
def valid_kiro_token():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–∞–ª–∏–¥–Ω—ã–π –º–æ–∫ Kiro access token."""
    return "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.test_kiro_access_token"


@pytest.fixture
def mock_kiro_token_response(valid_kiro_token):
    """
    –§–∞–±—Ä–∏–∫–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –º–æ–∫-–æ—Ç–≤–µ—Ç–∞ Kiro token refresh endpoint.
    """
    def _create_response(expires_in: int = 3600, token: str = None):
        return {
            "accessToken": token or valid_kiro_token,
            "refreshToken": "new_refresh_token_xyz",
            "expiresIn": expires_in,
            "profileArn": "arn:aws:codewhisperer:us-east-1:123456789:profile/test"
        }
    return _create_response


@pytest.fixture
def valid_proxy_api_key():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤–∞–ª–∏–¥–Ω—ã–π API –∫–ª—é—á –ø—Ä–æ–∫—Å–∏ (–∏–∑ config)."""
    return "changeme_proxy_secret"


@pytest.fixture
def invalid_proxy_api_key():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π API –∫–ª—é—á –¥–ª—è –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤."""
    return "invalid_wrong_secret_key"


@pytest.fixture
def auth_headers(valid_proxy_api_key):
    """
    –§–∞–±—Ä–∏–∫–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤–∞–ª–∏–¥–Ω—ã—Ö –∏ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã—Ö Authorization headers.
    """
    def _create_headers(api_key: str = None, invalid: bool = False):
        if invalid:
            return {"Authorization": "Bearer wrong_key_123"}
        key = api_key or valid_proxy_api_key
        return {"Authorization": f"Bearer {key}"}
    
    return _create_headers


# =============================================================================
# –§–∏–∫—Å—Ç—É—Ä—ã –º–æ–¥–µ–ª–µ–π Kiro
# =============================================================================

@pytest.fixture
def mock_kiro_models_response():
    """
    –ú–æ–∫ —É—Å–ø–µ—à–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –æ—Ç Kiro API –¥–ª—è ListAvailableModels.
    """
    return {
        "models": [
            {
                "modelId": "claude-sonnet-4.5",
                "displayName": "Claude Sonnet 4.5",
                "tokenLimits": {
                    "maxInputTokens": 200000,
                    "maxOutputTokens": 8192
                }
            },
            {
                "modelId": "claude-opus-4.5",
                "displayName": "Claude Opus 4.5",
                "tokenLimits": {
                    "maxInputTokens": 200000,
                    "maxOutputTokens": 8192
                }
            },
            {
                "modelId": "claude-haiku-4.5",
                "displayName": "Claude Haiku 4.5",
                "tokenLimits": {
                    "maxInputTokens": 200000,
                    "maxOutputTokens": 8192
                }
            }
        ]
    }


# =============================================================================
# –§–∏–∫—Å—Ç—É—Ä—ã streaming –æ—Ç–≤–µ—Ç–æ–≤ Kiro
# =============================================================================

@pytest.fixture
def mock_kiro_streaming_chunks():
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –º–æ–∫ SSE chunks –æ—Ç Kiro API –¥–ª—è streaming response.
    –ü–æ–∫—Ä—ã–≤–∞–µ—Ç: –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç, tool calls, usage.
    """
    return [
        # Chunk 1: –ù–∞—á–∞–ª–æ —Ç–µ–∫—Å—Ç–∞
        b'{"content":"Hello"}',
        # Chunk 2: –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
        b'{"content":" World!"}',
        # Chunk 3: Tool call start
        b'{"name":"get_weather","toolUseId":"call_abc123"}',
        # Chunk 4: Tool call input
        b'{"input":"{\\"location\\": \\"Moscow\\"}"}',
        # Chunk 5: Tool call stop
        b'{"stop":true}',
        # Chunk 6: Usage
        b'{"usage":1.5}',
        # Chunk 7: Context usage
        b'{"contextUsagePercentage":25.5}',
    ]

@pytest.fixture
def mock_kiro_simple_text_chunks():
    """
    –ú–æ–∫ –ø—Ä–æ—Å—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –æ—Ç Kiro (–±–µ–∑ tool calls).
    """
    return [
        b'{"content":"This is a complete response."}',
        b'{"usage":0.5}',
        b'{"contextUsagePercentage":10.0}',
    ]


@pytest.fixture
def mock_kiro_stream_with_usage():
    """
    –ú–æ–∫ SSE –æ—Ç–≤–µ—Ç–∞ Kiro —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ usage.
    """
    return [
        b'{"content":"Final text."}',
        b'{"usage":1.3}',
        b'{"contextUsagePercentage":50.0}',
    ]


# =============================================================================
# –§–∏–∫—Å—Ç—É—Ä—ã OpenAI –∑–∞–ø—Ä–æ—Å–æ–≤
# =============================================================================

@pytest.fixture
def sample_openai_chat_request():
    """
    –§–∞–±—Ä–∏–∫–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤–∞–ª–∏–¥–Ω—ã—Ö OpenAI chat completion requests.
    """
    def _create_request(
        model: str = "claude-sonnet-4-5",
        messages: list = None,
        stream: bool = False,
        temperature: float = None,
        max_tokens: int = None,
        tools: list = None,
        **kwargs
    ):
        if messages is None:
            messages = [{"role": "user", "content": "Hello, AI!"}]
        
        request = {
            "model": model,
            "messages": messages,
            "stream": stream
        }
        
        if temperature is not None:
            request["temperature"] = temperature
        if max_tokens is not None:
            request["max_tokens"] = max_tokens
        if tools is not None:
            request["tools"] = tools
        
        request.update(kwargs)
        return request
    
    return _create_request


@pytest.fixture
def sample_tool_definition():
    """
    –ü—Ä–∏–º–µ—Ä –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è tool –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è tool calling.
    """
    return {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "Get weather for a location",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {"type": "string", "description": "City name"}
                },
                "required": ["location"]
            }
        }
    }


# =============================================================================
# –§–∏–∫—Å—Ç—É—Ä—ã HTTP –∫–ª–∏–µ–Ω—Ç–∞
# =============================================================================

@pytest.fixture
async def mock_httpx_client():
    """
    –°–æ–∑–¥–∞–µ—Ç –º–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–π httpx.AsyncClient –¥–ª—è –∏–∑–æ–ª—è—Ü–∏–∏ –æ—Ç —Å–µ—Ç–µ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤.
    """
    print("–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ httpx.AsyncClient...")
    mock_client = AsyncMock(spec=httpx.AsyncClient)
    
    # –ú–æ–∫–∏—Ä—É–µ–º –º–µ—Ç–æ–¥—ã
    mock_client.post = AsyncMock()
    mock_client.get = AsyncMock()
    mock_client.aclose = AsyncMock()
    mock_client.build_request = Mock()
    mock_client.send = AsyncMock()
    mock_client.is_closed = False
    
    return mock_client


@pytest.fixture
def mock_httpx_response():
    """
    –§–∞–±—Ä–∏–∫–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –º–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö httpx.Response –æ–±—ä–µ–∫—Ç–æ–≤.
    """
    def _create_response(
        status_code: int = 200,
        json_data: Dict[str, Any] = None,
        text: str = None,
        stream_chunks: list = None
    ):
        print(f"–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–∫ httpx.Response (status={status_code})...")
        mock_response = AsyncMock(spec=httpx.Response)
        mock_response.status_code = status_code
        
        if json_data is not None:
            mock_response.json = Mock(return_value=json_data)
        
        if text is not None:
            mock_response.text = text
            mock_response.content = text.encode()
        
        if stream_chunks is not None:
            # –î–ª—è streaming responses
            async def mock_aiter_bytes():
                for chunk in stream_chunks:
                    yield chunk
            
            mock_response.aiter_bytes = mock_aiter_bytes
        
        mock_response.raise_for_status = Mock()
        mock_response.aclose = AsyncMock()
        mock_response.aread = AsyncMock(return_value=b'{"error": "mocked error"}')
        
        return mock_response
    
    return _create_response


# =============================================================================
# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ —Å–µ—Ç–∏
# =============================================================================

@pytest.fixture(scope="session", autouse=True)
def block_all_network_calls():
    """
    –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –§–ò–ö–°–¢–£–†–ê: –ì–ª–æ–±–∞–ª—å–Ω–æ –±–ª–æ–∫–∏—Ä—É–µ—Ç –í–°–ï —Å–µ—Ç–µ–≤—ã–µ –≤—ã–∑–æ–≤—ã.
    –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ –ù–ò –û–î–ò–ù —Ç–µ—Å—Ç –Ω–µ —Å–º–æ–∂–µ—Ç —Å–¥–µ–ª–∞—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π —Å–µ—Ç–µ–≤–æ–π –∑–∞–ø—Ä–æ—Å.
    """
    
    # –°–æ–∑–¥–∞–µ–º –º–æ–∫, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è –≤—Å–µ—Ö –∏–Ω—Å—Ç–∞–Ω—Å–æ–≤ AsyncClient
    mock_async_client = AsyncMock(spec=httpx.AsyncClient)

    async def network_call_error(*args, **kwargs):
        raise RuntimeError(
            "üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –ø–æ–ø—ã—Ç–∫–∞ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Å–µ—Ç–µ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞! "
            "–¢–µ—Å—Ç –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏–ª –º–æ–∫ –¥–ª—è httpx.AsyncClient. "
            "–í—Å–µ HTTP –≤—ã–∑–æ–≤—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —è–≤–Ω–æ –∑–∞–º–æ–∫–∏—Ä–æ–≤–∞–Ω—ã."
        )

    mock_async_client.post.side_effect = network_call_error
    mock_async_client.get.side_effect = network_call_error
    mock_async_client.send.side_effect = network_call_error
    
    # –ú–æ–∫–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä
    mock_async_client.__aenter__ = AsyncMock(return_value=mock_async_client)
    mock_async_client.__aexit__ = AsyncMock()
    mock_async_client.aclose = AsyncMock()
    mock_async_client.is_closed = False

    # –ü–∞—Ç—á–∏–º AsyncClient –≤ –º–æ–¥—É–ª—è—Ö –≥–¥–µ –æ–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
    patchers = [
        patch('kiro_gateway.auth.httpx.AsyncClient', return_value=mock_async_client),
        patch('kiro_gateway.http_client.httpx.AsyncClient', return_value=mock_async_client),
        patch('kiro_gateway.routes.httpx.AsyncClient', return_value=mock_async_client),
        patch('kiro_gateway.streaming.httpx.AsyncClient', return_value=mock_async_client),
    ]
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ç—á–µ—Ä—ã
    for patcher in patchers:
        patcher.start()
    
    print("üõ°Ô∏è –ì–õ–û–ë–ê–õ–¨–ù–ê–Ø –ë–õ–û–ö–ò–†–û–í–ö–ê –°–ï–¢–ò –ê–ö–¢–ò–í–ò–†–û–í–ê–ù–ê")
    
    yield

    # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–∞—Ç—á–µ—Ä—ã
    for patcher in patchers:
        patcher.stop()
    
    print("üõ°Ô∏è –ì–õ–û–ë–ê–õ–¨–ù–ê–Ø –ë–õ–û–ö–ò–†–û–í–ö–ê –°–ï–¢–ò –î–ï–ê–ö–¢–ò–í–ò–†–û–í–ê–ù–ê")


# =============================================================================
# –§–∏–∫—Å—Ç—É—Ä—ã –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
# =============================================================================

@pytest.fixture
def clean_app():
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç "—á–∏—Å—Ç—ã–π" —ç–∫–∑–µ–º–ø–ª—è—Ä –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ—Å—Ç–∞.
    """
    print("–ò–º–ø–æ—Ä—Ç –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –¥–ª—è —Ç–µ—Å—Ç–∞...")
    from main import app
    # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –≤—Å–µ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –ø–µ—Ä–µ–¥ —Ç–µ—Å—Ç–æ–º
    app.dependency_overrides = {}
    return app


@pytest.fixture
def test_client(clean_app):
    """
    –°–æ–∑–¥–∞–µ—Ç FastAPI TestClient –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤ endpoints,
    –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—è lifespan —Å–æ–±—ã—Ç–∏—è.
    """
    print("–°–æ–∑–¥–∞–Ω–∏–µ TestClient —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π lifespan...")
    with TestClient(clean_app) as client:
        yield client
    print("–ó–∞–∫—Ä—ã—Ç–∏–µ TestClient...")


@pytest.fixture
async def async_test_client(clean_app):
    """
    –°–æ–∑–¥–∞–µ—Ç –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π test client –¥–ª—è async endpoints.
    """
    print("–°–æ–∑–¥–∞–Ω–∏–µ async test client...")
    from httpx import AsyncClient, ASGITransport
    
    transport = ASGITransport(app=clean_app)
    async with AsyncClient(transport=transport, base_url="http://test") as client:
        yield client
    
    print("–ó–∞–∫—Ä—ã—Ç–∏–µ async test client...")


# =============================================================================
# –§–∏–∫—Å—Ç—É—Ä—ã –¥–ª—è KiroAuthManager
# =============================================================================

@pytest.fixture
def mock_auth_manager():
    """
    –°–æ–∑–¥–∞–µ—Ç –º–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–π KiroAuthManager –¥–ª—è —Ç–µ—Å—Ç–æ–≤.
    """
    from kiro_gateway.auth import KiroAuthManager
    
    manager = KiroAuthManager(
        refresh_token="test_refresh_token",
        profile_arn="arn:aws:codewhisperer:us-east-1:123456789:profile/test",
        region="us-east-1"
    )
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤–∞–ª–∏–¥–Ω—ã–π —Ç–æ–∫–µ–Ω
    manager._access_token = "test_access_token"
    manager._expires_at = datetime.now(timezone.utc).replace(
        year=2099  # –î–∞–ª–µ–∫–æ –≤ –±—É–¥—É—â–µ–º
    )
    
    return manager


@pytest.fixture
def expired_auth_manager():
    """
    –°–æ–∑–¥–∞–µ—Ç KiroAuthManager —Å –∏—Å—Ç–µ–∫—à–∏–º —Ç–æ–∫–µ–Ω–æ–º.
    """
    from kiro_gateway.auth import KiroAuthManager
    
    manager = KiroAuthManager(
        refresh_token="test_refresh_token",
        profile_arn="arn:aws:codewhisperer:us-east-1:123456789:profile/test",
        region="us-east-1"
    )
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏—Å—Ç–µ–∫—à–∏–π —Ç–æ–∫–µ–Ω
    manager._access_token = "expired_token"
    manager._expires_at = datetime.now(timezone.utc).replace(
        year=2020  # –í –ø—Ä–æ—à–ª–æ–º
    )
    
    return manager


# =============================================================================
# –§–∏–∫—Å—Ç—É—Ä—ã –¥–ª—è ModelInfoCache
# =============================================================================

@pytest.fixture
def sample_models_data():
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è ModelInfoCache.
    """
    return [
        {
            "modelId": "claude-sonnet-4",
            "displayName": "Claude Sonnet 4",
            "tokenLimits": {
                "maxInputTokens": 200000,
                "maxOutputTokens": 8192
            }
        },
        {
            "modelId": "claude-opus-4.5",
            "displayName": "Claude Opus 4.5",
            "tokenLimits": {
                "maxInputTokens": 200000,
                "maxOutputTokens": 8192
            }
        },
        {
            "modelId": "claude-haiku-4.5",
            "displayName": "Claude Haiku 4.5",
            "tokenLimits": {
                "maxInputTokens": 100000,
                "maxOutputTokens": 4096
            }
        }
    ]


@pytest.fixture
def empty_model_cache():
    """
    –°–æ–∑–¥–∞–µ—Ç –ø—É—Å—Ç–æ–π ModelInfoCache.
    """
    from kiro_gateway.cache import ModelInfoCache
    return ModelInfoCache()


@pytest.fixture
async def populated_model_cache(mock_kiro_models_response):
    """
    –°–æ–∑–¥–∞–µ—Ç ModelInfoCache —Å –ø—Ä–µ–¥–∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏.
    """
    from kiro_gateway.cache import ModelInfoCache
    
    cache = ModelInfoCache()
    await cache.update(mock_kiro_models_response["models"])
    return cache


# =============================================================================
# –§–∏–∫—Å—Ç—É—Ä—ã –≤—Ä–µ–º–µ–Ω–∏
# =============================================================================

@pytest.fixture
def mock_time():
    """
    –ú–æ–∫–∏—Ä—É–µ—Ç time.time() –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è –≤ —Ç–µ—Å—Ç–∞—Ö.
    """
    with patch('time.time') as mock:
        # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ä–µ–º–µ–Ω–∏: 2024-01-01 12:00:00
        mock.return_value = 1704110400.0
        yield mock


@pytest.fixture
def mock_datetime():
    """
    –ú–æ–∫–∏—Ä—É–µ—Ç datetime.now() –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è.
    """
    fixed_time = datetime(2024, 1, 1, 12, 0, 0, tzinfo=timezone.utc)
    
    with patch('kiro_gateway.auth.datetime') as mock_dt:
        mock_dt.now.return_value = fixed_time
        mock_dt.fromisoformat = datetime.fromisoformat
        mock_dt.fromtimestamp = datetime.fromtimestamp
        yield mock_dt


# =============================================================================
# –§–∏–∫—Å—Ç—É—Ä—ã –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
# =============================================================================

@pytest.fixture
def temp_creds_file(tmp_path):
    """
    –°–æ–∑–¥–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª credentials –¥–ª—è —Ç–µ—Å—Ç–æ–≤.
    """
    creds_file = tmp_path / "kiro-auth-token.json"
    creds_data = {
        "accessToken": "file_access_token",
        "refreshToken": "file_refresh_token",
        "expiresAt": "2099-01-01T00:00:00.000Z",
        "profileArn": "arn:aws:codewhisperer:us-east-1:123456789:profile/test",
        "region": "us-east-1"
    }
    creds_file.write_text(json.dumps(creds_data))
    return str(creds_file)


@pytest.fixture
def temp_debug_dir(tmp_path):
    """
    –°–æ–∑–¥–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è debug —Ñ–∞–π–ª–æ–≤.
    """
    debug_dir = tmp_path / "debug_logs"
    debug_dir.mkdir()
    return debug_dir


# =============================================================================
# –§–∏–∫—Å—Ç—É—Ä—ã –¥–ª—è –ø–∞—Ä—Å–µ—Ä–∞
# =============================================================================

@pytest.fixture
def aws_event_parser():
    """
    –°–æ–∑–¥–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä AwsEventStreamParser –¥–ª—è —Ç–µ—Å—Ç–æ–≤.
    """
    from kiro_gateway.parsers import AwsEventStreamParser
    return AwsEventStreamParser()


# =============================================================================
# –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ç–µ—Å—Ç–æ–≤
# =============================================================================

def create_kiro_content_chunk(content: str) -> bytes:
    """–£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è Kiro SSE chunk —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º."""
    return f'{{"content":"{content}"}}'.encode()


def create_kiro_tool_start_chunk(name: str, tool_id: str) -> bytes:
    """–£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è Kiro SSE chunk —Å –Ω–∞—á–∞–ª–æ–º tool call."""
    return f'{{"name":"{name}","toolUseId":"{tool_id}"}}'.encode()


def create_kiro_tool_input_chunk(input_json: str) -> bytes:
    """–£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è Kiro SSE chunk —Å input –¥–ª—è tool call."""
    escaped = input_json.replace('"', '\\"')
    return f'{{"input":"{escaped}"}}'.encode()


def create_kiro_tool_stop_chunk() -> bytes:
    """–£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è Kiro SSE chunk —Å –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ–º tool call."""
    return b'{"stop":true}'


def create_kiro_usage_chunk(usage: float) -> bytes:
    """–£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è Kiro SSE chunk —Å usage."""
    return f'{{"usage":{usage}}}'.encode()


def create_kiro_context_usage_chunk(percentage: float) -> bytes:
    """–£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è Kiro SSE chunk —Å context usage."""
    return f'{{"contextUsagePercentage":{percentage}}}'.encode()


================================================
FILE: tests/integration/test_full_flow.py
================================================
# -*- coding: utf-8 -*-

"""
Integration-—Ç–µ—Å—Ç—ã –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ end-to-end flow.
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã.
"""

import pytest
import json
from unittest.mock import AsyncMock, Mock, patch, MagicMock
from datetime import datetime, timezone, timedelta

from fastapi.testclient import TestClient
import httpx

from kiro_gateway.config import PROXY_API_KEY, AVAILABLE_MODELS


class TestFullChatCompletionFlow:
    """Integration-—Ç–µ—Å—Ç—ã –ø–æ–ª–Ω–æ–≥–æ flow chat completions."""
    
    def test_full_flow_health_to_models_to_chat(self, test_client, valid_proxy_api_key):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–ª–Ω—ã–π flow –æ—Ç health check –¥–æ chat completions.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤—Å–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã —Ä–∞–±–æ—Ç–∞—é—Ç –≤–º–µ—Å—Ç–µ.
        """
        print("–®–∞–≥ 1: Health check...")
        health_response = test_client.get("/health")
        assert health_response.status_code == 200
        assert health_response.json()["status"] == "healthy"
        print(f"Health: {health_response.json()}")
        
        print("–®–∞–≥ 2: –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π...")
        models_response = test_client.get(
            "/v1/models",
            headers={"Authorization": f"Bearer {valid_proxy_api_key}"}
        )
        assert models_response.status_code == 200
        assert len(models_response.json()["data"]) > 0
        print(f"–ú–æ–¥–µ–ª–∏: {[m['id'] for m in models_response.json()['data']]}")
        
        print("–®–∞–≥ 3: –í–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞ chat completions...")
        # –≠—Ç–æ—Ç –∑–∞–ø—Ä–æ—Å –ø—Ä–æ–π–¥—ë—Ç –≤–∞–ª–∏–¥–∞—Ü–∏—é, –Ω–æ —É–ø–∞–¥—ë—Ç –Ω–∞ HTTP –∏–∑-–∑–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ —Å–µ—Ç–∏
        chat_response = test_client.post(
            "/v1/chat/completions",
            headers={"Authorization": f"Bearer {valid_proxy_api_key}"},
            json={
                "model": "claude-sonnet-4-5",
                "messages": [{"role": "user", "content": "Hello"}]
            }
        )
        # –ó–∞–ø—Ä–æ—Å –¥–æ–ª–∂–µ–Ω –ø—Ä–æ–π—Ç–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é (–Ω–µ 422)
        assert chat_response.status_code != 422
        print(f"Chat response status: {chat_response.status_code}")
    
    def test_authentication_flow(self, test_client, valid_proxy_api_key, invalid_proxy_api_key):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç flow –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –∑–∞—â–∏—â—ë–Ω–Ω—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã —Ç—Ä–µ–±—É—é—Ç –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏.
        """
        print("–®–∞–≥ 1: –ó–∞–ø—Ä–æ—Å –±–µ–∑ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏...")
        no_auth_response = test_client.get("/v1/models")
        assert no_auth_response.status_code == 401
        print(f"–ë–µ–∑ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏: {no_auth_response.status_code}")
        
        print("–®–∞–≥ 2: –ó–∞–ø—Ä–æ—Å —Å –Ω–µ–≤–µ—Ä–Ω—ã–º –∫–ª—é—á–æ–º...")
        wrong_auth_response = test_client.get(
            "/v1/models",
            headers={"Authorization": f"Bearer {invalid_proxy_api_key}"}
        )
        assert wrong_auth_response.status_code == 401
        print(f"–ù–µ–≤–µ—Ä–Ω—ã–π –∫–ª—é—á: {wrong_auth_response.status_code}")
        
        print("–®–∞–≥ 3: –ó–∞–ø—Ä–æ—Å —Å –≤–µ—Ä–Ω—ã–º –∫–ª—é—á–æ–º...")
        valid_auth_response = test_client.get(
            "/v1/models",
            headers={"Authorization": f"Bearer {valid_proxy_api_key}"}
        )
        assert valid_auth_response.status_code == 200
        print(f"–í–µ—Ä–Ω—ã–π –∫–ª—é—á: {valid_auth_response.status_code}")
    
    def test_openai_compatibility_format(self, test_client, valid_proxy_api_key):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Ñ–æ—Ä–º–∞—Ç–∞ –æ—Ç–≤–µ—Ç–æ–≤ —Å OpenAI API.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –æ—Ç–≤–µ—Ç—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ OpenAI.
        """
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ /v1/models...")
        models_response = test_client.get(
            "/v1/models",
            headers={"Authorization": f"Bearer {valid_proxy_api_key}"}
        )
        
        assert models_response.status_code == 200
        data = models_response.json()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –æ—Ç–≤–µ—Ç–∞ OpenAI
        assert "object" in data
        assert data["object"] == "list"
        assert "data" in data
        assert isinstance(data["data"], list)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
        for model in data["data"]:
            assert "id" in model
            assert "object" in model
            assert model["object"] == "model"
            assert "owned_by" in model
            assert "created" in model
        
        print(f"–§–æ—Ä–º–∞—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç OpenAI API: {len(data['data'])} –º–æ–¥–µ–ª–µ–π")


class TestRequestValidationFlow:
    """Integration-—Ç–µ—Å—Ç—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤."""
    
    def test_chat_completions_request_validation(self, test_client, valid_proxy_api_key):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–∞—Ü–∏—é —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤–∞–ª–∏–¥–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.
        """
        print("–¢–µ—Å—Ç 1: –ü—É—Å—Ç—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è...")
        empty_messages = test_client.post(
            "/v1/chat/completions",
            headers={"Authorization": f"Bearer {valid_proxy_api_key}"},
            json={"model": "claude-sonnet-4-5", "messages": []}
        )
        assert empty_messages.status_code == 422
        print(f"–ü—É—Å—Ç—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è: {empty_messages.status_code}")
        
        print("–¢–µ—Å—Ç 2: –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç model...")
        no_model = test_client.post(
            "/v1/chat/completions",
            headers={"Authorization": f"Bearer {valid_proxy_api_key}"},
            json={"messages": [{"role": "user", "content": "Hello"}]}
        )
        assert no_model.status_code == 422
        print(f"–ë–µ–∑ model: {no_model.status_code}")
        
        print("–¢–µ—Å—Ç 3: –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç messages...")
        no_messages = test_client.post(
            "/v1/chat/completions",
            headers={"Authorization": f"Bearer {valid_proxy_api_key}"},
            json={"model": "claude-sonnet-4-5"}
        )
        assert no_messages.status_code == 422
        print(f"–ë–µ–∑ messages: {no_messages.status_code}")
        
        print("–¢–µ—Å—Ç 4: –í–∞–ª–∏–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å...")
        valid_request = test_client.post(
            "/v1/chat/completions",
            headers={"Authorization": f"Bearer {valid_proxy_api_key}"},
            json={
                "model": "claude-sonnet-4-5",
                "messages": [{"role": "user", "content": "Hello"}]
            }
        )
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –ø—Ä–æ–π—Ç–∏ (–Ω–µ 422)
        assert valid_request.status_code != 422
        print(f"–í–∞–ª–∏–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å: {valid_request.status_code}")
    
    def test_complex_message_formats(self, test_client, valid_proxy_api_key):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É —Å–ª–æ–∂–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ —Å–æ–æ–±—â–µ–Ω–∏–π.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ multimodal –∏ tool —Ñ–æ—Ä–º–∞—Ç—ã –ø—Ä–∏–Ω–∏–º–∞—é—Ç—Å—è.
        """
        print("–¢–µ—Å—Ç 1: System + User —Å–æ–æ–±—â–µ–Ω–∏—è...")
        system_user = test_client.post(
            "/v1/chat/completions",
            headers={"Authorization": f"Bearer {valid_proxy_api_key}"},
            json={
                "model": "claude-sonnet-4-5",
                "messages": [
                    {"role": "system", "content": "You are helpful"},
                    {"role": "user", "content": "Hello"}
                ]
            }
        )
        assert system_user.status_code != 422
        print(f"System + User: {system_user.status_code}")
        
        print("–¢–µ—Å—Ç 2: Multi-turn conversation...")
        multi_turn = test_client.post(
            "/v1/chat/completions",
            headers={"Authorization": f"Bearer {valid_proxy_api_key}"},
            json={
                "model": "claude-sonnet-4-5",
                "messages": [
                    {"role": "user", "content": "Hello"},
                    {"role": "assistant", "content": "Hi there!"},
                    {"role": "user", "content": "How are you?"}
                ]
            }
        )
        assert multi_turn.status_code != 422
        print(f"Multi-turn: {multi_turn.status_code}")
        
        print("–¢–µ—Å—Ç 3: –° tools...")
        with_tools = test_client.post(
            "/v1/chat/completions",
            headers={"Authorization": f"Bearer {valid_proxy_api_key}"},
            json={
                "model": "claude-sonnet-4-5",
                "messages": [{"role": "user", "content": "What's the weather?"}],
                "tools": [{
                    "type": "function",
                    "function": {
                        "name": "get_weather",
                        "description": "Get weather",
                        "parameters": {"type": "object", "properties": {}}
                    }
                }]
            }
        )
        assert with_tools.status_code != 422
        print(f"–° tools: {with_tools.status_code}")


class TestErrorHandlingFlow:
    """Integration-—Ç–µ—Å—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫."""
    
    def test_invalid_json_handling(self, test_client, valid_proxy_api_key):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –Ω–µ–≤–∞–ª–∏–¥–Ω–æ–≥–æ JSON.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–Ω—è—Ç–Ω—É—é –æ—à–∏–±–∫—É.
        """
        print("–û—Ç–ø—Ä–∞–≤–∫–∞ –Ω–µ–≤–∞–ª–∏–¥–Ω–æ–≥–æ JSON...")
        response = test_client.post(
            "/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {valid_proxy_api_key}",
                "Content-Type": "application/json"
            },
            content=b"not valid json"
        )
        
        assert response.status_code == 422
        print(f"–ù–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON: {response.status_code}")
    
    def test_wrong_content_type_handling(self, test_client, valid_proxy_api_key):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –Ω–µ–≤–µ—Ä–Ω–æ–≥–æ Content-Type.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –Ω–µ–≤–µ—Ä–Ω—ã–π Content-Type –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è.
        """
        print("–û—Ç–ø—Ä–∞–≤–∫–∞ —Å –Ω–µ–≤–µ—Ä–Ω—ã–º Content-Type...")
        response = test_client.post(
            "/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {valid_proxy_api_key}",
                "Content-Type": "text/plain"
            },
            content=b"Hello"
        )
        
        # –î–æ–ª–∂–Ω–∞ –±—ã—Ç—å –æ—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        assert response.status_code == 422
        print(f"–ù–µ–≤–µ—Ä–Ω—ã–π Content-Type: {response.status_code}")


class TestModelsEndpointIntegration:
    """Integration-—Ç–µ—Å—Ç—ã —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞ /v1/models."""
    
    def test_models_returns_all_available_models(self, test_client, valid_proxy_api_key):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –≤—Å–µ –º–æ–¥–µ–ª–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç—Å—è.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è –≤ –ø–æ–ª–Ω–æ—Ç–µ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π.
        """
        print("–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π...")
        response = test_client.get(
            "/v1/models",
            headers={"Authorization": f"Bearer {valid_proxy_api_key}"}
        )
        
        assert response.status_code == 200
        
        returned_ids = {m["id"] for m in response.json()["data"]}
        expected_ids = set(AVAILABLE_MODELS)
        
        print(f"–í–æ–∑–≤—Ä–∞—â—ë–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏: {returned_ids}")
        print(f"–û–∂–∏–¥–∞–µ–º—ã–µ –º–æ–¥–µ–ª–∏: {expected_ids}")
        
        assert returned_ids == expected_ids
    
    def test_models_caching_behavior(self, test_client, valid_proxy_api_key):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–≤–µ–¥–µ–Ω–∏–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã —Ä–∞–±–æ—Ç–∞—é—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.
        """
        print("–ü–µ—Ä–≤—ã–π –∑–∞–ø—Ä–æ—Å –º–æ–¥–µ–ª–µ–π...")
        response1 = test_client.get(
            "/v1/models",
            headers={"Authorization": f"Bearer {valid_proxy_api_key}"}
        )
        assert response1.status_code == 200
        
        print("–í—Ç–æ—Ä–æ–π –∑–∞–ø—Ä–æ—Å –º–æ–¥–µ–ª–µ–π...")
        response2 = test_client.get(
            "/v1/models",
            headers={"Authorization": f"Bearer {valid_proxy_api_key}"}
        )
        assert response2.status_code == 200
        
        # –û—Ç–≤–µ—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∏–¥–µ–Ω—Ç–∏—á–Ω—ã
        assert response1.json()["data"] == response2.json()["data"]
        print("–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")


class TestStreamingFlagHandling:
    """Integration-—Ç–µ—Å—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–ª–∞–≥–∞ stream."""
    
    def test_stream_true_accepted(self, test_client, valid_proxy_api_key):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ stream=true –ø—Ä–∏–Ω–∏–º–∞–µ—Ç—Å—è.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ streaming —Ä–µ–∂–∏–º –¥–æ—Å—Ç—É–ø–µ–Ω.
        
        –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –î–ª—è streaming —Ä–µ–∂–∏–º–∞ –Ω—É–∂–µ–Ω –º–æ–∫ HTTP –∫–ª–∏–µ–Ω—Ç–∞,
        —Ç–∞–∫ –∫–∞–∫ –∑–∞–ø—Ä–æ—Å –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞.
        """
        print("–ó–∞–ø—Ä–æ—Å —Å stream=true...")
        
        # –°–æ–∑–¥–∞—ë–º –º–æ–∫ response –¥–ª—è streaming
        mock_response = AsyncMock()
        mock_response.status_code = 200
        
        async def mock_aiter_bytes():
            yield b'{"content":"Hello"}'
            yield b'{"usage":0.5}'
        
        mock_response.aiter_bytes = mock_aiter_bytes
        mock_response.aclose = AsyncMock()
        
        # –ú–æ–∫–∏—Ä—É–µ–º request_with_retry —á—Ç–æ–±—ã –≤–µ—Ä–Ω—É—Ç—å –Ω–∞—à –º–æ–∫ response
        with patch('kiro_gateway.routes.KiroHttpClient') as MockHttpClient:
            mock_client_instance = AsyncMock()
            mock_client_instance.request_with_retry = AsyncMock(return_value=mock_response)
            mock_client_instance.client = AsyncMock()
            mock_client_instance.close = AsyncMock()
            MockHttpClient.return_value = mock_client_instance
            
            response = test_client.post(
                "/v1/chat/completions",
                headers={"Authorization": f"Bearer {valid_proxy_api_key}"},
                json={
                    "model": "claude-sonnet-4-5",
                    "messages": [{"role": "user", "content": "Hello"}],
                    "stream": True
                }
            )
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –ø—Ä–æ–π—Ç–∏ –∏ streaming –¥–æ–ª–∂–µ–Ω —Ä–∞–±–æ—Ç–∞—Ç—å
        assert response.status_code == 200
        print(f"stream=true: {response.status_code}")
    
    def test_stream_false_accepted(self, test_client, valid_proxy_api_key):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ stream=false –ø—Ä–∏–Ω–∏–º–∞–µ—Ç—Å—è.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ non-streaming —Ä–µ–∂–∏–º –¥–æ—Å—Ç—É–ø–µ–Ω.
        """
        print("–ó–∞–ø—Ä–æ—Å —Å stream=false...")
        response = test_client.post(
            "/v1/chat/completions",
            headers={"Authorization": f"Bearer {valid_proxy_api_key}"},
            json={
                "model": "claude-sonnet-4-5",
                "messages": [{"role": "user", "content": "Hello"}],
                "stream": False
            }
        )
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –ø—Ä–æ–π—Ç–∏
        assert response.status_code != 422
        print(f"stream=false: {response.status_code}")


class TestHealthEndpointIntegration:
    """Integration-—Ç–µ—Å—Ç—ã health endpoints."""
    
    def test_root_and_health_consistency(self, test_client):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å / –∏ /health.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –æ–±–∞ —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞ –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Å—Ç–∞—Ç—É—Å.
        """
        print("–ó–∞–ø—Ä–æ—Å –∫ /...")
        root_response = test_client.get("/")
        
        print("–ó–∞–ø—Ä–æ—Å –∫ /health...")
        health_response = test_client.get("/health")
        
        assert root_response.status_code == 200
        assert health_response.status_code == 200
        
        # –û–±–∞ –¥–æ–ª–∂–Ω—ã –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å "ok" —Å—Ç–∞—Ç—É—Å
        assert root_response.json()["status"] == "ok"
        assert health_response.json()["status"] == "healthy"
        
        # –í–µ—Ä—Å–∏–∏ –¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å
        assert root_response.json()["version"] == health_response.json()["version"]
        
        print("Health endpoints –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã")


================================================
FILE: tests/unit/test_auth_manager.py
================================================
# -*- coding: utf-8 -*-

"""
Unit-—Ç–µ—Å—Ç—ã –¥–ª—è KiroAuthManager.
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ª–æ–≥–∏–∫—É —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞–º–∏ Kiro –±–µ–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö —Å–µ—Ç–µ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤.
"""

import asyncio
import pytest
from datetime import datetime, timezone, timedelta
from unittest.mock import AsyncMock, Mock, patch
import httpx

from kiro_gateway.auth import KiroAuthManager
from kiro_gateway.config import TOKEN_REFRESH_THRESHOLD


class TestKiroAuthManagerInitialization:
    """–¢–µ—Å—Ç—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ KiroAuthManager."""
    
    def test_initialization_stores_credentials(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ credentials –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä–∞ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ –ø—Ä–∏–≤–∞—Ç–Ω—ã—Ö –ø–æ–ª—è—Ö.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ KiroAuthManager —Å —Ç–µ—Å—Ç–æ–≤—ã–º–∏ credentials...")
        manager = KiroAuthManager(
            refresh_token="test_refresh_123",
            profile_arn="arn:aws:codewhisperer:us-east-1:123456789:profile/test",
            region="us-east-1"
        )
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –í—Å–µ credentials —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ...")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º refresh_token: –û–∂–∏–¥–∞–ª–æ—Å—å 'test_refresh_123', –ü–æ–ª—É—á–µ–Ω–æ '{manager._refresh_token}'")
        assert manager._refresh_token == "test_refresh_123"
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º profile_arn: –û–∂–∏–¥–∞–ª–æ—Å—å 'arn:aws:...', –ü–æ–ª—É—á–µ–Ω–æ '{manager._profile_arn}'")
        assert manager._profile_arn == "arn:aws:codewhisperer:us-east-1:123456789:profile/test"
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º region: –û–∂–∏–¥–∞–ª–æ—Å—å 'us-east-1', –ü–æ–ª—É—á–µ–Ω–æ '{manager._region}'")
        assert manager._region == "us-east-1"
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –¢–æ–∫–µ–Ω –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ –ø—É—Å—Ç–æ–π...")
        assert manager._access_token is None
        assert manager._expires_at is None
    
    def test_initialization_sets_correct_urls_for_region(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ URL –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–≥–∏–æ–Ω–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ URL –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ —Ñ–æ—Ä–º–∏—Ä—É—é—Ç—Å—è —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ä–µ–≥–∏–æ–Ω–æ–º.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ KiroAuthManager —Å —Ä–µ–≥–∏–æ–Ω–æ–º eu-west-1...")
        manager = KiroAuthManager(
            refresh_token="test_token",
            region="eu-west-1"
        )
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: URL —Å–æ–¥–µ—Ä–∂–∞—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–µ–≥–∏–æ–Ω...")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º refresh_url: –û–∂–∏–¥–∞–ª–æ—Å—å 'eu-west-1' –≤ URL, –ü–æ–ª—É—á–µ–Ω–æ '{manager._refresh_url}'")
        assert "eu-west-1" in manager._refresh_url
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º api_host: –û–∂–∏–¥–∞–ª–æ—Å—å 'eu-west-1' –≤ URL, –ü–æ–ª—É—á–µ–Ω–æ '{manager._api_host}'")
        assert "eu-west-1" in manager._api_host
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º q_host: –û–∂–∏–¥–∞–ª–æ—Å—å 'eu-west-1' –≤ URL, –ü–æ–ª—É—á–µ–Ω–æ '{manager._q_host}'")
        assert "eu-west-1" in manager._q_host
    
    def test_initialization_generates_fingerprint(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ fingerprint.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ fingerprint –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –∏ –∏–º–µ–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ KiroAuthManager...")
        manager = KiroAuthManager(refresh_token="test_token")
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: Fingerprint —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω...")
        print(f"Fingerprint: {manager._fingerprint}")
        assert manager._fingerprint is not None
        assert len(manager._fingerprint) == 64  # SHA256 hex digest


class TestKiroAuthManagerCredentialsFile:
    """–¢–µ—Å—Ç—ã –∑–∞–≥—Ä—É–∑–∫–∏ credentials –∏–∑ —Ñ–∞–π–ª–∞."""
    
    def test_load_credentials_from_file(self, temp_creds_file):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∑–∞–≥—Ä—É–∑–∫—É credentials –∏–∑ JSON —Ñ–∞–π–ª–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —á–∏—Ç–∞—é—Ç—Å—è –∏–∑ —Ñ–∞–π–ª–∞.
        """
        print(f"–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ KiroAuthManager —Å —Ñ–∞–π–ª–æ–º credentials: {temp_creds_file}")
        manager = KiroAuthManager(creds_file=temp_creds_file)
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞...")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º access_token: –û–∂–∏–¥–∞–ª–æ—Å—å 'file_access_token', –ü–æ–ª—É—á–µ–Ω–æ '{manager._access_token}'")
        assert manager._access_token == "file_access_token"
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º refresh_token: –û–∂–∏–¥–∞–ª–æ—Å—å 'file_refresh_token', –ü–æ–ª—É—á–µ–Ω–æ '{manager._refresh_token}'")
        assert manager._refresh_token == "file_refresh_token"
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º region: –û–∂–∏–¥–∞–ª–æ—Å—å 'us-east-1', –ü–æ–ª—É—á–µ–Ω–æ '{manager._region}'")
        assert manager._region == "us-east-1"
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: expiresAt —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ...")
        assert manager._expires_at is not None
        assert manager._expires_at.year == 2099
    
    def test_load_credentials_file_not_found(self, tmp_path):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞ credentials.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–µ –ø–∞–¥–∞–µ—Ç –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ —Ñ–∞–π–ª–∞.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ KiroAuthManager —Å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º —Ñ–∞–π–ª–æ–º...")
        non_existent_file = str(tmp_path / "non_existent.json")
        
        manager = KiroAuthManager(
            refresh_token="fallback_token",
            creds_file=non_existent_file
        )
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è fallback refresh_token...")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º refresh_token: –û–∂–∏–¥–∞–ª–æ—Å—å 'fallback_token', –ü–æ–ª—É—á–µ–Ω–æ '{manager._refresh_token}'")
        assert manager._refresh_token == "fallback_token"


class TestKiroAuthManagerTokenExpiration:
    """–¢–µ—Å—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏—Å—Ç–µ—á–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞."""
    
    def test_is_token_expiring_soon_returns_true_when_no_expires_at(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –±–µ–∑ expires_at —Ç–æ–∫–µ–Ω —Å—á–∏—Ç–∞–µ—Ç—Å—è –∏—Å—Ç–µ–∫–∞—é—â–∏–º.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è –≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ–º –ø–æ–≤–µ–¥–µ–Ω–∏–∏ –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤—Ä–µ–º–µ–Ω–∏.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ KiroAuthManager –±–µ–∑ expires_at...")
        manager = KiroAuthManager(refresh_token="test_token")
        manager._expires_at = None
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: is_token_expiring_soon –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç True...")
        result = manager.is_token_expiring_soon()
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å True, –ü–æ–ª—É—á–µ–Ω–æ {result}")
        assert result is True
    
    def test_is_token_expiring_soon_returns_true_when_expired(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –∏—Å—Ç–µ–∫—à–∏–π —Ç–æ–∫–µ–Ω –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Ç–æ–∫–µ–Ω –≤ –ø—Ä–æ—à–ª–æ–º —Å—á–∏—Ç–∞–µ—Ç—Å—è –∏—Å—Ç–µ–∫–∞—é—â–∏–º.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ KiroAuthManager —Å –∏—Å—Ç–µ–∫—à–∏–º —Ç–æ–∫–µ–Ω–æ–º...")
        manager = KiroAuthManager(refresh_token="test_token")
        manager._expires_at = datetime.now(timezone.utc) - timedelta(hours=1)
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: is_token_expiring_soon –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –¥–ª—è –∏—Å—Ç–µ–∫—à–µ–≥–æ —Ç–æ–∫–µ–Ω–∞...")
        result = manager.is_token_expiring_soon()
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å True, –ü–æ–ª—É—á–µ–Ω–æ {result}")
        assert result is True
    
    def test_is_token_expiring_soon_returns_true_within_threshold(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ —Ç–æ–∫–µ–Ω –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö threshold —Å—á–∏—Ç–∞–µ—Ç—Å—è –∏—Å—Ç–µ–∫–∞—é—â–∏–º.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Ç–æ–∫–µ–Ω –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –∑–∞—Ä–∞–Ω–µ–µ (–∑–∞ 10 –º–∏–Ω—É—Ç –¥–æ –∏—Å—Ç–µ—á–µ–Ω–∏—è).
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ KiroAuthManager —Å —Ç–æ–∫–µ–Ω–æ–º, –∏—Å—Ç–µ–∫–∞—é—â–∏–º —á–µ—Ä–µ–∑ 5 –º–∏–Ω—É—Ç...")
        manager = KiroAuthManager(refresh_token="test_token")
        manager._expires_at = datetime.now(timezone.utc) + timedelta(minutes=5)
        
        print(f"TOKEN_REFRESH_THRESHOLD = {TOKEN_REFRESH_THRESHOLD} —Å–µ–∫—É–Ω–¥")
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: is_token_expiring_soon –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç True (5 –º–∏–Ω < 10 –º–∏–Ω threshold)...")
        result = manager.is_token_expiring_soon()
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å True, –ü–æ–ª—É—á–µ–Ω–æ {result}")
        assert result is True
    
    def test_is_token_expiring_soon_returns_false_when_valid(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –≤–∞–ª–∏–¥–Ω—ã–π —Ç–æ–∫–µ–Ω –Ω–µ —Å—á–∏—Ç–∞–µ—Ç—Å—è –∏—Å—Ç–µ–∫–∞—é—â–∏–º.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Ç–æ–∫–µ–Ω –¥–∞–ª–µ–∫–æ –≤ –±—É–¥—É—â–µ–º –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ KiroAuthManager —Å —Ç–æ–∫–µ–Ω–æ–º, –∏—Å—Ç–µ–∫–∞—é—â–∏–º —á–µ—Ä–µ–∑ 1 —á–∞—Å...")
        manager = KiroAuthManager(refresh_token="test_token")
        manager._expires_at = datetime.now(timezone.utc) + timedelta(hours=1)
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: is_token_expiring_soon –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç False...")
        result = manager.is_token_expiring_soon()
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å False, –ü–æ–ª—É—á–µ–Ω–æ {result}")
        assert result is False


class TestKiroAuthManagerTokenRefresh:
    """–¢–µ—Å—Ç—ã –º–µ—Ö–∞–Ω–∏–∑–º–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞."""
    
    @pytest.mark.asyncio
    async def test_refresh_token_successful(self, valid_kiro_token, mock_kiro_token_response):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –¢–µ—Å—Ç–∏—Ä—É–µ—Ç —É—Å–ø–µ—à–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞ —á–µ—Ä–µ–∑ Kiro API.
        –¶–µ–ª—å: –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –ø—Ä–∏ —É—Å–ø–µ—à–Ω–æ–º –æ—Ç–≤–µ—Ç–µ —Ç–æ–∫–µ–Ω –∏ –≤—Ä–µ–º—è –∏—Å—Ç–µ—á–µ–Ω–∏—è —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ KiroAuthManager...")
        manager = KiroAuthManager(
            refresh_token="test_refresh",
            region="us-east-1"
        )
        
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ú–æ–∫–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –æ—Ç Kiro...")
        mock_response = AsyncMock()
        mock_response.status_code = 200
        mock_response.json = Mock(return_value=mock_kiro_token_response())
        mock_response.raise_for_status = Mock()
        
        with patch('kiro_gateway.auth.httpx.AsyncClient') as mock_client_class:
            mock_client = AsyncMock()
            mock_client.post = AsyncMock(return_value=mock_response)
            mock_client.__aenter__ = AsyncMock(return_value=mock_client)
            mock_client.__aexit__ = AsyncMock(return_value=None)
            mock_client_class.return_value = mock_client
            
            print("–î–µ–π—Å—Ç–≤–∏–µ: –í—ã–∑–æ–≤ _refresh_token_request()...")
            await manager._refresh_token_request()
            
            print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –¢–æ–∫–µ–Ω —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ...")
            print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º access_token: –û–∂–∏–¥–∞–ª–æ—Å—å '{valid_kiro_token}', –ü–æ–ª—É—á–µ–Ω–æ '{manager._access_token}'")
            assert manager._access_token == valid_kiro_token
            
            print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –í—Ä–µ–º—è –∏—Å—Ç–µ—á–µ–Ω–∏—è —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ...")
            assert manager._expires_at is not None
            
            print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –ë—ã–ª —Å–¥–µ–ª–∞–Ω POST –∑–∞–ø—Ä–æ—Å...")
            mock_client.post.assert_called_once()
    
    @pytest.mark.asyncio
    async def test_refresh_token_updates_refresh_token(self, mock_kiro_token_response):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ refresh_token –∏–∑ –æ—Ç–≤–µ—Ç–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –Ω–æ–≤—ã–π refresh_token —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ KiroAuthManager...")
        manager = KiroAuthManager(refresh_token="old_refresh_token")
        
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ú–æ–∫–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ —Å –Ω–æ–≤—ã–º refresh_token...")
        mock_response = AsyncMock()
        mock_response.status_code = 200
        mock_response.json = Mock(return_value=mock_kiro_token_response())
        mock_response.raise_for_status = Mock()
        
        with patch('kiro_gateway.auth.httpx.AsyncClient') as mock_client_class:
            mock_client = AsyncMock()
            mock_client.post = AsyncMock(return_value=mock_response)
            mock_client.__aenter__ = AsyncMock(return_value=mock_client)
            mock_client.__aexit__ = AsyncMock(return_value=None)
            mock_client_class.return_value = mock_client
            
            print("–î–µ–π—Å—Ç–≤–∏–µ: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞...")
            await manager._refresh_token_request()
            
            print("–ü—Ä–æ–≤–µ—Ä–∫–∞: refresh_token –æ–±–Ω–æ–≤–ª–µ–Ω...")
            print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º refresh_token: –û–∂–∏–¥–∞–ª–æ—Å—å 'new_refresh_token_xyz', –ü–æ–ª—É—á–µ–Ω–æ '{manager._refresh_token}'")
            assert manager._refresh_token == "new_refresh_token_xyz"
    
    @pytest.mark.asyncio
    async def test_refresh_token_missing_access_token_raises(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—Ç–≤–µ—Ç–∞ –±–µ–∑ accessToken.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ—Ç—Å—è –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–º –æ—Ç–≤–µ—Ç–µ.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ KiroAuthManager...")
        manager = KiroAuthManager(refresh_token="test_refresh")
        
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ú–æ–∫–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –±–µ–∑ accessToken...")
        mock_response = AsyncMock()
        mock_response.status_code = 200
        mock_response.json = Mock(return_value={"expiresIn": 3600})  # –ù–µ—Ç accessToken!
        mock_response.raise_for_status = Mock()
        
        with patch('kiro_gateway.auth.httpx.AsyncClient') as mock_client_class:
            mock_client = AsyncMock()
            mock_client.post = AsyncMock(return_value=mock_response)
            mock_client.__aenter__ = AsyncMock(return_value=mock_client)
            mock_client.__aexit__ = AsyncMock(return_value=None)
            mock_client_class.return_value = mock_client
            
            print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ–ø—ã—Ç–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞...")
            with pytest.raises(ValueError) as exc_info:
                await manager._refresh_token_request()
            
            print(f"–ü—Ä–æ–≤–µ—Ä–∫–∞: –í—ã–±—Ä–æ—à–µ–Ω–æ ValueError —Å–æ–æ–±—â–µ–Ω–∏–µ–º: {exc_info.value}")
            assert "accessToken" in str(exc_info.value)
    
    @pytest.mark.asyncio
    async def test_refresh_token_no_refresh_token_raises(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è refresh_token.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ—Ç—Å—è –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –±–µ–∑ refresh_token.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ KiroAuthManager –±–µ–∑ refresh_token...")
        manager = KiroAuthManager()
        manager._refresh_token = None
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ–ø—ã—Ç–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞ –±–µ–∑ refresh_token...")
        with pytest.raises(ValueError) as exc_info:
            await manager._refresh_token_request()
        
        print(f"–ü—Ä–æ–≤–µ—Ä–∫–∞: –í—ã–±—Ä–æ—à–µ–Ω–æ ValueError: {exc_info.value}")
        assert "Refresh token" in str(exc_info.value)


class TestKiroAuthManagerGetAccessToken:
    """–¢–µ—Å—Ç—ã –ø—É–±–ª–∏—á–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞ get_access_token."""
    
    @pytest.mark.asyncio
    async def test_get_access_token_refreshes_when_expired(self, valid_kiro_token, mock_kiro_token_response):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏—Å—Ç–µ–∫—à–µ–≥–æ —Ç–æ–∫–µ–Ω–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —É—Å—Ç–∞—Ä–µ–≤—à–∏–π —Ç–æ–∫–µ–Ω –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –ø–µ—Ä–µ–¥ –≤–æ–∑–≤—Ä–∞—Ç–æ–º.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ KiroAuthManager —Å –∏—Å—Ç–µ–∫—à–∏–º —Ç–æ–∫–µ–Ω–æ–º...")
        manager = KiroAuthManager(refresh_token="test_refresh")
        manager._access_token = "old_expired_token"
        manager._expires_at = datetime.now(timezone.utc) - timedelta(hours=1)
        
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ú–æ–∫–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è...")
        mock_response = AsyncMock()
        mock_response.status_code = 200
        mock_response.json = Mock(return_value=mock_kiro_token_response())
        mock_response.raise_for_status = Mock()
        
        with patch('kiro_gateway.auth.httpx.AsyncClient') as mock_client_class:
            mock_client = AsyncMock()
            mock_client.post = AsyncMock(return_value=mock_response)
            mock_client.__aenter__ = AsyncMock(return_value=mock_client)
            mock_client.__aexit__ = AsyncMock(return_value=None)
            mock_client_class.return_value = mock_client
            
            print("–î–µ–π—Å—Ç–≤–∏–µ: –ó–∞–ø—Ä–æ—Å —Ç–æ–∫–µ–Ω–∞ —á–µ—Ä–µ–∑ get_access_token()...")
            token = await manager.get_access_token()
            
            print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –ü–æ–ª—É—á–µ–Ω –Ω–æ–≤—ã–π —Ç–æ–∫–µ–Ω, –∞ –Ω–µ –∏—Å—Ç–µ–∫—à–∏–π...")
            print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ç–æ–∫–µ–Ω: –û–∂–∏–¥–∞–ª–æ—Å—å '{valid_kiro_token}', –ü–æ–ª—É—á–µ–Ω–æ '{token}'")
            assert token == valid_kiro_token
            assert token != "old_expired_token"
            
            print("–ü—Ä–æ–≤–µ—Ä–∫–∞: _refresh_token_request –±—ã–ª –≤—ã–∑–≤–∞–Ω...")
            mock_client.post.assert_called_once()
    
    @pytest.mark.asyncio
    async def test_get_access_token_returns_valid_without_refresh(self, valid_kiro_token):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–æ–∑–≤—Ä–∞—Ç –≤–∞–ª–∏–¥–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞ –±–µ–∑ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –Ω–µ –¥–µ–ª–∞—é—Ç—Å—è –ª–∏—à–Ω–∏–µ –∑–∞–ø—Ä–æ—Å—ã, –µ—Å–ª–∏ —Ç–æ–∫–µ–Ω –≤–∞–ª–∏–¥–µ–Ω.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ KiroAuthManager —Å –≤–∞–ª–∏–¥–Ω—ã–º —Ç–æ–∫–µ–Ω–æ–º...")
        manager = KiroAuthManager(refresh_token="test_refresh")
        manager._access_token = valid_kiro_token
        manager._expires_at = datetime.now(timezone.utc) + timedelta(hours=1)
        
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ú–æ–∫–∏—Ä–æ–≤–∞–Ω–∏–µ httpx –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –≤—ã–∑–æ–≤–æ–≤...")
        with patch('kiro_gateway.auth.httpx.AsyncClient') as mock_client_class:
            mock_client = AsyncMock()
            mock_client.post = AsyncMock()
            mock_client_class.return_value = mock_client
            
            print("–î–µ–π—Å—Ç–≤–∏–µ: –ó–∞–ø—Ä–æ—Å –≤–∞–ª–∏–¥–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞...")
            token = await manager.get_access_token()
            
            print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –í–æ–∑–≤—Ä–∞—â–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ç–æ–∫–µ–Ω...")
            print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ç–æ–∫–µ–Ω: –û–∂–∏–¥–∞–ª–æ—Å—å '{valid_kiro_token}', –ü–æ–ª—É—á–µ–Ω–æ '{token}'")
            assert token == valid_kiro_token
            
            print("–ü—Ä–æ–≤–µ—Ä–∫–∞: _refresh_token –ù–ï –±—ã–ª –≤—ã–∑–≤–∞–Ω (–Ω–µ—Ç —Å–µ—Ç–µ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤)...")
            mock_client.post.assert_not_called()
    
    @pytest.mark.asyncio
    async def test_get_access_token_thread_safety(self, valid_kiro_token, mock_kiro_token_response):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ asyncio.Lock.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤—ã–∑–æ–≤—ã –Ω–µ –ø—Ä–∏–≤–æ–¥—è—Ç –∫ race condition.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ KiroAuthManager...")
        manager = KiroAuthManager(refresh_token="test_refresh")
        manager._access_token = None
        manager._expires_at = None
        
        refresh_call_count = 0
        
        async def mock_refresh():
            nonlocal refresh_call_count
            refresh_call_count += 1
            await asyncio.sleep(0.1)  # –ò–º–∏—Ç–∞—Ü–∏—è –∑–∞–¥–µ—Ä–∂–∫–∏
            manager._access_token = valid_kiro_token
            manager._expires_at = datetime.now(timezone.utc) + timedelta(hours=1)
        
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ü–∞—Ç—á–∏–Ω–≥ _refresh_token_request –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –≤—ã–∑–æ–≤–æ–≤...")
        with patch.object(manager, '_refresh_token_request', side_effect=mock_refresh):
            print("–î–µ–π—Å—Ç–≤–∏–µ: 5 –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤—ã–∑–æ–≤–æ–≤ get_access_token()...")
            tokens = await asyncio.gather(*[
                manager.get_access_token() for _ in range(5)
            ])
            
            print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –í—Å–µ –≤—ã–∑–æ–≤—ã –ø–æ–ª—É—á–∏–ª–∏ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Ç–æ–∫–µ–Ω...")
            assert all(token == valid_kiro_token for token in tokens)
            
            print(f"–ü—Ä–æ–≤–µ—Ä–∫–∞: _refresh_token –≤—ã–∑–≤–∞–Ω –¢–û–õ–¨–ö–û –û–î–ò–ù –†–ê–ó (–±–ª–∞–≥–æ–¥–∞—Ä—è lock)...")
            print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã–∑–æ–≤–æ–≤: –û–∂–∏–¥–∞–ª–æ—Å—å 1, –ü–æ–ª—É—á–µ–Ω–æ {refresh_call_count}")
            assert refresh_call_count == 1


class TestKiroAuthManagerForceRefresh:
    """–¢–µ—Å—Ç—ã –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞."""
    
    @pytest.mark.asyncio
    async def test_force_refresh_updates_token(self, valid_kiro_token, mock_kiro_token_response):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ force_refresh –≤—Å–µ–≥–¥–∞ –æ–±–Ω–æ–≤–ª—è–µ—Ç —Ç–æ–∫–µ–Ω.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ KiroAuthManager —Å –≤–∞–ª–∏–¥–Ω—ã–º —Ç–æ–∫–µ–Ω–æ–º...")
        manager = KiroAuthManager(refresh_token="test_refresh")
        manager._access_token = "old_but_valid_token"
        manager._expires_at = datetime.now(timezone.utc) + timedelta(hours=1)
        
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ú–æ–∫–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è...")
        mock_response = AsyncMock()
        mock_response.status_code = 200
        mock_response.json = Mock(return_value=mock_kiro_token_response())
        mock_response.raise_for_status = Mock()
        
        with patch('kiro_gateway.auth.httpx.AsyncClient') as mock_client_class:
            mock_client = AsyncMock()
            mock_client.post = AsyncMock(return_value=mock_response)
            mock_client.__aenter__ = AsyncMock(return_value=mock_client)
            mock_client.__aexit__ = AsyncMock(return_value=None)
            mock_client_class.return_value = mock_client
            
            print("–î–µ–π—Å—Ç–≤–∏–µ: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞...")
            token = await manager.force_refresh()
            
            print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –¢–æ–∫–µ–Ω –æ–±–Ω–æ–≤–ª–µ–Ω, –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å —Å—Ç–∞—Ä–æ–≥–æ...")
            print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ç–æ–∫–µ–Ω: –û–∂–∏–¥–∞–ª–æ—Å—å '{valid_kiro_token}', –ü–æ–ª—É—á–µ–Ω–æ '{token}'")
            assert token == valid_kiro_token
            
            print("–ü—Ä–æ–≤–µ—Ä–∫–∞: POST –∑–∞–ø—Ä–æ—Å –±—ã–ª —Å–¥–µ–ª–∞–Ω...")
            mock_client.post.assert_called_once()


class TestKiroAuthManagerProperties:
    """–¢–µ—Å—Ç—ã —Å–≤–æ–π—Å—Ç–≤ KiroAuthManager."""
    
    def test_profile_arn_property(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–≤–æ–π—Å—Ç–≤–æ profile_arn.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ profile_arn –¥–æ—Å—Ç—É–ø–µ–Ω —á–µ—Ä–µ–∑ property.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ KiroAuthManager —Å profile_arn...")
        manager = KiroAuthManager(
            refresh_token="test",
            profile_arn="arn:aws:test:profile"
        )
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: profile_arn –¥–æ—Å—Ç—É–ø–µ–Ω...")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º profile_arn: –û–∂–∏–¥–∞–ª–æ—Å—å 'arn:aws:test:profile', –ü–æ–ª—É—á–µ–Ω–æ '{manager.profile_arn}'")
        assert manager.profile_arn == "arn:aws:test:profile"
    
    def test_region_property(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–≤–æ–π—Å—Ç–≤–æ region.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ region –¥–æ—Å—Ç—É–ø–µ–Ω —á–µ—Ä–µ–∑ property.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ KiroAuthManager —Å region...")
        manager = KiroAuthManager(
            refresh_token="test",
            region="eu-west-1"
        )
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: region –¥–æ—Å—Ç—É–ø–µ–Ω...")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º region: –û–∂–∏–¥–∞–ª–æ—Å—å 'eu-west-1', –ü–æ–ª—É—á–µ–Ω–æ '{manager.region}'")
        assert manager.region == "eu-west-1"
    
    def test_api_host_property(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–≤–æ–π—Å—Ç–≤–æ api_host.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ api_host —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ KiroAuthManager...")
        manager = KiroAuthManager(
            refresh_token="test",
            region="us-east-1"
        )
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: api_host —Å–æ–¥–µ—Ä–∂–∏—Ç codewhisperer –∏ —Ä–µ–≥–∏–æ–Ω...")
        print(f"api_host: {manager.api_host}")
        assert "codewhisperer" in manager.api_host
        assert "us-east-1" in manager.api_host
    
    def test_fingerprint_property(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–≤–æ–π—Å—Ç–≤–æ fingerprint.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ fingerprint –¥–æ—Å—Ç—É–ø–µ–Ω —á–µ—Ä–µ–∑ property.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ KiroAuthManager...")
        manager = KiroAuthManager(refresh_token="test")
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: fingerprint –¥–æ—Å—Ç—É–ø–µ–Ω –∏ –∏–º–µ–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—É—é –¥–ª–∏–Ω—É...")
        print(f"fingerprint: {manager.fingerprint}")
        assert len(manager.fingerprint) == 64


================================================
FILE: tests/unit/test_cache.py
================================================
# -*- coding: utf-8 -*-

"""
Unit-—Ç–µ—Å—Ç—ã –¥–ª—è ModelInfoCache.
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ª–æ–≥–∏–∫—É –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.
"""

import asyncio
import time
import pytest

from kiro_gateway.cache import ModelInfoCache
from kiro_gateway.config import DEFAULT_MAX_INPUT_TOKENS


class TestModelInfoCacheInitialization:
    """–¢–µ—Å—Ç—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ ModelInfoCache."""
    
    def test_initialization_creates_empty_cache(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –∫—ç—à —Å–æ–∑–¥–∞—ë—Ç—Å—è –ø—É—Å—Ç—ã–º.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ ModelInfoCache...")
        cache = ModelInfoCache()
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –ö—ç—à –ø—É—Å—Ç –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏...")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º is_empty(): –û–∂–∏–¥–∞–ª–æ—Å—å True, –ü–æ–ª—É—á–µ–Ω–æ {cache.is_empty()}")
        assert cache.is_empty() is True
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º size: –û–∂–∏–¥–∞–ª–æ—Å—å 0, –ü–æ–ª—É—á–µ–Ω–æ {cache.size}")
        assert cache.size == 0
    
    def test_initialization_with_custom_ttl(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–∑–¥–∞–Ω–∏–µ –∫—ç—à–∞ —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º TTL.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ TTL –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ ModelInfoCache —Å TTL=7200...")
        cache = ModelInfoCache(cache_ttl=7200)
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: TTL —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ...")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º _cache_ttl: –û–∂–∏–¥–∞–ª–æ—Å—å 7200, –ü–æ–ª—É—á–µ–Ω–æ {cache._cache_ttl}")
        assert cache._cache_ttl == 7200
    
    def test_initialization_last_update_is_none(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ last_update_time –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ None.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤—Ä–µ–º—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –¥–æ –ø–µ—Ä–≤–æ–≥–æ update.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ ModelInfoCache...")
        cache = ModelInfoCache()
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: last_update_time –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ None...")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º last_update_time: –û–∂–∏–¥–∞–ª–æ—Å—å None, –ü–æ–ª—É—á–µ–Ω–æ {cache.last_update_time}")
        assert cache.last_update_time is None


class TestModelInfoCacheUpdate:
    """–¢–µ—Å—Ç—ã –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫—ç—à–∞."""
    
    @pytest.mark.asyncio
    async def test_update_populates_cache(self, sample_models_data):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –∫—ç—à–∞ –¥–∞–Ω–Ω—ã–º–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ update() –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–æ–¥–µ–ª–∏.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ ModelInfoCache...")
        cache = ModelInfoCache()
        
        print(f"–î–µ–π—Å—Ç–≤–∏–µ: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫—ç—à–∞ —Å {len(sample_models_data)} –º–æ–¥–µ–ª—è–º–∏...")
        await cache.update(sample_models_data)
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –ö—ç—à –∑–∞–ø–æ–ª–Ω–µ–Ω...")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º is_empty(): –û–∂–∏–¥–∞–ª–æ—Å—å False, –ü–æ–ª—É—á–µ–Ω–æ {cache.is_empty()}")
        assert cache.is_empty() is False
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º size: –û–∂–∏–¥–∞–ª–æ—Å—å {len(sample_models_data)}, –ü–æ–ª—É—á–µ–Ω–æ {cache.size}")
        assert cache.size == len(sample_models_data)
    
    @pytest.mark.asyncio
    async def test_update_sets_last_update_time(self, sample_models_data):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–∫—É –≤—Ä–µ–º–µ–Ω–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ last_update_time —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ update.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ ModelInfoCache...")
        cache = ModelInfoCache()
        
        before_update = time.time()
        print(f"–î–µ–π—Å—Ç–≤–∏–µ: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫—ç—à–∞ (–≤—Ä–µ–º—è –¥–æ: {before_update})...")
        await cache.update(sample_models_data)
        after_update = time.time()
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: last_update_time —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ —Ä–∞–∑—É–º–Ω—ã—Ö –ø—Ä–µ–¥–µ–ª–∞—Ö...")
        print(f"last_update_time: {cache.last_update_time}")
        assert cache.last_update_time is not None
        assert before_update <= cache.last_update_time <= after_update
    
    @pytest.mark.asyncio
    async def test_update_replaces_existing_data(self, sample_models_data):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∑–∞–º–µ–Ω—É –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–º update.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–º–µ–Ω—è—é—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ ModelInfoCache –∏ –ø–µ—Ä–≤–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ...")
        cache = ModelInfoCache()
        await cache.update(sample_models_data)
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å –Ω–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏...")
        new_data = [{"modelId": "new-model", "tokenLimits": {"maxInputTokens": 50000}}]
        await cache.update(new_data)
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –°—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –∑–∞–º–µ–Ω–µ–Ω—ã...")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º size: –û–∂–∏–¥–∞–ª–æ—Å—å 1, –ü–æ–ª—É—á–µ–Ω–æ {cache.size}")
        assert cache.size == 1
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –°—Ç–∞—Ä–∞—è –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞...")
        assert cache.get("claude-sonnet-4") is None
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –ù–æ–≤–∞—è –º–æ–¥–µ–ª—å –¥–æ—Å—Ç—É–ø–Ω–∞...")
        assert cache.get("new-model") is not None
    
    @pytest.mark.asyncio
    async def test_update_with_empty_list(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—É—Å—Ç—ã–º —Å–ø–∏—Å–∫–æ–º.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –∫—ç—à –æ—á–∏—â–∞–µ—Ç—Å—è –ø—Ä–∏ –ø—É—Å—Ç–æ–º update.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ ModelInfoCache —Å –¥–∞–Ω–Ω—ã–º–∏...")
        cache = ModelInfoCache()
        await cache.update([{"modelId": "test-model"}])
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—É—Å—Ç—ã–º —Å–ø–∏—Å–∫–æ–º...")
        await cache.update([])
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –ö—ç—à –ø—É—Å—Ç...")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º is_empty(): –û–∂–∏–¥–∞–ª–æ—Å—å True, –ü–æ–ª—É—á–µ–Ω–æ {cache.is_empty()}")
        assert cache.is_empty() is True


class TestModelInfoCacheGet:
    """–¢–µ—Å—Ç—ã –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∫—ç—à–∞."""
    
    @pytest.mark.asyncio
    async def test_get_returns_model_info(self, sample_models_data):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ get() –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –∫—ç—à–∞...")
        cache = ModelInfoCache()
        await cache.update(sample_models_data)
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ claude-sonnet-4...")
        model_info = cache.get("claude-sonnet-4")
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∞...")
        print(f"model_info: {model_info}")
        assert model_info is not None
        assert model_info["modelId"] == "claude-sonnet-4"
    
    @pytest.mark.asyncio
    async def test_get_returns_none_for_unknown_model(self, sample_models_data):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–æ–∑–≤—Ä–∞—Ç None –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ get() –Ω–µ –ø–∞–¥–∞–µ—Ç –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –º–æ–¥–µ–ª–∏.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –∫—ç—à–∞...")
        cache = ModelInfoCache()
        await cache.update(sample_models_data)
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –º–æ–¥–µ–ª–∏...")
        model_info = cache.get("non-existent-model")
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –í–æ–∑–≤—Ä–∞—â—ë–Ω None...")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º model_info: –û–∂–∏–¥–∞–ª–æ—Å—å None, –ü–æ–ª—É—á–µ–Ω–æ {model_info}")
        assert model_info is None
    
    def test_get_from_empty_cache(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç get() –∏–∑ –ø—É—Å—Ç–æ–≥–æ –∫—ç—à–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø—É—Å—Ç–æ–π –∫—ç—à –Ω–µ –≤—ã–∑—ã–≤–∞–µ—Ç –æ—à–∏–±–æ–∫.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ –ø—É—Å—Ç–æ–≥–æ –∫—ç—à–∞...")
        cache = ModelInfoCache()
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–∑ –ø—É—Å—Ç–æ–≥–æ –∫—ç—à–∞...")
        model_info = cache.get("any-model")
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –í–æ–∑–≤—Ä–∞—â—ë–Ω None...")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º model_info: –û–∂–∏–¥–∞–ª–æ—Å—å None, –ü–æ–ª—É—á–µ–Ω–æ {model_info}")
        assert model_info is None


class TestModelInfoCacheGetMaxInputTokens:
    """–¢–µ—Å—Ç—ã –ø–æ–ª—É—á–µ–Ω–∏—è maxInputTokens."""
    
    @pytest.mark.asyncio
    async def test_get_max_input_tokens_returns_value(self, sample_models_data):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–ª—É—á–µ–Ω–∏–µ maxInputTokens –¥–ª—è –º–æ–¥–µ–ª–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑–≤–ª–µ–∫–∞–µ—Ç—Å—è –∏–∑ tokenLimits.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –∫—ç—à–∞...")
        cache = ModelInfoCache()
        await cache.update(sample_models_data)
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ–ª—É—á–µ–Ω–∏–µ maxInputTokens –¥–ª—è claude-sonnet-4...")
        max_tokens = cache.get_max_input_tokens("claude-sonnet-4")
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –ó–Ω–∞—á–µ–Ω–∏–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ...")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º max_tokens: –û–∂–∏–¥–∞–ª–æ—Å—å 200000, –ü–æ–ª—É—á–µ–Ω–æ {max_tokens}")
        assert max_tokens == 200000
    
    @pytest.mark.asyncio
    async def test_get_max_input_tokens_returns_default_for_unknown(self, sample_models_data):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–æ–∑–≤—Ä–∞—Ç –¥–µ—Ñ–æ–ª—Ç–∞ –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è DEFAULT_MAX_INPUT_TOKENS.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –∫—ç—à–∞...")
        cache = ModelInfoCache()
        await cache.update(sample_models_data)
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ–ª—É—á–µ–Ω–∏–µ maxInputTokens –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏...")
        max_tokens = cache.get_max_input_tokens("unknown-model")
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –í–æ–∑–≤—Ä–∞—â—ë–Ω –¥–µ—Ñ–æ–ª—Ç...")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º max_tokens: –û–∂–∏–¥–∞–ª–æ—Å—å {DEFAULT_MAX_INPUT_TOKENS}, –ü–æ–ª—É—á–µ–Ω–æ {max_tokens}")
        assert max_tokens == DEFAULT_MAX_INPUT_TOKENS
    
    @pytest.mark.asyncio
    async def test_get_max_input_tokens_returns_default_when_no_token_limits(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–æ–∑–≤—Ä–∞—Ç –¥–µ—Ñ–æ–ª—Ç–∞ –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ tokenLimits.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –º–æ–¥–µ–ª—å –±–µ–∑ tokenLimits –Ω–µ –ª–æ–º–∞–µ—Ç –ª–æ–≥–∏–∫—É.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ –∫—ç—à–∞ —Å –º–æ–¥–µ–ª—å—é –±–µ–∑ tokenLimits...")
        cache = ModelInfoCache()
        await cache.update([{"modelId": "model-without-limits"}])
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ–ª—É—á–µ–Ω–∏–µ maxInputTokens...")
        max_tokens = cache.get_max_input_tokens("model-without-limits")
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –í–æ–∑–≤—Ä–∞—â—ë–Ω –¥–µ—Ñ–æ–ª—Ç...")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º max_tokens: –û–∂–∏–¥–∞–ª–æ—Å—å {DEFAULT_MAX_INPUT_TOKENS}, –ü–æ–ª—É—á–µ–Ω–æ {max_tokens}")
        assert max_tokens == DEFAULT_MAX_INPUT_TOKENS
    
    @pytest.mark.asyncio
    async def test_get_max_input_tokens_returns_default_when_max_input_is_none(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–æ–∑–≤—Ä–∞—Ç –¥–µ—Ñ–æ–ª—Ç–∞ –ø—Ä–∏ maxInputTokens=None.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ None –≤ tokenLimits –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ –∫—ç—à–∞ —Å –º–æ–¥–µ–ª—å—é —Å maxInputTokens=None...")
        cache = ModelInfoCache()
        await cache.update([{
            "modelId": "model-with-null",
            "tokenLimits": {"maxInputTokens": None}
        }])
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ–ª—É—á–µ–Ω–∏–µ maxInputTokens...")
        max_tokens = cache.get_max_input_tokens("model-with-null")
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –í–æ–∑–≤—Ä–∞—â—ë–Ω –¥–µ—Ñ–æ–ª—Ç...")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º max_tokens: –û–∂–∏–¥–∞–ª–æ—Å—å {DEFAULT_MAX_INPUT_TOKENS}, –ü–æ–ª—É—á–µ–Ω–æ {max_tokens}")
        assert max_tokens == DEFAULT_MAX_INPUT_TOKENS


class TestModelInfoCacheIsEmpty:
    """–¢–µ—Å—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—É—Å—Ç–æ—Ç—ã –∫—ç—à–∞."""
    
    def test_is_empty_returns_true_for_new_cache(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç is_empty() –¥–ª—è –Ω–æ–≤–æ–≥–æ –∫—ç—à–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –Ω–æ–≤—ã–π –∫—ç—à —Å—á–∏—Ç–∞–µ—Ç—Å—è –ø—É—Å—Ç—ã–º.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –∫—ç—à–∞...")
        cache = ModelInfoCache()
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: is_empty() –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç True...")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º is_empty(): –û–∂–∏–¥–∞–ª–æ—Å—å True, –ü–æ–ª—É—á–µ–Ω–æ {cache.is_empty()}")
        assert cache.is_empty() is True
    
    @pytest.mark.asyncio
    async def test_is_empty_returns_false_after_update(self, sample_models_data):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç is_empty() –ø–æ—Å–ª–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–π –∫—ç—à –Ω–µ —Å—á–∏—Ç–∞–µ—Ç—Å—è –ø—É—Å—Ç—ã–º.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –∫—ç—à–∞...")
        cache = ModelInfoCache()
        await cache.update(sample_models_data)
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: is_empty() –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç False...")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º is_empty(): –û–∂–∏–¥–∞–ª–æ—Å—å False, –ü–æ–ª—É—á–µ–Ω–æ {cache.is_empty()}")
        assert cache.is_empty() is False


class TestModelInfoCacheIsStale:
    """–¢–µ—Å—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ —É—Å—Ç–∞—Ä–µ–≤–∞–Ω–∏—è –∫—ç—à–∞."""
    
    def test_is_stale_returns_true_for_new_cache(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç is_stale() –¥–ª—è –Ω–æ–≤–æ–≥–æ –∫—ç—à–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –∫—ç—à –±–µ–∑ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π —Å—á–∏—Ç–∞–µ—Ç—Å—è —É—Å—Ç–∞—Ä–µ–≤—à–∏–º.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –∫—ç—à–∞...")
        cache = ModelInfoCache()
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: is_stale() –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç True...")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º is_stale(): –û–∂–∏–¥–∞–ª–æ—Å—å True, –ü–æ–ª—É—á–µ–Ω–æ {cache.is_stale()}")
        assert cache.is_stale() is True
    
    @pytest.mark.asyncio
    async def test_is_stale_returns_false_after_recent_update(self, sample_models_data):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç is_stale() —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Å–≤–µ–∂–∏–π –∫—ç—à –Ω–µ —Å—á–∏—Ç–∞–µ—Ç—Å—è —É—Å—Ç–∞—Ä–µ–≤—à–∏–º.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –∫—ç—à–∞...")
        cache = ModelInfoCache()
        await cache.update(sample_models_data)
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: is_stale() –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç False...")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º is_stale(): –û–∂–∏–¥–∞–ª–æ—Å—å False, –ü–æ–ª—É—á–µ–Ω–æ {cache.is_stale()}")
        assert cache.is_stale() is False
    
    @pytest.mark.asyncio
    async def test_is_stale_returns_true_after_ttl_expires(self, sample_models_data):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç is_stale() –ø–æ—Å–ª–µ –∏—Å—Ç–µ—á–µ–Ω–∏—è TTL.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –∫—ç—à —Å—á–∏—Ç–∞–µ—Ç—Å—è —É—Å—Ç–∞—Ä–µ–≤—à–∏–º –ø–æ—Å–ª–µ TTL.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ –∫—ç—à–∞ —Å TTL=0.1 —Å–µ–∫—É–Ω–¥—ã...")
        cache = ModelInfoCache(cache_ttl=0.1)
        await cache.update(sample_models_data)
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û–∂–∏–¥–∞–Ω–∏–µ –∏—Å—Ç–µ—á–µ–Ω–∏—è TTL...")
        await asyncio.sleep(0.2)
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: is_stale() –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç True...")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º is_stale(): –û–∂–∏–¥–∞–ª–æ—Å—å True, –ü–æ–ª—É—á–µ–Ω–æ {cache.is_stale()}")
        assert cache.is_stale() is True


class TestModelInfoCacheGetAllModelIds:
    """–¢–µ—Å—Ç—ã –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ ID –º–æ–¥–µ–ª–µ–π."""
    
    def test_get_all_model_ids_returns_empty_for_new_cache(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç get_all_model_ids() –¥–ª—è –ø—É—Å—Ç–æ–≥–æ –∫—ç—à–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ –ø—É—Å—Ç–æ–≥–æ –∫—ç—à–∞...")
        cache = ModelInfoCache()
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ ID –º–æ–¥–µ–ª–µ–π...")
        model_ids = cache.get_all_model_ids()
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –°–ø–∏—Å–æ–∫ –ø—É—Å—Ç...")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º model_ids: –û–∂–∏–¥–∞–ª–æ—Å—å [], –ü–æ–ª—É—á–µ–Ω–æ {model_ids}")
        assert model_ids == []
    
    @pytest.mark.asyncio
    async def test_get_all_model_ids_returns_all_ids(self, sample_models_data):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç get_all_model_ids() –¥–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ–≥–æ –∫—ç—à–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç—Å—è –≤—Å–µ ID –º–æ–¥–µ–ª–µ–π.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –∫—ç—à–∞...")
        cache = ModelInfoCache()
        await cache.update(sample_models_data)
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ ID –º–æ–¥–µ–ª–µ–π...")
        model_ids = cache.get_all_model_ids()
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –í—Å–µ ID –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç...")
        expected_ids = [m["modelId"] for m in sample_models_data]
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º model_ids: –û–∂–∏–¥–∞–ª–æ—Å—å {expected_ids}, –ü–æ–ª—É—á–µ–Ω–æ {model_ids}")
        assert set(model_ids) == set(expected_ids)


class TestModelInfoCacheThreadSafety:
    """–¢–µ—Å—Ç—ã –ø–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∫—ç—à–∞."""
    
    @pytest.mark.asyncio
    async def test_concurrent_updates_dont_corrupt_cache(self, sample_models_data):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –ø—Ä–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö update.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ asyncio.Lock –∑–∞—â–∏—â–∞–µ—Ç –æ—Ç race conditions.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ –∫—ç—à–∞...")
        cache = ModelInfoCache()
        
        async def update_with_data(data):
            await cache.update(data)
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: 10 –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π...")
        tasks = []
        for i in range(10):
            data = [{"modelId": f"model-{i}", "tokenLimits": {"maxInputTokens": 100000 + i}}]
            tasks.append(update_with_data(data))
        
        await asyncio.gather(*tasks)
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –ö—ç—à —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è...")
        # –ò–∑-–∑–∞ race condition, –º—ã –Ω–µ –∑–Ω–∞–µ–º –∫–∞–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –±—ã–ª–æ –ø–æ—Å–ª–µ–¥–Ω–∏–º,
        # –Ω–æ –∫—ç—à –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ä–æ–≤–Ω–æ –æ–¥–Ω—É –º–æ–¥–µ–ª—å
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º size: –û–∂–∏–¥–∞–ª–æ—Å—å 1, –ü–æ–ª—É—á–µ–Ω–æ {cache.size}")
        assert cache.size == 1
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –ö—ç—à –Ω–µ –ø–æ–≤—Ä–µ–∂–¥—ë–Ω...")
        model_ids = cache.get_all_model_ids()
        assert len(model_ids) == 1
        assert model_ids[0].startswith("model-")
    
    @pytest.mark.asyncio
    async def test_concurrent_reads_are_safe(self, sample_models_data):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö —á—Ç–µ–Ω–∏–π.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ get() –Ω–µ –≤—ã–∑—ã–≤–∞—é—Ç –ø—Ä–æ–±–ª–µ–º.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –∫—ç—à–∞...")
        cache = ModelInfoCache()
        await cache.update(sample_models_data)
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: 100 –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö —á—Ç–µ–Ω–∏–π...")
        async def read_model():
            return cache.get("claude-sonnet-4")
        
        results = await asyncio.gather(*[read_model() for _ in range(100)])
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –í—Å–µ —á—Ç–µ–Ω–∏—è –≤–µ—Ä–Ω—É–ª–∏ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç...")
        assert all(r is not None for r in results)
        assert all(r["modelId"] == "claude-sonnet-4" for r in results)


================================================
FILE: tests/unit/test_config.py
================================================
# -*- coding: utf-8 -*-

"""
Unit tests for the configuration module.
Verifies loading settings from environment variables.
"""

import pytest
import os
from unittest.mock import patch


class TestLogLevelConfig:
    """Tests for LOG_LEVEL configuration."""
    
    def test_default_log_level_is_info(self):
        """
        What it does: Verifies that LOG_LEVEL defaults to INFO.
        Purpose: Ensure that INFO is used when no environment variable is set.
        
        Note: This test verifies the config.py code logic, not the actual
        value from the .env file. We mock os.getenv to simulate
        the absence of the environment variable.
        """
        print("Setup: Mocking os.getenv for LOG_LEVEL...")
        
        # Create a mock that returns None for LOG_LEVEL (simulating missing variable)
        original_getenv = os.getenv
        
        def mock_getenv(key, default=None):
            if key == "LOG_LEVEL":
                print(f"os.getenv('{key}') -> None (mocked)")
                return default  # Return default, simulating missing variable
            return original_getenv(key, default)
        
        with patch.object(os, 'getenv', side_effect=mock_getenv):
            # Reload config module with mocked getenv
            import importlib
            import kiro_gateway.config as config_module
            importlib.reload(config_module)
            
            print(f"LOG_LEVEL: {config_module.LOG_LEVEL}")
            print(f"Comparing: Expected 'INFO', Got '{config_module.LOG_LEVEL}'")
            assert config_module.LOG_LEVEL == "INFO"
        
        # Restore module with real values
        import importlib
        import kiro_gateway.config as config_module
        importlib.reload(config_module)
    
    def test_log_level_from_environment(self):
        """
        What it does: Verifies loading LOG_LEVEL from environment variable.
        Purpose: Ensure that the value from environment is used.
        """
        print("Setup: Setting LOG_LEVEL=DEBUG...")
        
        with patch.dict(os.environ, {"LOG_LEVEL": "DEBUG"}):
            import importlib
            import kiro_gateway.config as config_module
            importlib.reload(config_module)
            
            print(f"LOG_LEVEL: {config_module.LOG_LEVEL}")
            print(f"Comparing: Expected 'DEBUG', Got '{config_module.LOG_LEVEL}'")
            assert config_module.LOG_LEVEL == "DEBUG"
    
    def test_log_level_uppercase_conversion(self):
        """
        What it does: Verifies LOG_LEVEL conversion to uppercase.
        Purpose: Ensure that lowercase value is converted to uppercase.
        """
        print("Setup: Setting LOG_LEVEL=warning (lowercase)...")
        
        with patch.dict(os.environ, {"LOG_LEVEL": "warning"}):
            import importlib
            import kiro_gateway.config as config_module
            importlib.reload(config_module)
            
            print(f"LOG_LEVEL: {config_module.LOG_LEVEL}")
            print(f"Comparing: Expected 'WARNING', Got '{config_module.LOG_LEVEL}'")
            assert config_module.LOG_LEVEL == "WARNING"
    
    def test_log_level_trace(self):
        """
        What it does: Verifies setting LOG_LEVEL=TRACE.
        Purpose: Ensure that TRACE level is supported.
        """
        print("Setup: Setting LOG_LEVEL=TRACE...")
        
        with patch.dict(os.environ, {"LOG_LEVEL": "TRACE"}):
            import importlib
            import kiro_gateway.config as config_module
            importlib.reload(config_module)
            
            print(f"LOG_LEVEL: {config_module.LOG_LEVEL}")
            assert config_module.LOG_LEVEL == "TRACE"
    
    def test_log_level_error(self):
        """
        What it does: Verifies setting LOG_LEVEL=ERROR.
        Purpose: Ensure that ERROR level is supported.
        """
        print("Setup: Setting LOG_LEVEL=ERROR...")
        
        with patch.dict(os.environ, {"LOG_LEVEL": "ERROR"}):
            import importlib
            import kiro_gateway.config as config_module
            importlib.reload(config_module)
            
            print(f"LOG_LEVEL: {config_module.LOG_LEVEL}")
            assert config_module.LOG_LEVEL == "ERROR"
    
    def test_log_level_critical(self):
        """
        What it does: Verifies setting LOG_LEVEL=CRITICAL.
        Purpose: Ensure that CRITICAL level is supported.
        """
        print("Setup: Setting LOG_LEVEL=CRITICAL...")
        
        with patch.dict(os.environ, {"LOG_LEVEL": "CRITICAL"}):
            import importlib
            import kiro_gateway.config as config_module
            importlib.reload(config_module)
            
            print(f"LOG_LEVEL: {config_module.LOG_LEVEL}")
            assert config_module.LOG_LEVEL == "CRITICAL"


class TestToolDescriptionMaxLengthConfig:
    """Tests for TOOL_DESCRIPTION_MAX_LENGTH configuration."""
    
    def test_default_tool_description_max_length(self):
        """
        What it does: Verifies the default value for TOOL_DESCRIPTION_MAX_LENGTH.
        Purpose: Ensure that 10000 is used by default.
        """
        print("Setup: Removing TOOL_DESCRIPTION_MAX_LENGTH from environment...")
        
        with patch.dict(os.environ, {}, clear=False):
            if "TOOL_DESCRIPTION_MAX_LENGTH" in os.environ:
                del os.environ["TOOL_DESCRIPTION_MAX_LENGTH"]
            
            import importlib
            import kiro_gateway.config as config_module
            importlib.reload(config_module)
            
            print(f"TOOL_DESCRIPTION_MAX_LENGTH: {config_module.TOOL_DESCRIPTION_MAX_LENGTH}")
            assert config_module.TOOL_DESCRIPTION_MAX_LENGTH == 10000
    
    def test_tool_description_max_length_from_environment(self):
        """
        What it does: Verifies loading TOOL_DESCRIPTION_MAX_LENGTH from environment.
        Purpose: Ensure that the value from environment is used.
        """
        print("Setup: Setting TOOL_DESCRIPTION_MAX_LENGTH=5000...")
        
        with patch.dict(os.environ, {"TOOL_DESCRIPTION_MAX_LENGTH": "5000"}):
            import importlib
            import kiro_gateway.config as config_module
            importlib.reload(config_module)
            
            print(f"TOOL_DESCRIPTION_MAX_LENGTH: {config_module.TOOL_DESCRIPTION_MAX_LENGTH}")
            assert config_module.TOOL_DESCRIPTION_MAX_LENGTH == 5000
    
    def test_tool_description_max_length_zero_disables(self):
        """
        What it does: Verifies that 0 disables the feature.
        Purpose: Ensure that TOOL_DESCRIPTION_MAX_LENGTH=0 works.
        """
        print("Setup: Setting TOOL_DESCRIPTION_MAX_LENGTH=0...")
        
        with patch.dict(os.environ, {"TOOL_DESCRIPTION_MAX_LENGTH": "0"}):
            import importlib
            import kiro_gateway.config as config_module
            importlib.reload(config_module)
            
            print(f"TOOL_DESCRIPTION_MAX_LENGTH: {config_module.TOOL_DESCRIPTION_MAX_LENGTH}")
            assert config_module.TOOL_DESCRIPTION_MAX_LENGTH == 0


class TestTimeoutConfigurationWarning:
    """Tests for _warn_timeout_configuration() function."""
    
    def test_no_warning_when_first_token_less_than_streaming(self, capsys):
        """
        What it does: Verifies that warning is NOT shown with correct configuration.
        Purpose: Ensure that no warning when FIRST_TOKEN_TIMEOUT < STREAMING_READ_TIMEOUT.
        """
        print("Setup: FIRST_TOKEN_TIMEOUT=15, STREAMING_READ_TIMEOUT=300...")
        
        with patch.dict(os.environ, {
            "FIRST_TOKEN_TIMEOUT": "15",
            "STREAMING_READ_TIMEOUT": "300"
        }):
            import importlib
            import kiro_gateway.config as config_module
            importlib.reload(config_module)
            
            # Call the warning function
            config_module._warn_timeout_configuration()
            
            captured = capsys.readouterr()
            print(f"Captured stderr: {captured.err}")
            
            # Warning should NOT be shown
            assert "WARNING" not in captured.err
            assert "Suboptimal timeout configuration" not in captured.err
    
    def test_warning_when_first_token_equals_streaming(self, capsys):
        """
        What it does: Verifies that warning is shown when timeouts are equal.
        Purpose: Ensure that warning when FIRST_TOKEN_TIMEOUT == STREAMING_READ_TIMEOUT.
        """
        print("Setup: FIRST_TOKEN_TIMEOUT=300, STREAMING_READ_TIMEOUT=300...")
        
        with patch.dict(os.environ, {
            "FIRST_TOKEN_TIMEOUT": "300",
            "STREAMING_READ_TIMEOUT": "300"
        }):
            import importlib
            import kiro_gateway.config as config_module
            importlib.reload(config_module)
            
            # Call the warning function
            config_module._warn_timeout_configuration()
            
            captured = capsys.readouterr()
            print(f"Captured stderr: {captured.err}")
            
            # Warning SHOULD be shown
            assert "WARNING" in captured.err or "Suboptimal timeout configuration" in captured.err
    
    def test_warning_when_first_token_greater_than_streaming(self, capsys):
        """
        What it does: Verifies that warning is shown when FIRST_TOKEN > STREAMING.
        Purpose: Ensure that warning when FIRST_TOKEN_TIMEOUT > STREAMING_READ_TIMEOUT.
        """
        print("Setup: FIRST_TOKEN_TIMEOUT=500, STREAMING_READ_TIMEOUT=300...")
        
        with patch.dict(os.environ, {
            "FIRST_TOKEN_TIMEOUT": "500",
            "STREAMING_READ_TIMEOUT": "300"
        }):
            import importlib
            import kiro_gateway.config as config_module
            importlib.reload(config_module)
            
            # Call the warning function
            config_module._warn_timeout_configuration()
            
            captured = capsys.readouterr()
            print(f"Captured stderr: {captured.err}")
            
            # Warning SHOULD be shown
            assert "WARNING" in captured.err or "Suboptimal timeout configuration" in captured.err
            # Verify that timeout values are mentioned in warning
            assert "500" in captured.err
            assert "300" in captured.err
    
    def test_warning_contains_recommendation(self, capsys):
        """
        What it does: Verifies that warning contains a recommendation.
        Purpose: Ensure that user receives useful information.
        """
        print("Setup: FIRST_TOKEN_TIMEOUT=400, STREAMING_READ_TIMEOUT=300...")
        
        with patch.dict(os.environ, {
            "FIRST_TOKEN_TIMEOUT": "400",
            "STREAMING_READ_TIMEOUT": "300"
        }):
            import importlib
            import kiro_gateway.config as config_module
            importlib.reload(config_module)
            
            # Call the warning function
            config_module._warn_timeout_configuration()
            
            captured = capsys.readouterr()
            print(f"Captured stderr: {captured.err}")
            
            # Warning should contain recommendation
            assert "Recommendation" in captured.err or "LESS than" in captured.err


================================================
FILE: tests/unit/test_converters.py
================================================
# -*- coding: utf-8 -*-

"""
Unit-—Ç–µ—Å—Ç—ã –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–æ–≤ OpenAI <-> Kiro.
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ª–æ–≥–∏–∫—É –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ñ–æ—Ä–º–∞—Ç–æ–≤ —Å–æ–æ–±—â–µ–Ω–∏–π –∏ payload.
"""

import pytest

from unittest.mock import patch

from kiro_gateway.converters import (
    extract_text_content,
    merge_adjacent_messages,
    build_kiro_history,
    build_kiro_payload,
    process_tools_with_long_descriptions,
    _extract_tool_results,
    _extract_tool_uses,
    _build_user_input_context,
    _sanitize_json_schema
)
from kiro_gateway.models import ChatMessage, ChatCompletionRequest, Tool, ToolFunction


class TestExtractTextContent:
    """–¢–µ—Å—Ç—ã —Ñ—É–Ω–∫—Ü–∏–∏ extract_text_content."""
    
    def test_extracts_from_string(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Å—Ç—Ä–æ–∫–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Å—Ç—Ä–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è –∫–∞–∫ –µ—Å—Ç—å.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ü—Ä–æ—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞...")
        content = "Hello, World!"
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞...")
        result = extract_text_content(content)
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å 'Hello, World!', –ü–æ–ª—É—á–µ–Ω–æ '{result}'")
        assert result == "Hello, World!"
    
    def test_extracts_from_none(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É None.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ None –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: None...")
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞...")
        result = extract_text_content(None)
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å '', –ü–æ–ª—É—á–µ–Ω–æ '{result}'")
        assert result == ""
    
    def test_extracts_from_list_with_text_type(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑ —Å–ø–∏—Å–∫–∞ —Å type=text.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ OpenAI multimodal —Ñ–æ—Ä–º–∞—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–ø–∏—Å–æ–∫ —Å type=text...")
        content = [
            {"type": "text", "text": "Hello"},
            {"type": "text", "text": " World"}
        ]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞...")
        result = extract_text_content(content)
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å 'Hello World', –ü–æ–ª—É—á–µ–Ω–æ '{result}'")
        assert result == "Hello World"
    
    def test_extracts_from_list_with_text_key(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑ —Å–ø–∏—Å–∫–∞ —Å –∫–ª—é—á–æ–º text.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–ø–∏—Å–æ–∫ —Å –∫–ª—é—á–æ–º text...")
        content = [{"text": "Hello"}, {"text": " World"}]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞...")
        result = extract_text_content(content)
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å 'Hello World', –ü–æ–ª—É—á–µ–Ω–æ '{result}'")
        assert result == "Hello World"
    
    def test_extracts_from_list_with_strings(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑ —Å–ø–∏—Å–∫–∞ —Å—Ç—Ä–æ–∫.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫...")
        content = ["Hello", " ", "World"]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞...")
        result = extract_text_content(content)
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å 'Hello World', –ü–æ–ª—É—á–µ–Ω–æ '{result}'")
        assert result == "Hello World"
    
    def test_extracts_from_mixed_list(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑ —Å–º–µ—à–∞–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –≤ –æ–¥–Ω–æ–º —Å–ø–∏—Å–∫–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–º–µ—à–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫...")
        content = [
            {"type": "text", "text": "Part1"},
            "Part2",
            {"text": "Part3"}
        ]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞...")
        result = extract_text_content(content)
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å 'Part1Part2Part3', –ü–æ–ª—É—á–µ–Ω–æ '{result}'")
        assert result == "Part1Part2Part3"
    
    def test_converts_other_types_to_string(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é –¥—Ä—É–≥–∏—Ö —Ç–∏–ø–æ–≤ –≤ —Å—Ç—Ä–æ–∫—É.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —á–∏—Å–ª–∞ –∏ –¥—Ä—É–≥–∏–µ —Ç–∏–ø—ã –ø—Ä–µ–æ–±—Ä–∞–∑—É—é—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ß–∏—Å–ª–æ...")
        content = 42
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞...")
        result = extract_text_content(content)
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å '42', –ü–æ–ª—É—á–µ–Ω–æ '{result}'")
        assert result == "42"
    
    def test_handles_empty_list(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –ø—É—Å—Ç–æ–≥–æ —Å–ø–∏—Å–∫–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫...")
        content = []
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞...")
        result = extract_text_content(content)
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å '', –ü–æ–ª—É—á–µ–Ω–æ '{result}'")
        assert result == ""


class TestMergeAdjacentMessages:
    """–¢–µ—Å—Ç—ã —Ñ—É–Ω–∫—Ü–∏–∏ merge_adjacent_messages."""
    
    def test_merges_adjacent_user_messages(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ—Å–µ–¥–Ω–∏—Ö user —Å–æ–æ–±—â–µ–Ω–∏–π.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏—è —Å –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π —Ä–æ–ª—å—é –æ–±—ä–µ–¥–∏–Ω—è—é—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –î–≤–∞ user —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–¥—Ä—è–¥...")
        messages = [
            ChatMessage(role="user", content="Hello"),
            ChatMessage(role="user", content="World")
        ]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π...")
        result = merge_adjacent_messages(messages)
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –¥–ª–∏–Ω—É: –û–∂–∏–¥–∞–ª–æ—Å—å 1, –ü–æ–ª—É—á–µ–Ω–æ {len(result)}")
        assert len(result) == 1
        assert "Hello" in result[0].content
        assert "World" in result[0].content
    
    def test_preserves_alternating_messages(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ—Ä–µ–¥—É—é—â–∏—Ö—Å—è —Å–æ–æ–±—â–µ–Ω–∏–π.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Ä–∞–∑–Ω—ã–µ —Ä–æ–ª–∏ –Ω–µ –æ–±—ä–µ–¥–∏–Ω—è—é—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ß–µ—Ä–µ–¥—É—é—â–∏–µ—Å—è —Å–æ–æ–±—â–µ–Ω–∏—è...")
        messages = [
            ChatMessage(role="user", content="Hello"),
            ChatMessage(role="assistant", content="Hi"),
            ChatMessage(role="user", content="How are you?")
        ]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π...")
        result = merge_adjacent_messages(messages)
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –¥–ª–∏–Ω—É: –û–∂–∏–¥–∞–ª–æ—Å—å 3, –ü–æ–ª—É—á–µ–Ω–æ {len(result)}")
        assert len(result) == 3
    
    def test_handles_empty_list(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –ø—É—Å—Ç–æ–≥–æ —Å–ø–∏—Å–∫–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –Ω–µ –≤—ã–∑—ã–≤–∞–µ—Ç –æ—à–∏–±–æ–∫.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫...")
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π...")
        result = merge_adjacent_messages([])
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å [], –ü–æ–ª—É—á–µ–Ω–æ {result}")
        assert result == []
    
    def test_handles_single_message(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –æ–¥–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –æ–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è –∫–∞–∫ –µ—Å—Ç—å.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –û–¥–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ...")
        messages = [ChatMessage(role="user", content="Hello")]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π...")
        result = merge_adjacent_messages(messages)
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –¥–ª–∏–Ω—É: –û–∂–∏–¥–∞–ª–æ—Å—å 1, –ü–æ–ª—É—á–µ–Ω–æ {len(result)}")
        assert len(result) == 1
        assert result[0].content == "Hello"
    
    def test_merges_multiple_adjacent_groups(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≥—Ä—É–ø–ø.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ –≥—Ä—É–ø–ø —Å–æ—Å–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –æ–±—ä–µ–¥–∏–Ω—è—é—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ù–µ—Å–∫–æ–ª—å–∫–æ –≥—Ä—É–ø–ø —Å–æ—Å–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π...")
        messages = [
            ChatMessage(role="user", content="A"),
            ChatMessage(role="user", content="B"),
            ChatMessage(role="assistant", content="C"),
            ChatMessage(role="assistant", content="D"),
            ChatMessage(role="user", content="E")
        ]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π...")
        result = merge_adjacent_messages(messages)
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –¥–ª–∏–Ω—É: –û–∂–∏–¥–∞–ª–æ—Å—å 3, –ü–æ–ª—É—á–µ–Ω–æ {len(result)}")
        assert len(result) == 3
        assert result[0].role == "user"
        assert result[1].role == "assistant"
        assert result[2].role == "user"
    
    def test_converts_tool_message_to_user_with_tool_result(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ tool message –≤ user message —Å tool_result.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ role="tool" –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç—Å—è –≤ user message —Å tool_results content.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Tool message...")
        messages = [
            ChatMessage(role="tool", content="Tool result text", tool_call_id="call_123")
        ]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π...")
        result = merge_adjacent_messages(messages)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –¥–ª–∏–Ω—É: –û–∂–∏–¥–∞–ª–æ—Å—å 1, –ü–æ–ª—É—á–µ–Ω–æ {len(result)}")
        assert len(result) == 1
        assert result[0].role == "user"
        
        print("–ü—Ä–æ–≤–µ—Ä—è–µ–º content —Å–æ–¥–µ—Ä–∂–∏—Ç tool_result...")
        assert isinstance(result[0].content, list)
        assert len(result[0].content) == 1
        assert result[0].content[0]["type"] == "tool_result"
        assert result[0].content[0]["tool_use_id"] == "call_123"
        assert result[0].content[0]["content"] == "Tool result text"
    
    def test_converts_multiple_tool_messages_to_single_user_message(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö tool messages –≤ –æ–¥–∏–Ω user message.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ tool results –æ–±—ä–µ–¥–∏–Ω—è—é—Ç—Å—è –≤ –æ–¥–∏–Ω user message.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ù–µ—Å–∫–æ–ª—å–∫–æ tool messages –ø–æ–¥—Ä—è–¥...")
        messages = [
            ChatMessage(role="tool", content="Result 1", tool_call_id="call_1"),
            ChatMessage(role="tool", content="Result 2", tool_call_id="call_2"),
            ChatMessage(role="tool", content="Result 3", tool_call_id="call_3")
        ]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π...")
        result = merge_adjacent_messages(messages)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –¥–ª–∏–Ω—É: –û–∂–∏–¥–∞–ª–æ—Å—å 1, –ü–æ–ª—É—á–µ–Ω–æ {len(result)}")
        assert len(result) == 1
        assert result[0].role == "user"
        
        print("–ü—Ä–æ–≤–µ—Ä—è–µ–º content —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ tool_results...")
        assert isinstance(result[0].content, list)
        assert len(result[0].content) == 3
        
        tool_use_ids = [item["tool_use_id"] for item in result[0].content]
        assert "call_1" in tool_use_ids
        assert "call_2" in tool_use_ids
        assert "call_3" in tool_use_ids
    
    def test_tool_message_followed_by_user_message(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç tool message –ø–µ—Ä–µ–¥ user message.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ tool results –∏ user message –æ–±—ä–µ–¥–∏–Ω—è—é—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Tool message + user message...")
        messages = [
            ChatMessage(role="tool", content="Tool result", tool_call_id="call_1"),
            ChatMessage(role="user", content="Continue please")
        ]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π...")
        result = merge_adjacent_messages(messages)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –¥–ª–∏–Ω—É: –û–∂–∏–¥–∞–ª–æ—Å—å 1, –ü–æ–ª—É—á–µ–Ω–æ {len(result)}")
        # Tool message –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç—Å—è –≤ user, –∑–∞—Ç–µ–º –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç—Å—è —Å user
        assert len(result) == 1
        assert result[0].role == "user"
    
    def test_assistant_tool_user_sequence(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å assistant -> tool -> user.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ tool message –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –≤—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –º–µ–∂–¥—É assistant –∏ user.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: assistant -> tool -> user...")
        messages = [
            ChatMessage(role="assistant", content="I'll call a tool"),
            ChatMessage(role="tool", content="Tool output", tool_call_id="call_abc"),
            ChatMessage(role="user", content="Thanks!")
        ]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π...")
        result = merge_adjacent_messages(messages)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        # assistant –æ—Å—Ç–∞—ë—Ç—Å—è, tool+user –æ–±—ä–µ–¥–∏–Ω—è—é—Ç—Å—è –≤ –æ–¥–∏–Ω user
        assert len(result) == 2
        assert result[0].role == "assistant"
        assert result[1].role == "user"
    
    def test_tool_message_with_empty_content(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç tool message —Å –ø—É—Å—Ç—ã–º content.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∑–∞–º–µ–Ω—è–µ—Ç—Å—è –Ω–∞ "(empty result)".
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Tool message —Å –ø—É—Å—Ç—ã–º content...")
        messages = [
            ChatMessage(role="tool", content="", tool_call_id="call_empty")
        ]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π...")
        result = merge_adjacent_messages(messages)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        assert len(result) == 1
        assert result[0].content[0]["content"] == "(empty result)"
    
    def test_tool_message_with_none_tool_call_id(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç tool message –±–µ–∑ tool_call_id.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–π tool_call_id –∑–∞–º–µ–Ω—è–µ—Ç—Å—è –Ω–∞ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Tool message –±–µ–∑ tool_call_id...")
        messages = [
            ChatMessage(role="tool", content="Result", tool_call_id=None)
        ]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π...")
        result = merge_adjacent_messages(messages)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        assert len(result) == 1
        assert result[0].content[0]["tool_use_id"] == ""
    
    def test_merges_list_contents_correctly(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ list contents.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Å–ø–∏—Å–∫–∏ –æ–±—ä–µ–¥–∏–Ω—è—é—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –î–≤–∞ user —Å–æ–æ–±—â–µ–Ω–∏—è —Å list content...")
        messages = [
            ChatMessage(role="user", content=[{"type": "text", "text": "Part 1"}]),
            ChatMessage(role="user", content=[{"type": "text", "text": "Part 2"}])
        ]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π...")
        result = merge_adjacent_messages(messages)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        assert len(result) == 1
        assert isinstance(result[0].content, list)
        assert len(result[0].content) == 2
    
    def test_merges_adjacent_assistant_tool_calls(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ tool_calls –ø—Ä–∏ merge —Å–æ—Å–µ–¥–Ω–∏—Ö assistant —Å–æ–æ–±—â–µ–Ω–∏–π.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ tool_calls –∏–∑ –≤—Å–µ—Ö assistant —Å–æ–æ–±—â–µ–Ω–∏–π —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏.
        
        –≠—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ—Å—Ç –¥–ª—è –±–∞–≥–∞, –∫–æ–≥–¥–∞ Codex CLI –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ assistant
        —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ–¥—Ä—è–¥, –∫–∞–∂–¥–æ–µ —Å–æ —Å–≤–æ–∏–º tool_call. –ë–µ–∑ —ç—Ç–æ–≥–æ —Ñ–∏–∫—Å–∞ –≤—Ç–æ—Ä–æ–π tool_call
        —Ç–µ—Ä—è–ª—Å—è, —á—Ç–æ –ø—Ä–∏–≤–æ–¥–∏–ª–æ –∫ –æ—à–∏–±–∫–µ 400 –æ—Ç Kiro API (toolResult –±–µ–∑ toolUse).
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –î–≤–∞ assistant —Å–æ–æ–±—â–µ–Ω–∏—è —Å —Ä–∞–∑–Ω—ã–º–∏ tool_calls...")
        messages = [
            ChatMessage(
                role="assistant",
                content=None,
                tool_calls=[{
                    "id": "tooluse_first",
                    "type": "function",
                    "function": {
                        "name": "shell",
                        "arguments": '{"command": ["ls", "-la"]}'
                    }
                }]
            ),
            ChatMessage(
                role="assistant",
                content=None,
                tool_calls=[{
                    "id": "tooluse_second",
                    "type": "function",
                    "function": {
                        "name": "shell",
                        "arguments": '{"command": ["pwd"]}'
                    }
                }]
            )
        ]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π...")
        result = merge_adjacent_messages(messages)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –¥–ª–∏–Ω—É: –û–∂–∏–¥–∞–ª–æ—Å—å 1, –ü–æ–ª—É—á–µ–Ω–æ {len(result)}")
        assert len(result) == 1
        assert result[0].role == "assistant"
        
        print("–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ–±–∞ tool_calls —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã...")
        assert result[0].tool_calls is not None
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ tool_calls: –û–∂–∏–¥–∞–ª–æ—Å—å 2, –ü–æ–ª—É—á–µ–Ω–æ {len(result[0].tool_calls)}")
        assert len(result[0].tool_calls) == 2
        
        tool_ids = [tc["id"] for tc in result[0].tool_calls]
        print(f"Tool IDs: {tool_ids}")
        assert "tooluse_first" in tool_ids
        assert "tooluse_second" in tool_ids
    
    def test_merges_three_adjacent_assistant_tool_calls(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ tool_calls –∏–∑ —Ç—Ä—ë—Ö assistant —Å–æ–æ–±—â–µ–Ω–∏–π.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤—Å–µ tool_calls —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏ –±–æ–ª–µ–µ –¥–≤—É—Ö —Å–æ–æ–±—â–µ–Ω–∏–π.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –¢—Ä–∏ assistant —Å–æ–æ–±—â–µ–Ω–∏—è —Å tool_calls...")
        messages = [
            ChatMessage(
                role="assistant",
                content="",
                tool_calls=[{"id": "call_1", "type": "function", "function": {"name": "tool1", "arguments": "{}"}}]
            ),
            ChatMessage(
                role="assistant",
                content="",
                tool_calls=[{"id": "call_2", "type": "function", "function": {"name": "tool2", "arguments": "{}"}}]
            ),
            ChatMessage(
                role="assistant",
                content="",
                tool_calls=[{"id": "call_3", "type": "function", "function": {"name": "tool3", "arguments": "{}"}}]
            )
        ]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π...")
        result = merge_adjacent_messages(messages)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        assert len(result) == 1
        assert len(result[0].tool_calls) == 3
        
        tool_ids = [tc["id"] for tc in result[0].tool_calls]
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º tool IDs: –û–∂–∏–¥–∞–ª–æ—Å—å ['call_1', 'call_2', 'call_3'], –ü–æ–ª—É—á–µ–Ω–æ {tool_ids}")
        assert tool_ids == ["call_1", "call_2", "call_3"]
    
    def test_merges_assistant_with_and_without_tool_calls(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ assistant —Å tool_calls –∏ –±–µ–∑.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ tool_calls –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Ç—Å—è –ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Assistant –±–µ–∑ tool_calls + assistant —Å tool_calls...")
        messages = [
            ChatMessage(role="assistant", content="Thinking...", tool_calls=None),
            ChatMessage(
                role="assistant",
                content="",
                tool_calls=[{"id": "call_1", "type": "function", "function": {"name": "tool1", "arguments": "{}"}}]
            )
        ]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π...")
        result = merge_adjacent_messages(messages)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        assert len(result) == 1
        assert result[0].tool_calls is not None
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ tool_calls: –û–∂–∏–¥–∞–ª–æ—Å—å 1, –ü–æ–ª—É—á–µ–Ω–æ {len(result[0].tool_calls)}")
        assert len(result[0].tool_calls) == 1
        assert result[0].tool_calls[0]["id"] == "call_1"


class TestBuildKiroHistory:
    """–¢–µ—Å—Ç—ã —Ñ—É–Ω–∫—Ü–∏–∏ build_kiro_history."""
    
    def test_builds_user_message(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ user —Å–æ–æ–±—â–µ–Ω–∏—è.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ user —Å–æ–æ–±—â–µ–Ω–∏–µ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç—Å—è –≤ userInputMessage.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: User —Å–æ–æ–±—â–µ–Ω–∏–µ...")
        messages = [ChatMessage(role="user", content="Hello")]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏...")
        result = build_kiro_history(messages, "claude-sonnet-4")
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        assert len(result) == 1
        assert "userInputMessage" in result[0]
        assert result[0]["userInputMessage"]["content"] == "Hello"
        assert result[0]["userInputMessage"]["modelId"] == "claude-sonnet-4"
    
    def test_builds_assistant_message(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ assistant —Å–æ–æ–±—â–µ–Ω–∏—è.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ assistant —Å–æ–æ–±—â–µ–Ω–∏–µ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç—Å—è –≤ assistantResponseMessage.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Assistant —Å–æ–æ–±—â–µ–Ω–∏–µ...")
        messages = [ChatMessage(role="assistant", content="Hi there")]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏...")
        result = build_kiro_history(messages, "claude-sonnet-4")
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        assert len(result) == 1
        assert "assistantResponseMessage" in result[0]
        assert result[0]["assistantResponseMessage"]["content"] == "Hi there"
    
    def test_ignores_system_messages(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ system —Å–æ–æ–±—â–µ–Ω–∏–π.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ system —Å–æ–æ–±—â–µ–Ω–∏—è –Ω–µ –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –≤ –∏—Å—Ç–æ—Ä–∏—é.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: System —Å–æ–æ–±—â–µ–Ω–∏–µ...")
        messages = [ChatMessage(role="system", content="You are helpful")]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏...")
        result = build_kiro_history(messages, "claude-sonnet-4")
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –¥–ª–∏–Ω—É: –û–∂–∏–¥–∞–ª–æ—Å—å 0, –ü–æ–ª—É—á–µ–Ω–æ {len(result)}")
        assert len(result) == 0
    
    def test_builds_conversation_history(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —á–µ—Ä–µ–¥–æ–≤–∞–Ω–∏–µ user/assistant —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ü–æ–ª–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞...")
        messages = [
            ChatMessage(role="user", content="Hello"),
            ChatMessage(role="assistant", content="Hi"),
            ChatMessage(role="user", content="How are you?")
        ]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏...")
        result = build_kiro_history(messages, "claude-sonnet-4")
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        assert len(result) == 3
        assert "userInputMessage" in result[0]
        assert "assistantResponseMessage" in result[1]
        assert "userInputMessage" in result[2]
    
    def test_handles_empty_list(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –ø—É—Å—Ç–æ–≥–æ —Å–ø–∏—Å–∫–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Å—Ç—É—é –∏—Å—Ç–æ—Ä–∏—é.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫...")
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏...")
        result = build_kiro_history([], "claude-sonnet-4")
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å [], –ü–æ–ª—É—á–µ–Ω–æ {result}")
        assert result == []


class TestExtractToolResults:
    """–¢–µ—Å—Ç—ã —Ñ—É–Ω–∫—Ü–∏–∏ _extract_tool_results."""
    
    def test_extracts_tool_results_from_list(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ tool results –∏–∑ —Å–ø–∏—Å–∫–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ tool_result —ç–ª–µ–º–µ–Ω—Ç—ã –∏–∑–≤–ª–µ–∫–∞—é—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–ø–∏—Å–æ–∫ —Å tool_result...")
        content = [
            {"type": "tool_result", "tool_use_id": "call_123", "content": "Result text"}
        ]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ tool results...")
        result = _extract_tool_results(content)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        assert len(result) == 1
        assert result[0]["toolUseId"] == "call_123"
        assert result[0]["status"] == "success"
    
    def test_returns_empty_for_string_content(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–æ–∑–≤—Ä–∞—Ç –ø—É—Å—Ç–æ–≥–æ —Å–ø–∏—Å–∫–∞ –¥–ª—è —Å—Ç—Ä–æ–∫–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Å—Ç—Ä–æ–∫–∞ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç tool results.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°—Ç—Ä–æ–∫–∞...")
        content = "Just a string"
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ tool results...")
        result = _extract_tool_results(content)
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å [], –ü–æ–ª—É—á–µ–Ω–æ {result}")
        assert result == []
    
    def test_returns_empty_for_list_without_tool_results(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–æ–∑–≤—Ä–∞—Ç –ø—É—Å—Ç–æ–≥–æ —Å–ø–∏—Å–∫–∞ –±–µ–∑ tool_result.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –æ–±—ã—á–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –Ω–µ –∏–∑–≤–ª–µ–∫–∞—é—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–ø–∏—Å–æ–∫ –±–µ–∑ tool_result...")
        content = [{"type": "text", "text": "Hello"}]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ tool results...")
        result = _extract_tool_results(content)
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å [], –ü–æ–ª—É—á–µ–Ω–æ {result}")
        assert result == []


class TestExtractToolUses:
    """–¢–µ—Å—Ç—ã —Ñ—É–Ω–∫—Ü–∏–∏ _extract_tool_uses."""
    
    def test_extracts_from_tool_calls_field(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑ –ø–æ–ª—è tool_calls.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ OpenAI tool_calls —Ñ–æ—Ä–º–∞—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–æ–±—â–µ–Ω–∏–µ —Å tool_calls...")
        msg = ChatMessage(
            role="assistant",
            content="",
            tool_calls=[{
                "id": "call_123",
                "function": {
                    "name": "get_weather",
                    "arguments": '{"location": "Moscow"}'
                }
            }]
        )
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ tool uses...")
        result = _extract_tool_uses(msg)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        assert len(result) == 1
        assert result[0]["name"] == "get_weather"
        assert result[0]["toolUseId"] == "call_123"
    
    def test_extracts_from_content_list(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–∑ content —Å–ø–∏—Å–∫–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ tool_use –≤ content –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–æ–±—â–µ–Ω–∏–µ —Å tool_use –≤ content...")
        msg = ChatMessage(
            role="assistant",
            content=[{
                "type": "tool_use",
                "id": "call_456",
                "name": "search",
                "input": {"query": "test"}
            }]
        )
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ tool uses...")
        result = _extract_tool_uses(msg)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        assert len(result) == 1
        assert result[0]["name"] == "search"
        assert result[0]["toolUseId"] == "call_456"
    
    def test_returns_empty_for_no_tool_uses(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–æ–∑–≤—Ä–∞—Ç –ø—É—Å—Ç–æ–≥–æ —Å–ø–∏—Å–∫–∞ –±–µ–∑ tool uses.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –æ–±—ã—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç tool uses.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –û–±—ã—á–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ...")
        msg = ChatMessage(role="assistant", content="Hello")
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ tool uses...")
        result = _extract_tool_uses(msg)
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å [], –ü–æ–ª—É—á–µ–Ω–æ {result}")
        assert result == []


class TestProcessToolsWithLongDescriptions:
    """–¢–µ—Å—Ç—ã —Ñ—É–Ω–∫—Ü–∏–∏ process_tools_with_long_descriptions."""
    
    def test_returns_none_and_empty_string_for_none_tools(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É None –≤–º–µ—Å—Ç–æ —Å–ø–∏—Å–∫–∞ tools.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ None –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç (None, "").
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: None –≤–º–µ—Å—Ç–æ tools...")
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û–±—Ä–∞–±–æ—Ç–∫–∞ tools...")
        processed, doc = process_tools_with_long_descriptions(None)
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å (None, ''), –ü–æ–ª—É—á–µ–Ω–æ ({processed}, '{doc}')")
        assert processed is None
        assert doc == ""
    
    def test_returns_none_and_empty_string_for_empty_list(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –ø—É—Å—Ç–æ–≥–æ —Å–ø–∏—Å–∫–∞ tools.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç (None, "").
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ tools...")
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û–±—Ä–∞–±–æ—Ç–∫–∞ tools...")
        processed, doc = process_tools_with_long_descriptions([])
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å (None, ''), –ü–æ–ª—É—á–µ–Ω–æ ({processed}, '{doc}')")
        assert processed is None
        assert doc == ""
    
    def test_short_description_unchanged(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –∫–æ—Ä–æ—Ç–∫–∏–µ descriptions –Ω–µ –∏–∑–º–µ–Ω—è—é—Ç—Å—è.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ tools —Å –∫–æ—Ä–æ—Ç–∫–∏–º–∏ descriptions –æ—Å—Ç–∞—é—Ç—Å—è –∫–∞–∫ –µ—Å—Ç—å.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Tool —Å –∫–æ—Ä–æ—Ç–∫–∏–º description...")
        tools = [Tool(
            type="function",
            function=ToolFunction(
                name="get_weather",
                description="Get weather for a location",
                parameters={"type": "object", "properties": {}}
            )
        )]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û–±—Ä–∞–±–æ—Ç–∫–∞ tools...")
        with patch('kiro_gateway.converters.TOOL_DESCRIPTION_MAX_LENGTH', 10000):
            processed, doc = process_tools_with_long_descriptions(tools)
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º description: –û–∂–∏–¥–∞–ª–æ—Å—å 'Get weather for a location', –ü–æ–ª—É—á–µ–Ω–æ '{processed[0].function.description}'")
        assert len(processed) == 1
        assert processed[0].function.description == "Get weather for a location"
        assert doc == ""
    
    def test_long_description_moved_to_system_prompt(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–µ—Ä–µ–Ω–æ—Å –¥–ª–∏–Ω–Ω–æ–≥–æ description –≤ system prompt.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –¥–ª–∏–Ω–Ω—ã–µ descriptions –ø–µ—Ä–µ–Ω–æ—Å—è—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Tool —Å –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–º description...")
        long_description = "A" * 15000  # 15000 —Å–∏–º–≤–æ–ª–æ–≤ - –±–æ–ª—å—à–µ –ª–∏–º–∏—Ç–∞
        tools = [Tool(
            type="function",
            function=ToolFunction(
                name="bash",
                description=long_description,
                parameters={"type": "object", "properties": {"command": {"type": "string"}}}
            )
        )]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û–±—Ä–∞–±–æ—Ç–∫–∞ tools —Å –ª–∏–º–∏—Ç–æ–º 10000...")
        with patch('kiro_gateway.converters.TOOL_DESCRIPTION_MAX_LENGTH', 10000):
            processed, doc = process_tools_with_long_descriptions(tools)
        
        print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º reference –≤ description...")
        assert len(processed) == 1
        assert "[Full documentation in system prompt under '## Tool: bash']" in processed[0].function.description
        
        print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –≤ system prompt...")
        assert "## Tool: bash" in doc
        assert long_description in doc
        assert "# Tool Documentation" in doc
    
    def test_mixed_short_and_long_descriptions(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É —Å–º–µ—à–∞–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ tools.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –∫–æ—Ä–æ—Ç–∫–∏–µ –æ—Å—Ç–∞—é—Ç—Å—è, –¥–ª–∏–Ω–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—è—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –î–≤–∞ tools - –∫–æ—Ä–æ—Ç–∫–∏–π –∏ –¥–ª–∏–Ω–Ω—ã–π...")
        short_desc = "Short description"
        long_desc = "B" * 15000
        tools = [
            Tool(
                type="function",
                function=ToolFunction(
                    name="short_tool",
                    description=short_desc,
                    parameters={}
                )
            ),
            Tool(
                type="function",
                function=ToolFunction(
                    name="long_tool",
                    description=long_desc,
                    parameters={}
                )
            )
        ]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û–±—Ä–∞–±–æ—Ç–∫–∞ tools...")
        with patch('kiro_gateway.converters.TOOL_DESCRIPTION_MAX_LENGTH', 10000):
            processed, doc = process_tools_with_long_descriptions(tools)
        
        print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ tools: –û–∂–∏–¥–∞–ª–æ—Å—å 2, –ü–æ–ª—É—á–µ–Ω–æ {len(processed)}")
        assert len(processed) == 2
        
        print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä–æ—Ç–∫–∏–π tool...")
        assert processed[0].function.description == short_desc
        
        print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω–Ω—ã–π tool...")
        assert "[Full documentation in system prompt" in processed[1].function.description
        assert "## Tool: long_tool" in doc
        assert long_desc in doc
    
    def test_preserves_tool_parameters(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ parameters –ø—Ä–∏ –ø–µ—Ä–µ–Ω–æ—Å–µ description.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ parameters –Ω–µ —Ç–µ—Ä—è—é—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Tool —Å parameters –∏ –¥–ª–∏–Ω–Ω—ã–º description...")
        params = {
            "type": "object",
            "properties": {
                "location": {"type": "string", "description": "City name"},
                "units": {"type": "string", "enum": ["celsius", "fahrenheit"]}
            },
            "required": ["location"]
        }
        tools = [Tool(
            type="function",
            function=ToolFunction(
                name="weather",
                description="C" * 15000,
                parameters=params
            )
        )]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û–±—Ä–∞–±–æ—Ç–∫–∞ tools...")
        with patch('kiro_gateway.converters.TOOL_DESCRIPTION_MAX_LENGTH', 10000):
            processed, doc = process_tools_with_long_descriptions(tools)
        
        print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ parameters...")
        assert processed[0].function.parameters == params
    
    def test_disabled_when_limit_is_zero(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø—Ä–∏ –ª–∏–º–∏—Ç–µ 0.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø—Ä–∏ TOOL_DESCRIPTION_MAX_LENGTH=0 tools –Ω–µ –∏–∑–º–µ–Ω—è—é—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Tool —Å –¥–ª–∏–Ω–Ω—ã–º description –∏ –ª–∏–º–∏—Ç 0...")
        long_desc = "D" * 15000
        tools = [Tool(
            type="function",
            function=ToolFunction(
                name="test_tool",
                description=long_desc,
                parameters={}
            )
        )]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û–±—Ä–∞–±–æ—Ç–∫–∞ tools —Å –ª–∏–º–∏—Ç–æ–º 0...")
        with patch('kiro_gateway.converters.TOOL_DESCRIPTION_MAX_LENGTH', 0):
            processed, doc = process_tools_with_long_descriptions(tools)
        
        print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ description –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è...")
        assert processed[0].function.description == long_desc
        assert doc == ""
    
    def test_non_function_tools_unchanged(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ non-function tools –Ω–µ –∏–∑–º–µ–Ω—è—é—Ç—Å—è.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Ç–æ–ª—å–∫–æ function tools –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Tool —Å type != function...")
        # –°–æ–∑–¥–∞—ë–º tool —Å –¥—Ä—É–≥–∏–º —Ç–∏–ø–æ–º (—Ö–æ—Ç—è –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ OpenAI –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ function)
        tools = [Tool(
            type="other_type",
            function=ToolFunction(
                name="test",
                description="E" * 15000,
                parameters={}
            )
        )]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û–±—Ä–∞–±–æ—Ç–∫–∞ tools...")
        with patch('kiro_gateway.converters.TOOL_DESCRIPTION_MAX_LENGTH', 10000):
            processed, doc = process_tools_with_long_descriptions(tools)
        
        print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ tool –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è...")
        assert len(processed) == 1
        assert processed[0].type == "other_type"
        assert doc == ""
    
    def test_multiple_long_descriptions_all_moved(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–µ—Ä–µ–Ω–æ—Å –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –¥–ª–∏–Ω–Ω—ã—Ö descriptions.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤—Å–µ –¥–ª–∏–Ω–Ω—ã–µ descriptions –ø–µ—Ä–µ–Ω–æ—Å—è—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –¢—Ä–∏ tools —Å –¥–ª–∏–Ω–Ω—ã–º–∏ descriptions...")
        tools = [
            Tool(type="function", function=ToolFunction(name="tool1", description="F" * 15000, parameters={})),
            Tool(type="function", function=ToolFunction(name="tool2", description="G" * 15000, parameters={})),
            Tool(type="function", function=ToolFunction(name="tool3", description="H" * 15000, parameters={}))
        ]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û–±—Ä–∞–±–æ—Ç–∫–∞ tools...")
        with patch('kiro_gateway.converters.TOOL_DESCRIPTION_MAX_LENGTH', 10000):
            processed, doc = process_tools_with_long_descriptions(tools)
        
        print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ —Ç—Ä–∏ tools...")
        assert len(processed) == 3
        for i, tool in enumerate(processed):
            assert "[Full documentation in system prompt" in tool.function.description
        
        print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ —Ç—Ä–∏ —Å–µ–∫—Ü–∏–∏...")
        assert "## Tool: tool1" in doc
        assert "## Tool: tool2" in doc
        assert "## Tool: tool3" in doc
    
    def test_empty_description_unchanged(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –ø—É—Å—Ç–æ–≥–æ description.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø—É—Å—Ç–æ–π description –Ω–µ –≤—ã–∑—ã–≤–∞–µ—Ç –æ—à–∏–±–æ–∫.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Tool —Å –ø—É—Å—Ç—ã–º description...")
        tools = [Tool(
            type="function",
            function=ToolFunction(
                name="empty_desc_tool",
                description="",
                parameters={}
            )
        )]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û–±—Ä–∞–±–æ—Ç–∫–∞ tools...")
        with patch('kiro_gateway.converters.TOOL_DESCRIPTION_MAX_LENGTH', 10000):
            processed, doc = process_tools_with_long_descriptions(tools)
        
        print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø—É—Å—Ç–æ–π description –æ—Å—Ç–∞–ª—Å—è –ø—É—Å—Ç—ã–º...")
        assert processed[0].function.description == ""
        assert doc == ""
    
    def test_none_description_unchanged(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É None description.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ None description –Ω–µ –≤—ã–∑—ã–≤–∞–µ—Ç –æ—à–∏–±–æ–∫.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Tool —Å None description...")
        tools = [Tool(
            type="function",
            function=ToolFunction(
                name="none_desc_tool",
                description=None,
                parameters={}
            )
        )]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û–±—Ä–∞–±–æ—Ç–∫–∞ tools...")
        with patch('kiro_gateway.converters.TOOL_DESCRIPTION_MAX_LENGTH', 10000):
            processed, doc = process_tools_with_long_descriptions(tools)
        
        print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ None description –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ...")
        # None –¥–æ–ª–∂–µ–Ω –æ—Å—Ç–∞—Ç—å—Å—è None –∏–ª–∏ —Å—Ç–∞—Ç—å –ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–æ–π
        assert processed[0].function.description is None or processed[0].function.description == ""
        assert doc == ""


class TestSanitizeJsonSchema:
    """
    –¢–µ—Å—Ç—ã —Ñ—É–Ω–∫—Ü–∏–∏ _sanitize_json_schema.
    
    –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –æ—á–∏—â–∞–µ—Ç JSON Schema –æ—Ç –ø–æ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–µ Kiro API –Ω–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç:
    - –ü—É—Å—Ç—ã–µ required –º–∞—Å—Å–∏–≤—ã []
    - additionalProperties
    """
    
    def test_returns_empty_dict_for_none(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É None.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ None –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: None schema...")
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û—á–∏—Å—Ç–∫–∞ schema...")
        result = _sanitize_json_schema(None)
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å {{}}, –ü–æ–ª—É—á–µ–Ω–æ {result}")
        assert result == {}
    
    def test_returns_empty_dict_for_empty_dict(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –ø—É—Å—Ç–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è –∫–∞–∫ –µ—Å—Ç—å.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ü—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å...")
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û—á–∏—Å—Ç–∫–∞ schema...")
        result = _sanitize_json_schema({})
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å {{}}, –ü–æ–ª—É—á–µ–Ω–æ {result}")
        assert result == {}
    
    def test_removes_empty_required_array(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —É–¥–∞–ª–µ–Ω–∏–µ –ø—É—Å—Ç–æ–≥–æ required –º–∞—Å—Å–∏–≤–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ required: [] —É–¥–∞–ª—è–µ—Ç—Å—è –∏–∑ schema.
        
        –≠—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ—Å—Ç –¥–ª—è –±–∞–≥–∞ Cline, –≥–¥–µ tools —Å required: []
        –≤—ã–∑—ã–≤–∞–ª–∏ –æ—à–∏–±–∫—É 400 "Improperly formed request" –æ—Ç Kiro API.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Schema —Å –ø—É—Å—Ç—ã–º required...")
        schema = {
            "type": "object",
            "properties": {},
            "required": []
        }
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û—á–∏—Å—Ç–∫–∞ schema...")
        result = _sanitize_json_schema(schema)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        print("–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ required —É–¥–∞–ª—ë–Ω...")
        assert "required" not in result
        assert result["type"] == "object"
        assert result["properties"] == {}
    
    def test_preserves_non_empty_required_array(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø—É—Å—Ç–æ–≥–æ required –º–∞—Å—Å–∏–≤–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ required —Å —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Schema —Å –Ω–µ–ø—É—Å—Ç—ã–º required...")
        schema = {
            "type": "object",
            "properties": {
                "location": {"type": "string"}
            },
            "required": ["location"]
        }
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û—á–∏—Å—Ç–∫–∞ schema...")
        result = _sanitize_json_schema(schema)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        print("–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ required —Å–æ—Ö—Ä–∞–Ω—ë–Ω...")
        assert "required" in result
        assert result["required"] == ["location"]
    
    def test_removes_additional_properties(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —É–¥–∞–ª–µ–Ω–∏–µ additionalProperties.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ additionalProperties —É–¥–∞–ª—è–µ—Ç—Å—è –∏–∑ schema.
        
        Kiro API –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç additionalProperties –≤ JSON Schema.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Schema —Å additionalProperties...")
        schema = {
            "type": "object",
            "properties": {},
            "additionalProperties": False
        }
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û—á–∏—Å—Ç–∫–∞ schema...")
        result = _sanitize_json_schema(schema)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        print("–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ additionalProperties —É–¥–∞–ª—ë–Ω...")
        assert "additionalProperties" not in result
        assert result["type"] == "object"
    
    def test_removes_both_empty_required_and_additional_properties(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —É–¥–∞–ª–µ–Ω–∏–µ –æ–±–æ–∏—Ö –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –ø–æ–ª–µ–π.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –æ–±–∞ –ø–æ–ª—è —É–¥–∞–ª—è—é—Ç—Å—è –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ.
        
        –≠—Ç–æ —Ä–µ–∞–ª—å–Ω—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π –æ—Ç Cline, –≥–¥–µ tools –∏–º–µ–ª–∏ –æ–±–∞ –ø–æ–ª—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Schema —Å –æ–±–æ–∏–º–∏ –ø—Ä–æ–±–ª–µ–º–Ω—ã–º–∏ –ø–æ–ª—è–º–∏...")
        schema = {
            "type": "object",
            "properties": {},
            "required": [],
            "additionalProperties": False
        }
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û—á–∏—Å—Ç–∫–∞ schema...")
        result = _sanitize_json_schema(schema)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        print("–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ–±–∞ –ø–æ–ª—è —É–¥–∞–ª–µ–Ω—ã...")
        assert "required" not in result
        assert "additionalProperties" not in result
        assert result == {"type": "object", "properties": {}}
    
    def test_recursively_sanitizes_nested_properties(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–µ–∫—É—Ä—Å–∏–≤–Ω—É—é –æ—á–∏—Å—Ç–∫—É –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö properties.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤–ª–æ–∂–µ–Ω–Ω—ã–µ schema —Ç–∞–∫–∂–µ –æ—á–∏—â–∞—é—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Schema —Å –≤–ª–æ–∂–µ–Ω–Ω—ã–º–∏ properties...")
        schema = {
            "type": "object",
            "properties": {
                "nested": {
                    "type": "object",
                    "properties": {},
                    "required": [],
                    "additionalProperties": False
                }
            }
        }
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û—á–∏—Å—Ç–∫–∞ schema...")
        result = _sanitize_json_schema(schema)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        print("–ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–ª–æ–∂–µ–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç...")
        nested = result["properties"]["nested"]
        assert "required" not in nested
        assert "additionalProperties" not in nested
    
    def test_recursively_sanitizes_dict_values(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–µ–∫—É—Ä—Å–∏–≤–Ω—É—é –æ—á–∏—Å—Ç–∫—É dict –∑–Ω–∞—á–µ–Ω–∏–π.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ª—é–±—ã–µ –≤–ª–æ–∂–µ–Ω–Ω—ã–µ dict –æ—á–∏—â–∞—é—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Schema —Å –≤–ª–æ–∂–µ–Ω–Ω—ã–º dict...")
        schema = {
            "type": "object",
            "items": {
                "type": "string",
                "additionalProperties": True
            }
        }
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û—á–∏—Å—Ç–∫–∞ schema...")
        result = _sanitize_json_schema(schema)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        print("–ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–ª–æ–∂–µ–Ω–Ω—ã–π items...")
        assert "additionalProperties" not in result["items"]
        assert result["items"]["type"] == "string"
    
    def test_sanitizes_items_in_lists(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—á–∏—Å—Ç–∫—É —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ —Å–ø–∏—Å–∫–∞—Ö (anyOf, oneOf).
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —ç–ª–µ–º–µ–Ω—Ç—ã —Å–ø–∏—Å–∫–æ–≤ —Ç–∞–∫–∂–µ –æ—á–∏—â–∞—é—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Schema —Å anyOf...")
        schema = {
            "anyOf": [
                {"type": "string", "additionalProperties": False},
                {"type": "number", "required": []}
            ]
        }
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û—á–∏—Å—Ç–∫–∞ schema...")
        result = _sanitize_json_schema(schema)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        print("–ü—Ä–æ–≤–µ—Ä—è–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã anyOf...")
        assert "additionalProperties" not in result["anyOf"][0]
        assert "required" not in result["anyOf"][1]
    
    def test_preserves_non_dict_list_items(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ-dict —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ —Å–ø–∏—Å–∫–∞—Ö.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Å—Ç—Ä–æ–∫–∏ –∏ –¥—Ä—É–≥–∏–µ —Ç–∏–ø—ã –≤ —Å–ø–∏—Å–∫–∞—Ö —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Schema —Å enum...")
        schema = {
            "type": "string",
            "enum": ["value1", "value2", "value3"]
        }
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û—á–∏—Å—Ç–∫–∞ schema...")
        result = _sanitize_json_schema(schema)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        print("–ü—Ä–æ–≤–µ—Ä—è–µ–º enum —Å–æ—Ö—Ä–∞–Ω—ë–Ω...")
        assert result["enum"] == ["value1", "value2", "value3"]
    
    def test_complex_real_world_schema(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—á–∏—Å—Ç–∫—É —Ä–µ–∞–ª—å–Ω–æ–π —Å–ª–æ–∂–Ω–æ–π schema –æ—Ç Cline.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Ä–µ–∞–ª—å–Ω—ã–µ schema –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –†–µ–∞–ª—å–Ω–∞—è schema –æ—Ç Cline...")
        schema = {
            "type": "object",
            "properties": {
                "question": {
                    "type": "string",
                    "description": "The question to ask"
                },
                "options": {
                    "type": "string",
                    "description": "Array of options"
                }
            },
            "required": ["question", "options"],
            "additionalProperties": False
        }
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –û—á–∏—Å—Ç–∫–∞ schema...")
        result = _sanitize_json_schema(schema)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        print("–ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç...")
        assert "additionalProperties" not in result
        assert result["required"] == ["question", "options"]  # –ù–µ–ø—É—Å—Ç–æ–π required —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è
        assert result["properties"]["question"]["type"] == "string"


class TestBuildUserInputContext:
    """–¢–µ—Å—Ç—ã —Ñ—É–Ω–∫—Ü–∏–∏ _build_user_input_context."""
    
    def test_builds_tools_context(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å tools.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ tools –ø—Ä–µ–æ–±—Ä–∞–∑—É—é—Ç—Å—è –≤ toolSpecification.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ó–∞–ø—Ä–æ—Å —Å tools...")
        request = ChatCompletionRequest(
            model="claude-sonnet-4",
            messages=[ChatMessage(role="user", content="Hello")],
            tools=[Tool(
                type="function",
                function=ToolFunction(
                    name="get_weather",
                    description="Get weather",
                    parameters={"type": "object", "properties": {}}
                )
            )]
        )
        current_msg = ChatMessage(role="user", content="Hello")
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞...")
        result = _build_user_input_context(request, current_msg)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        assert "tools" in result
        assert len(result["tools"]) == 1
        assert result["tools"][0]["toolSpecification"]["name"] == "get_weather"
    
    def test_returns_empty_for_no_tools(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–æ–∑–≤—Ä–∞—Ç –ø—É—Å—Ç–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –±–µ–∑ tools.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –∑–∞–ø—Ä–æ—Å –±–µ–∑ tools –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Å—Ç–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ó–∞–ø—Ä–æ—Å –±–µ–∑ tools...")
        request = ChatCompletionRequest(
            model="claude-sonnet-4",
            messages=[ChatMessage(role="user", content="Hello")]
        )
        current_msg = ChatMessage(role="user", content="Hello")
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞...")
        result = _build_user_input_context(request, current_msg)
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å {{}}, –ü–æ–ª—É—á–µ–Ω–æ {result}")
        assert result == {}
    
    def test_empty_description_replaced_with_placeholder(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∑–∞–º–µ–Ω—É –ø—É—Å—Ç–æ–≥–æ description –Ω–∞ placeholder.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø—É—Å—Ç–æ–π description –∑–∞–º–µ–Ω—è–µ—Ç—Å—è –Ω–∞ "Tool: {name}".
        
        –≠—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —Ç–µ—Å—Ç –¥–ª—è –±–∞–≥–∞ Cline, –≥–¥–µ tool focus_chain –∏–º–µ–ª
        –ø—É—Å—Ç–æ–π description "", —á—Ç–æ –≤—ã–∑—ã–≤–∞–ª–æ –æ—à–∏–±–∫—É 400 –æ—Ç Kiro API.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Tool —Å –ø—É—Å—Ç—ã–º description...")
        request = ChatCompletionRequest(
            model="claude-sonnet-4",
            messages=[ChatMessage(role="user", content="Hello")],
            tools=[Tool(
                type="function",
                function=ToolFunction(
                    name="focus_chain",
                    description="",
                    parameters={"type": "object", "properties": {}}
                )
            )]
        )
        current_msg = ChatMessage(role="user", content="Hello")
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞...")
        result = _build_user_input_context(request, current_msg)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        print("–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ description –∑–∞–º–µ–Ω—ë–Ω –Ω–∞ placeholder...")
        tool_spec = result["tools"][0]["toolSpecification"]
        assert tool_spec["description"] == "Tool: focus_chain"
    
    def test_whitespace_only_description_replaced_with_placeholder(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∑–∞–º–µ–Ω—É description –∏–∑ –ø—Ä–æ–±–µ–ª–æ–≤ –Ω–∞ placeholder.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ description —Å —Ç–æ–ª—å–∫–æ –ø—Ä–æ–±–µ–ª–∞–º–∏ –∑–∞–º–µ–Ω—è–µ—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Tool —Å description –∏–∑ –ø—Ä–æ–±–µ–ª–æ–≤...")
        request = ChatCompletionRequest(
            model="claude-sonnet-4",
            messages=[ChatMessage(role="user", content="Hello")],
            tools=[Tool(
                type="function",
                function=ToolFunction(
                    name="whitespace_tool",
                    description="   ",
                    parameters={}
                )
            )]
        )
        current_msg = ChatMessage(role="user", content="Hello")
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞...")
        result = _build_user_input_context(request, current_msg)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        print("–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ description –∑–∞–º–µ–Ω—ë–Ω –Ω–∞ placeholder...")
        tool_spec = result["tools"][0]["toolSpecification"]
        assert tool_spec["description"] == "Tool: whitespace_tool"
    
    def test_none_description_replaced_with_placeholder(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∑–∞–º–µ–Ω—É None description –Ω–∞ placeholder.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ None description –∑–∞–º–µ–Ω—è–µ—Ç—Å—è –Ω–∞ "Tool: {name}".
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Tool —Å None description...")
        request = ChatCompletionRequest(
            model="claude-sonnet-4",
            messages=[ChatMessage(role="user", content="Hello")],
            tools=[Tool(
                type="function",
                function=ToolFunction(
                    name="none_desc_tool",
                    description=None,
                    parameters={}
                )
            )]
        )
        current_msg = ChatMessage(role="user", content="Hello")
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞...")
        result = _build_user_input_context(request, current_msg)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        print("–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ description –∑–∞–º–µ–Ω—ë–Ω –Ω–∞ placeholder...")
        tool_spec = result["tools"][0]["toolSpecification"]
        assert tool_spec["description"] == "Tool: none_desc_tool"
    
    def test_non_empty_description_preserved(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–µ–ø—É—Å—Ç–æ–≥–æ description.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–π description –Ω–µ –∏–∑–º–µ–Ω—è–µ—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Tool —Å –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º description...")
        request = ChatCompletionRequest(
            model="claude-sonnet-4",
            messages=[ChatMessage(role="user", content="Hello")],
            tools=[Tool(
                type="function",
                function=ToolFunction(
                    name="get_weather",
                    description="Get weather for a location",
                    parameters={}
                )
            )]
        )
        current_msg = ChatMessage(role="user", content="Hello")
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞...")
        result = _build_user_input_context(request, current_msg)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        print("–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ description —Å–æ—Ö—Ä–∞–Ω—ë–Ω...")
        tool_spec = result["tools"][0]["toolSpecification"]
        assert tool_spec["description"] == "Get weather for a location"
    
    def test_sanitizes_tool_parameters(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—á–∏—Å—Ç–∫—É parameters –æ—Ç –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –ø–æ–ª–µ–π.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ _sanitize_json_schema –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –∫ parameters.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Tool —Å –ø—Ä–æ–±–ª–µ–º–Ω—ã–º–∏ parameters...")
        request = ChatCompletionRequest(
            model="claude-sonnet-4",
            messages=[ChatMessage(role="user", content="Hello")],
            tools=[Tool(
                type="function",
                function=ToolFunction(
                    name="test_tool",
                    description="Test tool",
                    parameters={
                        "type": "object",
                        "properties": {},
                        "required": [],
                        "additionalProperties": False
                    }
                )
            )]
        )
        current_msg = ChatMessage(role="user", content="Hello")
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞...")
        result = _build_user_input_context(request, current_msg)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        print("–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ parameters –æ—á–∏—â–µ–Ω—ã...")
        input_schema = result["tools"][0]["toolSpecification"]["inputSchema"]["json"]
        assert "required" not in input_schema
        assert "additionalProperties" not in input_schema
    
    def test_mixed_tools_with_empty_and_normal_descriptions(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É —Å–º–µ—à–∞–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ tools.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø—É—Å—Ç—ã–µ descriptions –∑–∞–º–µ–Ω—è—é—Ç—Å—è, –∞ –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è.
        
        –≠—Ç–æ —Ä–µ–∞–ª—å–Ω—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π –æ—Ç Cline, –≥–¥–µ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ tools –∏–º–µ—é—Ç
        –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ descriptions, –Ω–æ focus_chain –∏–º–µ–µ—Ç –ø—É—Å—Ç–æ–π.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–º–µ—à–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ tools...")
        request = ChatCompletionRequest(
            model="claude-sonnet-4",
            messages=[ChatMessage(role="user", content="Hello")],
            tools=[
                Tool(
                    type="function",
                    function=ToolFunction(
                        name="read_file",
                        description="Read contents of a file",
                        parameters={}
                    )
                ),
                Tool(
                    type="function",
                    function=ToolFunction(
                        name="focus_chain",
                        description="",
                        parameters={}
                    )
                ),
                Tool(
                    type="function",
                    function=ToolFunction(
                        name="write_file",
                        description="Write content to a file",
                        parameters={}
                    )
                )
            ]
        )
        current_msg = ChatMessage(role="user", content="Hello")
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞...")
        result = _build_user_input_context(request, current_msg)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        print("–ü—Ä–æ–≤–µ—Ä—è–µ–º descriptions...")
        tools = result["tools"]
        assert tools[0]["toolSpecification"]["description"] == "Read contents of a file"
        assert tools[1]["toolSpecification"]["description"] == "Tool: focus_chain"
        assert tools[2]["toolSpecification"]["description"] == "Write content to a file"


class TestBuildKiroPayloadToolCallsIntegration:
    """
    –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è build_kiro_payload —Å tool_calls.
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–ª–Ω—ã–π flow –æ—Ç OpenAI —Ñ–æ—Ä–º–∞—Ç–∞ –¥–æ Kiro —Ñ–æ—Ä–º–∞—Ç–∞.
    """
    
    def test_multiple_assistant_tool_calls_with_results(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–ª–Ω—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ assistant tool_calls –∏ –∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤—Å–µ toolUses –∏ toolResults –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Å–≤—è–∑—ã–≤–∞—é—Ç—Å—è –≤ Kiro payload.
        
        –≠—Ç–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç –¥–ª—è –±–∞–≥–∞ Codex CLI, –≥–¥–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ assistant —Å–æ–æ–±—â–µ–Ω–∏–π
        —Å tool_calls –æ—Ç–ø—Ä–∞–≤–ª—è–ª–∏—Å—å –ø–æ–¥—Ä—è–¥, –∞ –∑–∞—Ç–µ–º tool results. –ë–µ–∑ —Ñ–∏–∫—Å–∞ –≤—Ç–æ—Ä–æ–π toolUse
        —Ç–µ—Ä—è–ª—Å—è, —á—Ç–æ –ø—Ä–∏–≤–æ–¥–∏–ª–æ –∫ –æ—à–∏–±–∫–µ 400 –æ—Ç Kiro API.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ü–æ–ª–Ω—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π —Å –¥–≤—É–º—è tool_calls –∏ –∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏...")
        request = ChatCompletionRequest(
            model="claude-sonnet-4-5",
            messages=[
                ChatMessage(role="user", content="Run two commands"),
                # –ü–µ—Ä–≤—ã–π assistant —Å tool_call
                ChatMessage(
                    role="assistant",
                    content=None,
                    tool_calls=[{
                        "id": "tooluse_first",
                        "type": "function",
                        "function": {
                            "name": "shell",
                            "arguments": '{"command": ["ls"]}'
                        }
                    }]
                ),
                # –í—Ç–æ—Ä–æ–π assistant —Å tool_call (–ø–æ–¥—Ä—è–¥!)
                ChatMessage(
                    role="assistant",
                    content=None,
                    tool_calls=[{
                        "id": "tooluse_second",
                        "type": "function",
                        "function": {
                            "name": "shell",
                            "arguments": '{"command": ["pwd"]}'
                        }
                    }]
                ),
                # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±–æ–∏—Ö tool_calls
                ChatMessage(role="tool", content="file1.txt\nfile2.txt", tool_call_id="tooluse_first"),
                ChatMessage(role="tool", content="/home/user", tool_call_id="tooluse_second")
            ]
        )
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ Kiro payload...")
        result = build_kiro_payload(request, "conv-123", "arn:aws:test")
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
        history = result["conversationState"].get("history", [])
        print(f"–ò—Å—Ç–æ—Ä–∏—è: {history}")
        
        # –î–æ–ª–∂–µ–Ω –±—ã—Ç—å userInputMessage –∏ assistantResponseMessage –≤ –∏—Å—Ç–æ—Ä–∏–∏
        assert len(history) >= 2, f"–û–∂–∏–¥–∞–ª–æ—Å—å –º–∏–Ω–∏–º—É–º 2 —ç–ª–µ–º–µ–Ω—Ç–∞ –≤ –∏—Å—Ç–æ—Ä–∏–∏, –ø–æ–ª—É—á–µ–Ω–æ {len(history)}"
        
        # –ù–∞—Ö–æ–¥–∏–º assistantResponseMessage
        assistant_msgs = [h for h in history if "assistantResponseMessage" in h]
        print(f"Assistant —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –∏—Å—Ç–æ—Ä–∏–∏: {assistant_msgs}")
        assert len(assistant_msgs) >= 1, "–î–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω assistantResponseMessage"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤ assistantResponseMessage –µ—Å—Ç—å –æ–±–∞ toolUses
        assistant_msg = assistant_msgs[0]["assistantResponseMessage"]
        tool_uses = assistant_msg.get("toolUses", [])
        print(f"ToolUses –≤ assistant: {tool_uses}")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ toolUses: –û–∂–∏–¥–∞–ª–æ—Å—å 2, –ü–æ–ª—É—á–µ–Ω–æ {len(tool_uses)}")
        assert len(tool_uses) == 2, f"–î–æ–ª–∂–Ω–æ –±—ã—Ç—å 2 toolUses, –ø–æ–ª—É—á–µ–Ω–æ {len(tool_uses)}"
        
        tool_use_ids = [tu["toolUseId"] for tu in tool_uses]
        print(f"ToolUse IDs: {tool_use_ids}")
        assert "tooluse_first" in tool_use_ids
        assert "tooluse_second" in tool_use_ids
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º currentMessage —Å–æ–¥–µ—Ä–∂–∏—Ç toolResults
        current_msg = result["conversationState"]["currentMessage"]["userInputMessage"]
        context = current_msg.get("userInputMessageContext", {})
        tool_results = context.get("toolResults", [])
        print(f"ToolResults –≤ currentMessage: {tool_results}")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ toolResults: –û–∂–∏–¥–∞–ª–æ—Å—å 2, –ü–æ–ª—É—á–µ–Ω–æ {len(tool_results)}")
        assert len(tool_results) == 2, f"–î–æ–ª–∂–Ω–æ –±—ã—Ç—å 2 toolResults, –ø–æ–ª—É—á–µ–Ω–æ {len(tool_results)}"
        
        tool_result_ids = [tr["toolUseId"] for tr in tool_results]
        print(f"ToolResult IDs: {tool_result_ids}")
        assert "tooluse_first" in tool_result_ids
        assert "tooluse_second" in tool_result_ids


class TestBuildKiroPayload:
    """–¢–µ—Å—Ç—ã —Ñ—É–Ω–∫—Ü–∏–∏ build_kiro_payload."""
    
    def test_builds_simple_payload(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø—Ä–æ—Å—Ç–æ–≥–æ payload.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –±–∞–∑–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å...")
        request = ChatCompletionRequest(
            model="claude-sonnet-4-5",
            messages=[ChatMessage(role="user", content="Hello")]
        )
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ payload...")
        result = build_kiro_payload(request, "conv-123", "arn:aws:test")
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        assert "conversationState" in result
        assert result["conversationState"]["conversationId"] == "conv-123"
        assert "currentMessage" in result["conversationState"]
        assert result["profileArn"] == "arn:aws:test"
    
    def test_includes_system_prompt_in_first_message(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ system prompt –∫ –ø–µ—Ä–≤–æ–º—É —Å–æ–æ–±—â–µ–Ω–∏—é.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ system prompt –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç—Å—è —Å user —Å–æ–æ–±—â–µ–Ω–∏–µ–º.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ó–∞–ø—Ä–æ—Å —Å system prompt...")
        request = ChatCompletionRequest(
            model="claude-sonnet-4-5",
            messages=[
                ChatMessage(role="system", content="You are helpful"),
                ChatMessage(role="user", content="Hello")
            ]
        )
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ payload...")
        result = build_kiro_payload(request, "conv-123", "")
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        current_content = result["conversationState"]["currentMessage"]["userInputMessage"]["content"]
        assert "You are helpful" in current_content
        assert "Hello" in current_content
    
    def test_builds_history_for_multi_turn(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –¥–ª—è multi-turn.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ø–∞–¥–∞—é—Ç –≤ history.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Multi-turn –∑–∞–ø—Ä–æ—Å...")
        request = ChatCompletionRequest(
            model="claude-sonnet-4-5",
            messages=[
                ChatMessage(role="user", content="Hello"),
                ChatMessage(role="assistant", content="Hi"),
                ChatMessage(role="user", content="How are you?")
            ]
        )
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ payload...")
        result = build_kiro_payload(request, "conv-123", "")
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        assert "history" in result["conversationState"]
        assert len(result["conversationState"]["history"]) == 2
    
    def test_handles_assistant_as_last_message(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É assistant –∫–∞–∫ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Å–æ–∑–¥–∞—ë—Ç—Å—è "Continue" —Å–æ–æ–±—â–µ–Ω–∏–µ.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ó–∞–ø—Ä–æ—Å —Å assistant –≤ –∫–æ–Ω—Ü–µ...")
        request = ChatCompletionRequest(
            model="claude-sonnet-4-5",
            messages=[
                ChatMessage(role="user", content="Hello"),
                ChatMessage(role="assistant", content="Hi there")
            ]
        )
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ payload...")
        result = build_kiro_payload(request, "conv-123", "")
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        current_content = result["conversationState"]["currentMessage"]["userInputMessage"]["content"]
        assert current_content == "Continue"
    
    def test_raises_for_empty_messages(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤—ã–±—Ä–æ—Å –∏—Å–∫–ª—é—á–µ–Ω–∏—è –¥–ª—è –ø—É—Å—Ç—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å –≤—ã–∑—ã–≤–∞–µ—Ç ValueError.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ó–∞–ø—Ä–æ—Å —Ç–æ–ª—å–∫–æ —Å system —Å–æ–æ–±—â–µ–Ω–∏–µ–º...")
        request = ChatCompletionRequest(
            model="claude-sonnet-4-5",
            messages=[ChatMessage(role="system", content="You are helpful")]
        )
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ–ø—ã—Ç–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è payload...")
        with pytest.raises(ValueError) as exc_info:
            build_kiro_payload(request, "conv-123", "")
        
        print(f"–ò—Å–∫–ª—é—á–µ–Ω–∏–µ: {exc_info.value}")
        assert "No messages to send" in str(exc_info.value)
    
    def test_uses_continue_for_empty_content(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ "Continue" –¥–ª—è –ø—É—Å—Ç–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø—É—Å—Ç–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∑–∞–º–µ–Ω—è–µ—Ç—Å—è –Ω–∞ "Continue".
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ó–∞–ø—Ä–æ—Å —Å –ø—É—Å—Ç—ã–º –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º...")
        request = ChatCompletionRequest(
            model="claude-sonnet-4-5",
            messages=[ChatMessage(role="user", content="")]
        )
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ payload...")
        result = build_kiro_payload(request, "conv-123", "")
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        current_content = result["conversationState"]["currentMessage"]["userInputMessage"]["content"]
        assert current_content == "Continue"
    
    def test_maps_model_id_correctly(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –º–∞–ø–ø–∏–Ω–≥ –≤–Ω–µ—à–Ω–µ–≥–æ ID –º–æ–¥–µ–ª–∏ –≤–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ MODEL_MAPPING –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ó–∞–ø—Ä–æ—Å —Å –≤–Ω–µ—à–Ω–∏–º ID –º–æ–¥–µ–ª–∏...")
        request = ChatCompletionRequest(
            model="claude-sonnet-4-5",
            messages=[ChatMessage(role="user", content="Hello")]
        )
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ payload...")
        result = build_kiro_payload(request, "conv-123", "")
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        model_id = result["conversationState"]["currentMessage"]["userInputMessage"]["modelId"]
        # claude-sonnet-4-5 –¥–æ–ª–∂–µ–Ω –º–∞–ø–ø–∏—Ç—å—Å—è –≤ CLAUDE_SONNET_4_5_20250929_V1_0
        assert model_id == "CLAUDE_SONNET_4_5_20250929_V1_0"
    
    def test_long_tool_description_added_to_system_prompt(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é –¥–ª–∏–Ω–Ω—ã—Ö tool descriptions –≤ payload.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –¥–ª–∏–Ω–Ω—ã–µ descriptions –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –≤ system prompt –≤ payload.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ó–∞–ø—Ä–æ—Å —Å tool —Å –¥–ª–∏–Ω–Ω—ã–º description...")
        long_desc = "X" * 15000
        request = ChatCompletionRequest(
            model="claude-sonnet-4-5",
            messages=[
                ChatMessage(role="system", content="You are helpful"),
                ChatMessage(role="user", content="Hello")
            ],
            tools=[Tool(
                type="function",
                function=ToolFunction(
                    name="long_tool",
                    description=long_desc,
                    parameters={}
                )
            )]
        )
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ payload...")
        with patch('kiro_gateway.converters.TOOL_DESCRIPTION_MAX_LENGTH', 10000):
            result = build_kiro_payload(request, "conv-123", "")
        
        print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ system prompt —Å–æ–¥–µ—Ä–∂–∏—Ç tool documentation...")
        current_content = result["conversationState"]["currentMessage"]["userInputMessage"]["content"]
        assert "You are helpful" in current_content
        assert "## Tool: long_tool" in current_content
        assert long_desc in current_content
        
        print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ tool –≤ context –∏–º–µ–µ—Ç reference description...")
        tools_context = result["conversationState"]["currentMessage"]["userInputMessage"]["userInputMessageContext"]["tools"]
        assert "[Full documentation in system prompt" in tools_context[0]["toolSpecification"]["description"]


================================================
FILE: tests/unit/test_debug_logger.py
================================================
# -*- coding: utf-8 -*-

"""
Unit-—Ç–µ—Å—Ç—ã –¥–ª—è DebugLogger.
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ª–æ–≥–∏–∫—É –±—É—Ñ–µ—Ä–∏–∑–∞—Ü–∏–∏ –∏ –∑–∞–ø–∏—Å–∏ debug –ª–æ–≥–æ–≤ –≤ —Ä–∞–∑–Ω—ã—Ö —Ä–µ–∂–∏–º–∞—Ö.
"""

import json
import pytest
from pathlib import Path
from unittest.mock import patch, MagicMock


class TestDebugLoggerModeOff:
    """–¢–µ—Å—Ç—ã –¥–ª—è —Ä–µ–∂–∏–º–∞ DEBUG_MODE=off."""
    
    def test_prepare_new_request_does_nothing(self, tmp_path):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ prepare_new_request –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ—Ç –≤ —Ä–µ–∂–∏–º–µ off.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤ —Ä–µ–∂–∏–º–µ off –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ —Å–æ–∑–¥–∞—ë—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –†–µ–∂–∏–º off...")
        with patch('kiro_gateway.debug_logger.DEBUG_MODE', 'off'):
            with patch('kiro_gateway.debug_logger.DEBUG_DIR', str(tmp_path / "debug_logs")):
                # –ü–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä —Å –Ω–æ–≤—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
                from kiro_gateway.debug_logger import DebugLogger
                logger = DebugLogger.__new__(DebugLogger)
                logger._initialized = False
                logger.__init__()
                logger.debug_dir = tmp_path / "debug_logs"
                
                print("–î–µ–π—Å—Ç–≤–∏–µ: –í—ã–∑–æ–≤ prepare_new_request...")
                logger.prepare_new_request()
                
                print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ —Å–æ–∑–¥–∞–Ω–∞...")
                assert not (tmp_path / "debug_logs").exists()
    
    def test_log_request_body_does_nothing(self, tmp_path):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ log_request_body –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ—Ç –≤ —Ä–µ–∂–∏–º–µ off.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–ø–∏—Å—ã–≤–∞—é—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –†–µ–∂–∏–º off...")
        with patch('kiro_gateway.debug_logger.DEBUG_MODE', 'off'):
            from kiro_gateway.debug_logger import DebugLogger
            logger = DebugLogger.__new__(DebugLogger)
            logger._initialized = False
            logger.__init__()
            logger.debug_dir = tmp_path / "debug_logs"
            
            print("–î–µ–π—Å—Ç–≤–∏–µ: –í—ã–∑–æ–≤ log_request_body...")
            logger.log_request_body(b'{"test": "data"}')
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –Ω–µ —Å–æ–∑–¥–∞–Ω...")
            assert not (tmp_path / "debug_logs" / "request_body.json").exists()


class TestDebugLoggerModeAll:
    """–¢–µ—Å—Ç—ã –¥–ª—è —Ä–µ–∂–∏–º–∞ DEBUG_MODE=all."""
    
    def test_prepare_new_request_clears_directory(self, tmp_path):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ prepare_new_request –æ—á–∏—â–∞–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ —Ä–µ–∂–∏–º–µ all.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Å—Ç–∞—Ä—ã–µ –ª–æ–≥–∏ —É–¥–∞–ª—è—é—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –†–µ–∂–∏–º all, —Å–æ–∑–¥–∞—ë–º —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª...")
        debug_dir = tmp_path / "debug_logs"
        debug_dir.mkdir()
        old_file = debug_dir / "old_file.txt"
        old_file.write_text("old content")
        
        with patch('kiro_gateway.debug_logger.DEBUG_MODE', 'all'):
            from kiro_gateway.debug_logger import DebugLogger
            logger = DebugLogger.__new__(DebugLogger)
            logger._initialized = False
            logger.__init__()
            logger.debug_dir = debug_dir
            
            print("–î–µ–π—Å—Ç–≤–∏–µ: –í—ã–∑–æ–≤ prepare_new_request...")
            logger.prepare_new_request()
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª —É–¥–∞–ª—ë–Ω...")
            assert not old_file.exists()
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å—É—â–µ—Å—Ç–≤—É–µ—Ç...")
            assert debug_dir.exists()
    
    def test_log_request_body_writes_immediately(self, tmp_path):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ log_request_body –ø–∏—à–µ—Ç —Å—Ä–∞–∑—É –≤ —Ñ–∞–π–ª –≤ —Ä–µ–∂–∏–º–µ all.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –∑–∞–ø–∏—Å—ã–≤–∞—é—Ç—Å—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –†–µ–∂–∏–º all...")
        debug_dir = tmp_path / "debug_logs"
        debug_dir.mkdir()
        
        with patch('kiro_gateway.debug_logger.DEBUG_MODE', 'all'):
            from kiro_gateway.debug_logger import DebugLogger
            logger = DebugLogger.__new__(DebugLogger)
            logger._initialized = False
            logger.__init__()
            logger.debug_dir = debug_dir
            
            print("–î–µ–π—Å—Ç–≤–∏–µ: –í—ã–∑–æ–≤ log_request_body...")
            test_data = b'{"model": "test", "messages": []}'
            logger.log_request_body(test_data)
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω...")
            file_path = debug_dir / "request_body.json"
            assert file_path.exists()
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞...")
            content = json.loads(file_path.read_text())
            assert content["model"] == "test"
    
    def test_log_kiro_request_body_writes_immediately(self, tmp_path):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ log_kiro_request_body –ø–∏—à–µ—Ç —Å—Ä–∞–∑—É –≤ —Ñ–∞–π–ª –≤ —Ä–µ–∂–∏–º–µ all.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ Kiro payload –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –†–µ–∂–∏–º all...")
        debug_dir = tmp_path / "debug_logs"
        debug_dir.mkdir()
        
        with patch('kiro_gateway.debug_logger.DEBUG_MODE', 'all'):
            from kiro_gateway.debug_logger import DebugLogger
            logger = DebugLogger.__new__(DebugLogger)
            logger._initialized = False
            logger.__init__()
            logger.debug_dir = debug_dir
            
            print("–î–µ–π—Å—Ç–≤–∏–µ: –í—ã–∑–æ–≤ log_kiro_request_body...")
            test_data = b'{"conversationState": {}}'
            logger.log_kiro_request_body(test_data)
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω...")
            file_path = debug_dir / "kiro_request_body.json"
            assert file_path.exists()
    
    def test_log_raw_chunk_appends_to_file(self, tmp_path):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ log_raw_chunk –¥–æ–ø–∏—Å—ã–≤–∞–µ—Ç –≤ —Ñ–∞–π–ª –≤ —Ä–µ–∂–∏–º–µ all.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —á–∞–Ω–∫–∏ –Ω–∞–∫–∞–ø–ª–∏–≤–∞—é—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –†–µ–∂–∏–º all...")
        debug_dir = tmp_path / "debug_logs"
        debug_dir.mkdir()
        
        with patch('kiro_gateway.debug_logger.DEBUG_MODE', 'all'):
            from kiro_gateway.debug_logger import DebugLogger
            logger = DebugLogger.__new__(DebugLogger)
            logger._initialized = False
            logger.__init__()
            logger.debug_dir = debug_dir
            
            print("–î–µ–π—Å—Ç–≤–∏–µ: –í—ã–∑–æ–≤ log_raw_chunk –¥–≤–∞–∂–¥—ã...")
            logger.log_raw_chunk(b'chunk1')
            logger.log_raw_chunk(b'chunk2')
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞...")
            file_path = debug_dir / "response_stream_raw.txt"
            content = file_path.read_bytes()
            assert content == b'chunk1chunk2'


class TestDebugLoggerModeErrors:
    """–¢–µ—Å—Ç—ã –¥–ª—è —Ä–µ–∂–∏–º–∞ DEBUG_MODE=errors."""
    
    def test_log_request_body_buffers_data(self, tmp_path):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ log_request_body –±—É—Ñ–µ—Ä–∏–∑—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ —Ä–µ–∂–∏–º–µ errors.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–ø–∏—Å—ã–≤–∞—é—Ç—Å—è —Å—Ä–∞–∑—É.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –†–µ–∂–∏–º errors...")
        debug_dir = tmp_path / "debug_logs"
        
        with patch('kiro_gateway.debug_logger.DEBUG_MODE', 'errors'):
            from kiro_gateway.debug_logger import DebugLogger
            logger = DebugLogger.__new__(DebugLogger)
            logger._initialized = False
            logger.__init__()
            logger.debug_dir = debug_dir
            
            print("–î–µ–π—Å—Ç–≤–∏–µ: –í—ã–∑–æ–≤ log_request_body...")
            test_data = b'{"test": "buffered"}'
            logger.log_request_body(test_data)
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –ù–ï —Å–æ–∑–¥–∞–Ω...")
            assert not debug_dir.exists()
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –≤ –±—É—Ñ–µ—Ä–µ...")
            assert logger._request_body_buffer == test_data
    
    def test_flush_on_error_writes_buffers(self, tmp_path):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ flush_on_error –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –±—É—Ñ–µ—Ä—ã –≤ —Ñ–∞–π–ª—ã.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø—Ä–∏ –æ—à–∏–±–∫–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –†–µ–∂–∏–º errors, –∑–∞–ø–æ–ª–Ω—è–µ–º –±—É—Ñ–µ—Ä—ã...")
        debug_dir = tmp_path / "debug_logs"
        
        with patch('kiro_gateway.debug_logger.DEBUG_MODE', 'errors'):
            from kiro_gateway.debug_logger import DebugLogger
            logger = DebugLogger.__new__(DebugLogger)
            logger._initialized = False
            logger.__init__()
            logger.debug_dir = debug_dir
            
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –±—É—Ñ–µ—Ä—ã
            logger.log_request_body(b'{"request": "body"}')
            logger.log_kiro_request_body(b'{"kiro": "request"}')
            logger.log_raw_chunk(b'raw_chunk')
            logger.log_modified_chunk(b'modified_chunk')
            
            print("–î–µ–π—Å—Ç–≤–∏–µ: –í—ã–∑–æ–≤ flush_on_error...")
            logger.flush_on_error(400, "Bad Request")
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ —Ñ–∞–π–ª—ã —Å–æ–∑–¥–∞–Ω—ã...")
            assert (debug_dir / "request_body.json").exists()
            assert (debug_dir / "kiro_request_body.json").exists()
            assert (debug_dir / "response_stream_raw.txt").exists()
            assert (debug_dir / "response_stream_modified.txt").exists()
            assert (debug_dir / "error_info.json").exists()
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º error_info.json...")
            error_info = json.loads((debug_dir / "error_info.json").read_text())
            assert error_info["status_code"] == 400
            assert error_info["error_message"] == "Bad Request"
    
    def test_flush_on_error_clears_buffers(self, tmp_path):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ flush_on_error –æ—á–∏—â–∞–µ—Ç –±—É—Ñ–µ—Ä—ã –ø–æ—Å–ª–µ –∑–∞–ø–∏—Å–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –±—É—Ñ–µ—Ä—ã –Ω–µ –Ω–∞–∫–∞–ø–ª–∏–≤–∞—é—Ç—Å—è –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –†–µ–∂–∏–º errors...")
        debug_dir = tmp_path / "debug_logs"
        
        with patch('kiro_gateway.debug_logger.DEBUG_MODE', 'errors'):
            from kiro_gateway.debug_logger import DebugLogger
            logger = DebugLogger.__new__(DebugLogger)
            logger._initialized = False
            logger.__init__()
            logger.debug_dir = debug_dir
            
            logger.log_request_body(b'{"test": "data"}')
            
            print("–î–µ–π—Å—Ç–≤–∏–µ: –í—ã–∑–æ–≤ flush_on_error...")
            logger.flush_on_error(500, "Error")
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –±—É—Ñ–µ—Ä—ã –æ—á–∏—â–µ–Ω—ã...")
            assert logger._request_body_buffer is None
            assert logger._kiro_request_body_buffer is None
            assert len(logger._raw_chunks_buffer) == 0
            assert len(logger._modified_chunks_buffer) == 0
    
    def test_discard_buffers_clears_without_writing(self, tmp_path):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ discard_buffers –æ—á–∏—â–∞–µ—Ç –±—É—Ñ–µ—Ä—ã –±–µ–∑ –∑–∞–ø–∏—Å–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —É—Å–ø–µ—à–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –Ω–µ –æ—Å—Ç–∞–≤–ª—è—é—Ç –ª–æ–≥–æ–≤.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –†–µ–∂–∏–º errors, –∑–∞–ø–æ–ª–Ω—è–µ–º –±—É—Ñ–µ—Ä—ã...")
        debug_dir = tmp_path / "debug_logs"
        
        with patch('kiro_gateway.debug_logger.DEBUG_MODE', 'errors'):
            from kiro_gateway.debug_logger import DebugLogger
            logger = DebugLogger.__new__(DebugLogger)
            logger._initialized = False
            logger.__init__()
            logger.debug_dir = debug_dir
            
            logger.log_request_body(b'{"test": "data"}')
            logger.log_raw_chunk(b'chunk')
            
            print("–î–µ–π—Å—Ç–≤–∏–µ: –í—ã–∑–æ–≤ discard_buffers...")
            logger.discard_buffers()
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ù–ï —Å–æ–∑–¥–∞–Ω–∞...")
            assert not debug_dir.exists()
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –±—É—Ñ–µ—Ä—ã –æ—á–∏—â–µ–Ω—ã...")
            assert logger._request_body_buffer is None
            assert len(logger._raw_chunks_buffer) == 0
    
    def test_flush_on_error_writes_error_info_in_mode_all(self, tmp_path):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ flush_on_error –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç error_info.json –≤ —Ä–µ–∂–∏–º–µ all.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ—à–∏–±–∫–µ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ –æ–±–æ–∏—Ö —Ä–µ–∂–∏–º–∞—Ö.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –†–µ–∂–∏–º all...")
        debug_dir = tmp_path / "debug_logs"
        
        with patch('kiro_gateway.debug_logger.DEBUG_MODE', 'all'):
            from kiro_gateway.debug_logger import DebugLogger
            logger = DebugLogger.__new__(DebugLogger)
            logger._initialized = False
            logger.__init__()
            logger.debug_dir = debug_dir
            
            print("–î–µ–π—Å—Ç–≤–∏–µ: –í—ã–∑–æ–≤ flush_on_error...")
            logger.flush_on_error(400, "Bad Request")
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ error_info.json —Å–æ–∑–¥–∞–Ω...")
            assert (debug_dir / "error_info.json").exists()
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ error_info.json...")
            error_info = json.loads((debug_dir / "error_info.json").read_text())
            assert error_info["status_code"] == 400
            assert error_info["error_message"] == "Bad Request"


class TestDebugLoggerLogErrorInfo:
    """–¢–µ—Å—Ç—ã –¥–ª—è –º–µ—Ç–æ–¥–∞ log_error_info()."""
    
    def test_log_error_info_writes_in_mode_all(self, tmp_path):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ log_error_info –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Ñ–∞–π–ª –≤ —Ä–µ–∂–∏–º–µ all.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ error_info.json —Å–æ–∑–¥–∞—ë—Ç—Å—è –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –†–µ–∂–∏–º all...")
        debug_dir = tmp_path / "debug_logs"
        
        with patch('kiro_gateway.debug_logger.DEBUG_MODE', 'all'):
            from kiro_gateway.debug_logger import DebugLogger
            logger = DebugLogger.__new__(DebugLogger)
            logger._initialized = False
            logger.__init__()
            logger.debug_dir = debug_dir
            
            print("–î–µ–π—Å—Ç–≤–∏–µ: –í—ã–∑–æ–≤ log_error_info...")
            logger.log_error_info(500, "Internal Server Error")
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ error_info.json —Å–æ–∑–¥–∞–Ω...")
            error_file = debug_dir / "error_info.json"
            assert error_file.exists()
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ...")
            error_info = json.loads(error_file.read_text())
            assert error_info["status_code"] == 500
            assert error_info["error_message"] == "Internal Server Error"
    
    def test_log_error_info_writes_in_mode_errors(self, tmp_path):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ log_error_info –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Ñ–∞–π–ª –≤ —Ä–µ–∂–∏–º–µ errors.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –º–µ—Ç–æ–¥ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ –æ–±–æ–∏—Ö —Ä–µ–∂–∏–º–∞—Ö.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –†–µ–∂–∏–º errors...")
        debug_dir = tmp_path / "debug_logs"
        
        with patch('kiro_gateway.debug_logger.DEBUG_MODE', 'errors'):
            from kiro_gateway.debug_logger import DebugLogger
            logger = DebugLogger.__new__(DebugLogger)
            logger._initialized = False
            logger.__init__()
            logger.debug_dir = debug_dir
            
            print("–î–µ–π—Å—Ç–≤–∏–µ: –í—ã–∑–æ–≤ log_error_info...")
            logger.log_error_info(404, "Not Found")
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ error_info.json —Å–æ–∑–¥–∞–Ω...")
            error_file = debug_dir / "error_info.json"
            assert error_file.exists()
    
    def test_log_error_info_does_nothing_in_mode_off(self, tmp_path):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ log_error_info –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ—Ç –≤ —Ä–µ–∂–∏–º–µ off.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤ —Ä–µ–∂–∏–º–µ off —Ñ–∞–π–ª—ã –Ω–µ —Å–æ–∑–¥–∞—é—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –†–µ–∂–∏–º off...")
        debug_dir = tmp_path / "debug_logs"
        
        with patch('kiro_gateway.debug_logger.DEBUG_MODE', 'off'):
            from kiro_gateway.debug_logger import DebugLogger
            logger = DebugLogger.__new__(DebugLogger)
            logger._initialized = False
            logger.__init__()
            logger.debug_dir = debug_dir
            
            print("–î–µ–π—Å—Ç–≤–∏–µ: –í—ã–∑–æ–≤ log_error_info...")
            logger.log_error_info(500, "Error")
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ù–ï —Å–æ–∑–¥–∞–Ω–∞...")
            assert not debug_dir.exists()


class TestDebugLoggerHelperMethods:
    """–¢–µ—Å—Ç—ã –¥–ª—è –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ DebugLogger."""
    
    def test_is_enabled_returns_true_for_errors(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç _is_enabled() –¥–ª—è —Ä–µ–∂–∏–º–∞ errors.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Ä–µ–∂–∏–º errors —Å—á–∏—Ç–∞–µ—Ç—Å—è –≤–∫–ª—é—á—ë–Ω–Ω—ã–º.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –†–µ–∂–∏–º errors...")
        with patch('kiro_gateway.debug_logger.DEBUG_MODE', 'errors'):
            from kiro_gateway.debug_logger import DebugLogger
            logger = DebugLogger.__new__(DebugLogger)
            logger._initialized = False
            logger.__init__()
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º _is_enabled()...")
            assert logger._is_enabled() is True
    
    def test_is_enabled_returns_true_for_all(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç _is_enabled() –¥–ª—è —Ä–µ–∂–∏–º–∞ all.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Ä–µ–∂–∏–º all —Å—á–∏—Ç–∞–µ—Ç—Å—è –≤–∫–ª—é—á—ë–Ω–Ω—ã–º.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –†–µ–∂–∏–º all...")
        with patch('kiro_gateway.debug_logger.DEBUG_MODE', 'all'):
            from kiro_gateway.debug_logger import DebugLogger
            logger = DebugLogger.__new__(DebugLogger)
            logger._initialized = False
            logger.__init__()
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º _is_enabled()...")
            assert logger._is_enabled() is True
    
    def test_is_enabled_returns_false_for_off(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç _is_enabled() –¥–ª—è —Ä–µ–∂–∏–º–∞ off.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Ä–µ–∂–∏–º off —Å—á–∏—Ç–∞–µ—Ç—Å—è –≤—ã–∫–ª—é—á–µ–Ω–Ω—ã–º.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –†–µ–∂–∏–º off...")
        with patch('kiro_gateway.debug_logger.DEBUG_MODE', 'off'):
            from kiro_gateway.debug_logger import DebugLogger
            logger = DebugLogger.__new__(DebugLogger)
            logger._initialized = False
            logger.__init__()
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º _is_enabled()...")
            assert logger._is_enabled() is False
    
    def test_is_immediate_write_returns_true_for_all(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç _is_immediate_write() –¥–ª—è —Ä–µ–∂–∏–º–∞ all.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Ä–µ–∂–∏–º all –ø–∏—à–µ—Ç —Å—Ä–∞–∑—É.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –†–µ–∂–∏–º all...")
        with patch('kiro_gateway.debug_logger.DEBUG_MODE', 'all'):
            from kiro_gateway.debug_logger import DebugLogger
            logger = DebugLogger.__new__(DebugLogger)
            logger._initialized = False
            logger.__init__()
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º _is_immediate_write()...")
            assert logger._is_immediate_write() is True
    
    def test_is_immediate_write_returns_false_for_errors(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç _is_immediate_write() –¥–ª—è —Ä–µ–∂–∏–º–∞ errors.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Ä–µ–∂–∏–º errors –±—É—Ñ–µ—Ä–∏–∑—É–µ—Ç.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –†–µ–∂–∏–º errors...")
        with patch('kiro_gateway.debug_logger.DEBUG_MODE', 'errors'):
            from kiro_gateway.debug_logger import DebugLogger
            logger = DebugLogger.__new__(DebugLogger)
            logger._initialized = False
            logger.__init__()
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º _is_immediate_write()...")
            assert logger._is_immediate_write() is False


class TestDebugLoggerJsonHandling:
    """–¢–µ—Å—Ç—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ JSON –≤ DebugLogger."""
    
    def test_log_request_body_formats_json_pretty(self, tmp_path):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ JSON —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç—Å—è –∫—Ä–∞—Å–∏–≤–æ.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ JSON —á–∏—Ç–∞–µ–º –≤ —Ñ–∞–π–ª–µ.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –†–µ–∂–∏–º all...")
        debug_dir = tmp_path / "debug_logs"
        debug_dir.mkdir()
        
        with patch('kiro_gateway.debug_logger.DEBUG_MODE', 'all'):
            from kiro_gateway.debug_logger import DebugLogger
            logger = DebugLogger.__new__(DebugLogger)
            logger._initialized = False
            logger.__init__()
            logger.debug_dir = debug_dir
            
            print("–î–µ–π—Å—Ç–≤–∏–µ: –í—ã–∑–æ–≤ log_request_body —Å JSON...")
            logger.log_request_body(b'{"key":"value"}')
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ...")
            content = (debug_dir / "request_body.json").read_text()
            # –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω —Å –æ—Ç—Å—Ç—É–ø–∞–º–∏
            assert "  " in content or "\n" in content
    
    def test_log_request_body_handles_invalid_json(self, tmp_path):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –Ω–µ–≤–∞–ª–∏–¥–Ω–æ–≥–æ JSON.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è –∫–∞–∫ –µ—Å—Ç—å.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –†–µ–∂–∏–º all...")
        debug_dir = tmp_path / "debug_logs"
        debug_dir.mkdir()
        
        with patch('kiro_gateway.debug_logger.DEBUG_MODE', 'all'):
            from kiro_gateway.debug_logger import DebugLogger
            logger = DebugLogger.__new__(DebugLogger)
            logger._initialized = False
            logger.__init__()
            logger.debug_dir = debug_dir
            
            print("–î–µ–π—Å—Ç–≤–∏–µ: –í—ã–∑–æ–≤ log_request_body —Å –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–º JSON...")
            invalid_data = b'not a json {{'
            logger.log_request_body(invalid_data)
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∞–Ω—ã –∫–∞–∫ –µ—Å—Ç—å...")
            content = (debug_dir / "request_body.json").read_bytes()
            assert content == invalid_data


class TestDebugLoggerAppLogsCapture:
    """–¢–µ—Å—Ç—ã –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –ª–æ–≥–æ–≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è (app_logs.txt)."""
    
    def test_prepare_new_request_sets_up_log_capture(self, tmp_path):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ prepare_new_request –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –∑–∞—Ö–≤–∞—Ç –ª–æ–≥–æ–≤.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ sink –¥–ª—è –ª–æ–≥–æ–≤ —Å–æ–∑–¥–∞—ë—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –†–µ–∂–∏–º all...")
        debug_dir = tmp_path / "debug_logs"
        
        with patch('kiro_gateway.debug_logger.DEBUG_MODE', 'all'):
            from kiro_gateway.debug_logger import DebugLogger
            dbg_logger = DebugLogger.__new__(DebugLogger)
            dbg_logger._initialized = False
            dbg_logger.__init__()
            dbg_logger.debug_dir = debug_dir
            
            print("–î–µ–π—Å—Ç–≤–∏–µ: –í—ã–∑–æ–≤ prepare_new_request...")
            dbg_logger.prepare_new_request()
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ sink —Å–æ–∑–¥–∞–Ω...")
            assert dbg_logger._loguru_sink_id is not None
            
            # –û—á–∏—Å—Ç–∫–∞
            dbg_logger._clear_app_logs_buffer()
    
    def test_flush_on_error_writes_app_logs_in_mode_errors(self, tmp_path):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ flush_on_error –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç app_logs.txt –≤ —Ä–µ–∂–∏–º–µ errors.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ª–æ–≥–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –†–µ–∂–∏–º errors...")
        debug_dir = tmp_path / "debug_logs"
        
        with patch('kiro_gateway.debug_logger.DEBUG_MODE', 'errors'):
            from kiro_gateway.debug_logger import DebugLogger
            from loguru import logger as loguru_logger
            
            dbg_logger = DebugLogger.__new__(DebugLogger)
            dbg_logger._initialized = False
            dbg_logger.__init__()
            dbg_logger.debug_dir = debug_dir
            
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∑–∞—Ö–≤–∞—Ç –ª–æ–≥–æ–≤
            dbg_logger.prepare_new_request()
            
            # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –±—É—Ñ–µ—Ä —á—Ç–æ–±—ã flush —Å—Ä–∞–±–æ—Ç–∞–ª
            dbg_logger.log_request_body(b'{"test": "data"}')
            
            # –ü–∏—à–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –ª–æ–≥ –Ω–∞–ø—Ä—è–º—É—é –≤ –±—É—Ñ–µ—Ä (–∏–º–∏—Ç–∞—Ü–∏—è)
            dbg_logger._app_logs_buffer.write("Test log message\n")
            
            print("–î–µ–π—Å—Ç–≤–∏–µ: –í—ã–∑–æ–≤ flush_on_error...")
            dbg_logger.flush_on_error(500, "Test Error")
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ app_logs.txt —Å–æ–∑–¥–∞–Ω...")
            app_logs_file = debug_dir / "app_logs.txt"
            assert app_logs_file.exists()
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ...")
            content = app_logs_file.read_text()
            assert "Test log message" in content
    
    def test_discard_buffers_saves_logs_in_mode_all(self, tmp_path):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ discard_buffers —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ª–æ–≥–∏ –≤ —Ä–µ–∂–∏–º–µ all.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –¥–∞–∂–µ —É—Å–ø–µ—à–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç –ª–æ–≥–∏ –≤ —Ä–µ–∂–∏–º–µ all.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –†–µ–∂–∏–º all...")
        debug_dir = tmp_path / "debug_logs"
        debug_dir.mkdir()
        
        with patch('kiro_gateway.debug_logger.DEBUG_MODE', 'all'):
            from kiro_gateway.debug_logger import DebugLogger
            
            dbg_logger = DebugLogger.__new__(DebugLogger)
            dbg_logger._initialized = False
            dbg_logger.__init__()
            dbg_logger.debug_dir = debug_dir
            
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∑–∞—Ö–≤–∞—Ç –ª–æ–≥–æ–≤
            dbg_logger.prepare_new_request()
            
            # –ü–∏—à–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –ª–æ–≥ –Ω–∞–ø—Ä—è–º—É—é –≤ –±—É—Ñ–µ—Ä
            dbg_logger._app_logs_buffer.write("Success log message\n")
            
            print("–î–µ–π—Å—Ç–≤–∏–µ: –í—ã–∑–æ–≤ discard_buffers...")
            dbg_logger.discard_buffers()
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ app_logs.txt —Å–æ–∑–¥–∞–Ω...")
            app_logs_file = debug_dir / "app_logs.txt"
            assert app_logs_file.exists()
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ...")
            content = app_logs_file.read_text()
            assert "Success log message" in content
    
    def test_discard_buffers_does_not_save_logs_in_mode_errors(self, tmp_path):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ discard_buffers –ù–ï —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ª–æ–≥–∏ –≤ —Ä–µ–∂–∏–º–µ errors.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —É—Å–ø–µ—à–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –Ω–µ –æ—Å—Ç–∞–≤–ª—è—é—Ç –ª–æ–≥–æ–≤ –≤ —Ä–µ–∂–∏–º–µ errors.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –†–µ–∂–∏–º errors...")
        debug_dir = tmp_path / "debug_logs"
        
        with patch('kiro_gateway.debug_logger.DEBUG_MODE', 'errors'):
            from kiro_gateway.debug_logger import DebugLogger
            
            dbg_logger = DebugLogger.__new__(DebugLogger)
            dbg_logger._initialized = False
            dbg_logger.__init__()
            dbg_logger.debug_dir = debug_dir
            
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∑–∞—Ö–≤–∞—Ç –ª–æ–≥–æ–≤
            dbg_logger.prepare_new_request()
            
            # –ü–∏—à–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –ª–æ–≥ –Ω–∞–ø—Ä—è–º—É—é –≤ –±—É—Ñ–µ—Ä
            dbg_logger._app_logs_buffer.write("Should not be saved\n")
            
            print("–î–µ–π—Å—Ç–≤–∏–µ: –í—ã–∑–æ–≤ discard_buffers...")
            dbg_logger.discard_buffers()
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ù–ï —Å–æ–∑–¥–∞–Ω–∞...")
            assert not debug_dir.exists()
    
    def test_clear_app_logs_buffer_removes_sink(self, tmp_path):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ _clear_app_logs_buffer —É–¥–∞–ª—è–µ—Ç sink.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ sink –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —É–¥–∞–ª—è–µ—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –†–µ–∂–∏–º all...")
        with patch('kiro_gateway.debug_logger.DEBUG_MODE', 'all'):
            from kiro_gateway.debug_logger import DebugLogger
            
            dbg_logger = DebugLogger.__new__(DebugLogger)
            dbg_logger._initialized = False
            dbg_logger.__init__()
            dbg_logger.debug_dir = tmp_path / "debug_logs"
            
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∑–∞—Ö–≤–∞—Ç –ª–æ–≥–æ–≤
            dbg_logger.prepare_new_request()
            sink_id = dbg_logger._loguru_sink_id
            assert sink_id is not None
            
            print("–î–µ–π—Å—Ç–≤–∏–µ: –í—ã–∑–æ–≤ _clear_app_logs_buffer...")
            dbg_logger._clear_app_logs_buffer()
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ sink_id —Å–±—Ä–æ—à–µ–Ω...")
            assert dbg_logger._loguru_sink_id is None
    
    def test_app_logs_not_saved_when_empty(self, tmp_path):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –ø—É—Å—Ç—ã–µ –ª–æ–≥–∏ –Ω–µ —Å–æ–∑–¥–∞—é—Ç —Ñ–∞–π–ª.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ app_logs.txt –Ω–µ —Å–æ–∑–¥–∞—ë—Ç—Å—è –µ—Å–ª–∏ –ª–æ–≥–æ–≤ –Ω–µ—Ç.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –†–µ–∂–∏–º all...")
        debug_dir = tmp_path / "debug_logs"
        debug_dir.mkdir()
        
        with patch('kiro_gateway.debug_logger.DEBUG_MODE', 'all'):
            from kiro_gateway.debug_logger import DebugLogger
            
            dbg_logger = DebugLogger.__new__(DebugLogger)
            dbg_logger._initialized = False
            dbg_logger.__init__()
            dbg_logger.debug_dir = debug_dir
            
            # –ù–ï –ø–∏—à–µ–º –Ω–∏—á–µ–≥–æ –≤ –±—É—Ñ–µ—Ä
            
            print("–î–µ–π—Å—Ç–≤–∏–µ: –í—ã–∑–æ–≤ _write_app_logs_to_file...")
            dbg_logger._write_app_logs_to_file()
            
            print(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ app_logs.txt –ù–ï —Å–æ–∑–¥–∞–Ω...")
            app_logs_file = debug_dir / "app_logs.txt"
            assert not app_logs_file.exists()


================================================
FILE: tests/unit/test_http_client.py
================================================
# -*- coding: utf-8 -*-

"""
Unit tests for KiroHttpClient.
Tests retry logic, error handling, and HTTP client management.
"""

import asyncio
import pytest
from unittest.mock import AsyncMock, Mock, patch, MagicMock
from datetime import datetime, timezone, timedelta

import httpx
from fastapi import HTTPException

from kiro_gateway.http_client import KiroHttpClient
from kiro_gateway.auth import KiroAuthManager
from kiro_gateway.config import MAX_RETRIES, BASE_RETRY_DELAY, FIRST_TOKEN_MAX_RETRIES, STREAMING_READ_TIMEOUT


@pytest.fixture
def mock_auth_manager_for_http():
    """Creates a mocked KiroAuthManager for HTTP client tests."""
    manager = Mock(spec=KiroAuthManager)
    manager.get_access_token = AsyncMock(return_value="test_access_token")
    manager.force_refresh = AsyncMock(return_value="new_access_token")
    manager.fingerprint = "test_fingerprint_12345678"
    manager._fingerprint = "test_fingerprint_12345678"
    return manager


class TestKiroHttpClientInitialization:
    """Tests for KiroHttpClient initialization."""
    
    def test_initialization_stores_auth_manager(self, mock_auth_manager_for_http):
        """
        What it does: Verifies auth_manager is stored during initialization.
        Purpose: Ensure auth_manager is available for obtaining tokens.
        """
        print("Setup: Creating KiroHttpClient...")
        client = KiroHttpClient(mock_auth_manager_for_http)
        
        print("Verification: auth_manager is stored...")
        assert client.auth_manager is mock_auth_manager_for_http
    
    def test_initialization_client_is_none(self, mock_auth_manager_for_http):
        """
        What it does: Verifies that HTTP client is initially None.
        Purpose: Ensure lazy initialization.
        """
        print("Setup: Creating KiroHttpClient...")
        client = KiroHttpClient(mock_auth_manager_for_http)
        
        print("Verification: client is initially None...")
        assert client.client is None


class TestKiroHttpClientGetClient:
    """Tests for _get_client method."""
    
    @pytest.mark.asyncio
    async def test_get_client_creates_new_client(self, mock_auth_manager_for_http):
        """
        What it does: Verifies creation of a new HTTP client.
        Purpose: Ensure client is created on first call.
        """
        print("Setup: Creating KiroHttpClient...")
        http_client = KiroHttpClient(mock_auth_manager_for_http)
        
        print("Action: Getting client...")
        with patch('kiro_gateway.http_client.httpx.AsyncClient') as mock_async_client:
            mock_instance = AsyncMock()
            mock_instance.is_closed = False
            mock_async_client.return_value = mock_instance
            
            client = await http_client._get_client()
            
            print("Verification: Client created...")
            mock_async_client.assert_called_once()
            assert client is mock_instance
    
    @pytest.mark.asyncio
    async def test_get_client_reuses_existing_client(self, mock_auth_manager_for_http):
        """
        What it does: Verifies reuse of existing client.
        Purpose: Ensure client is not recreated unnecessarily.
        """
        print("Setup: Creating KiroHttpClient with existing client...")
        http_client = KiroHttpClient(mock_auth_manager_for_http)
        
        mock_existing = AsyncMock()
        mock_existing.is_closed = False
        http_client.client = mock_existing
        
        print("Action: Getting client...")
        client = await http_client._get_client()
        
        print("Verification: Existing client returned...")
        assert client is mock_existing
    
    @pytest.mark.asyncio
    async def test_get_client_recreates_closed_client(self, mock_auth_manager_for_http):
        """
        What it does: Verifies recreation of closed client.
        Purpose: Ensure closed client is replaced with a new one.
        """
        print("Setup: Creating KiroHttpClient with closed client...")
        http_client = KiroHttpClient(mock_auth_manager_for_http)
        
        mock_closed = AsyncMock()
        mock_closed.is_closed = True
        http_client.client = mock_closed
        
        print("Action: Getting client...")
        with patch('kiro_gateway.http_client.httpx.AsyncClient') as mock_async_client:
            mock_new = AsyncMock()
            mock_new.is_closed = False
            mock_async_client.return_value = mock_new
            
            client = await http_client._get_client()
            
            print("Verification: New client created...")
            mock_async_client.assert_called_once()
            assert client is mock_new


class TestKiroHttpClientClose:
    """Tests for close method."""
    
    @pytest.mark.asyncio
    async def test_close_closes_client(self, mock_auth_manager_for_http):
        """
        What it does: Verifies HTTP client closure.
        Purpose: Ensure aclose() is called.
        """
        print("Setup: Creating KiroHttpClient with client...")
        http_client = KiroHttpClient(mock_auth_manager_for_http)
        
        mock_client = AsyncMock()
        mock_client.is_closed = False
        mock_client.aclose = AsyncMock()
        http_client.client = mock_client
        
        print("Action: Closing client...")
        await http_client.close()
        
        print("Verification: aclose() called...")
        mock_client.aclose.assert_called_once()
    
    @pytest.mark.asyncio
    async def test_close_does_nothing_for_none_client(self, mock_auth_manager_for_http):
        """
        What it does: Verifies that close() doesn't fail for None client.
        Purpose: Ensure safe close() call without client.
        """
        print("Setup: Creating KiroHttpClient without client...")
        http_client = KiroHttpClient(mock_auth_manager_for_http)
        
        print("Action: Closing client...")
        await http_client.close()  # Should not raise an error
        
        print("Verification: No errors...")
    
    @pytest.mark.asyncio
    async def test_close_does_nothing_for_closed_client(self, mock_auth_manager_for_http):
        """
        What it does: Verifies that close() doesn't fail for closed client.
        Purpose: Ensure safe repeated close() call.
        """
        print("Setup: Creating KiroHttpClient with closed client...")
        http_client = KiroHttpClient(mock_auth_manager_for_http)
        
        mock_client = AsyncMock()
        mock_client.is_closed = True
        http_client.client = mock_client
        
        print("Action: Closing client...")
        await http_client.close()
        
        print("Verification: aclose() NOT called...")
        mock_client.aclose.assert_not_called()


class TestKiroHttpClientRequestWithRetry:
    """Tests for request_with_retry method."""
    
    @pytest.mark.asyncio
    async def test_successful_request_returns_response(self, mock_auth_manager_for_http):
        """
        What it does: Verifies successful request.
        Purpose: Ensure 200 response is returned immediately.
        """
        print("Setup: Creating KiroHttpClient...")
        http_client = KiroHttpClient(mock_auth_manager_for_http)
        
        mock_response = AsyncMock()
        mock_response.status_code = 200
        
        mock_client = AsyncMock()
        mock_client.is_closed = False
        mock_client.request = AsyncMock(return_value=mock_response)
        
        print("Action: Executing request...")
        with patch.object(http_client, '_get_client', return_value=mock_client):
            with patch('kiro_gateway.http_client.get_kiro_headers', return_value={}):
                response = await http_client.request_with_retry(
                    "POST",
                    "https://api.example.com/test",
                    {"data": "value"}
                )
        
        print("Verification: Response received...")
        assert response.status_code == 200
        mock_client.request.assert_called_once()
    
    @pytest.mark.asyncio
    async def test_403_triggers_token_refresh(self, mock_auth_manager_for_http):
        """
        What it does: Verifies token refresh on 403.
        Purpose: Ensure force_refresh() is called on 403.
        """
        print("Setup: Creating KiroHttpClient...")
        http_client = KiroHttpClient(mock_auth_manager_for_http)
        
        mock_response_403 = AsyncMock()
        mock_response_403.status_code = 403
        
        mock_response_200 = AsyncMock()
        mock_response_200.status_code = 200
        
        mock_client = AsyncMock()
        mock_client.is_closed = False
        mock_client.request = AsyncMock(side_effect=[mock_response_403, mock_response_200])
        
        print("Action: Executing request...")
        with patch.object(http_client, '_get_client', return_value=mock_client):
            with patch('kiro_gateway.http_client.get_kiro_headers', return_value={}):
                response = await http_client.request_with_retry(
                    "POST",
                    "https://api.example.com/test",
                    {"data": "value"}
                )
        
        print("Verification: force_refresh() called...")
        mock_auth_manager_for_http.force_refresh.assert_called_once()
        assert response.status_code == 200
    
    @pytest.mark.asyncio
    async def test_429_triggers_backoff(self, mock_auth_manager_for_http):
        """
        What it does: Verifies exponential backoff on 429.
        Purpose: Ensure request is retried after delay.
        """
        print("Setup: Creating KiroHttpClient...")
        http_client = KiroHttpClient(mock_auth_manager_for_http)
        
        mock_response_429 = AsyncMock()
        mock_response_429.status_code = 429
        
        mock_response_200 = AsyncMock()
        mock_response_200.status_code = 200
        
        mock_client = AsyncMock()
        mock_client.is_closed = False
        mock_client.request = AsyncMock(side_effect=[mock_response_429, mock_response_200])
        
        print("Action: Executing request...")
        with patch.object(http_client, '_get_client', return_value=mock_client):
            with patch('kiro_gateway.http_client.get_kiro_headers', return_value={}):
                with patch('kiro_gateway.http_client.asyncio.sleep', new_callable=AsyncMock) as mock_sleep:
                    response = await http_client.request_with_retry(
                        "POST",
                        "https://api.example.com/test",
                        {"data": "value"}
                    )
        
        print("Verification: sleep() called for backoff...")
        mock_sleep.assert_called_once()
        assert response.status_code == 200
    
    @pytest.mark.asyncio
    async def test_5xx_triggers_backoff(self, mock_auth_manager_for_http):
        """
        What it does: Verifies exponential backoff on 5xx.
        Purpose: Ensure server errors are handled with retry.
        """
        print("Setup: Creating KiroHttpClient...")
        http_client = KiroHttpClient(mock_auth_manager_for_http)
        
        mock_response_500 = AsyncMock()
        mock_response_500.status_code = 500
        
        mock_response_200 = AsyncMock()
        mock_response_200.status_code = 200
        
        mock_client = AsyncMock()
        mock_client.is_closed = False
        mock_client.request = AsyncMock(side_effect=[mock_response_500, mock_response_200])
        
        print("Action: Executing request...")
        with patch.object(http_client, '_get_client', return_value=mock_client):
            with patch('kiro_gateway.http_client.get_kiro_headers', return_value={}):
                with patch('kiro_gateway.http_client.asyncio.sleep', new_callable=AsyncMock) as mock_sleep:
                    response = await http_client.request_with_retry(
                        "POST",
                        "https://api.example.com/test",
                        {"data": "value"}
                    )
        
        print("Verification: sleep() called for backoff...")
        mock_sleep.assert_called_once()
        assert response.status_code == 200
    
    @pytest.mark.asyncio
    async def test_timeout_triggers_backoff(self, mock_auth_manager_for_http):
        """
        What it does: Verifies exponential backoff on timeout.
        Purpose: Ensure timeouts are handled with retry.
        """
        print("Setup: Creating KiroHttpClient...")
        http_client = KiroHttpClient(mock_auth_manager_for_http)
        
        mock_response_200 = AsyncMock()
        mock_response_200.status_code = 200
        
        mock_client = AsyncMock()
        mock_client.is_closed = False
        mock_client.request = AsyncMock(side_effect=[
            httpx.TimeoutException("Timeout"),
            mock_response_200
        ])
        
        print("Action: Executing request...")
        with patch.object(http_client, '_get_client', return_value=mock_client):
            with patch('kiro_gateway.http_client.get_kiro_headers', return_value={}):
                with patch('kiro_gateway.http_client.asyncio.sleep', new_callable=AsyncMock) as mock_sleep:
                    response = await http_client.request_with_retry(
                        "POST",
                        "https://api.example.com/test",
                        {"data": "value"}
                    )
        
        print("Verification: sleep() called for backoff...")
        mock_sleep.assert_called_once()
        assert response.status_code == 200
    
    @pytest.mark.asyncio
    async def test_request_error_triggers_backoff(self, mock_auth_manager_for_http):
        """
        What it does: Verifies exponential backoff on request error.
        Purpose: Ensure network errors are handled with retry.
        """
        print("Setup: Creating KiroHttpClient...")
        http_client = KiroHttpClient(mock_auth_manager_for_http)
        
        mock_response_200 = AsyncMock()
        mock_response_200.status_code = 200
        
        mock_client = AsyncMock()
        mock_client.is_closed = False
        mock_client.request = AsyncMock(side_effect=[
            httpx.RequestError("Connection error"),
            mock_response_200
        ])
        
        print("Action: Executing request...")
        with patch.object(http_client, '_get_client', return_value=mock_client):
            with patch('kiro_gateway.http_client.get_kiro_headers', return_value={}):
                with patch('kiro_gateway.http_client.asyncio.sleep', new_callable=AsyncMock) as mock_sleep:
                    response = await http_client.request_with_retry(
                        "POST",
                        "https://api.example.com/test",
                        {"data": "value"}
                    )
        
        print("Verification: sleep() called for backoff...")
        mock_sleep.assert_called_once()
        assert response.status_code == 200
    
    @pytest.mark.asyncio
    async def test_max_retries_exceeded_raises_502(self, mock_auth_manager_for_http):
        """
        What it does: Verifies HTTPException is raised after exhausting retries.
        Purpose: Ensure 502 is raised after MAX_RETRIES.
        """
        print("Setup: Creating KiroHttpClient...")
        http_client = KiroHttpClient(mock_auth_manager_for_http)
        
        mock_client = AsyncMock()
        mock_client.is_closed = False
        mock_client.request = AsyncMock(side_effect=httpx.TimeoutException("Timeout"))
        
        print("Action: Executing request...")
        with patch.object(http_client, '_get_client', return_value=mock_client):
            with patch('kiro_gateway.http_client.get_kiro_headers', return_value={}):
                with patch('kiro_gateway.http_client.asyncio.sleep', new_callable=AsyncMock):
                    with pytest.raises(HTTPException) as exc_info:
                        await http_client.request_with_retry(
                            "POST",
                            "https://api.example.com/test",
                            {"data": "value"}
                        )
        
        print(f"Verification: HTTPException with code 502...")
        assert exc_info.value.status_code == 502
        assert str(MAX_RETRIES) in exc_info.value.detail
    
    @pytest.mark.asyncio
    async def test_other_status_codes_returned_as_is(self, mock_auth_manager_for_http):
        """
        What it does: Verifies other status codes are returned without retry.
        Purpose: Ensure 400, 404, etc. are returned immediately.
        """
        print("Setup: Creating KiroHttpClient...")
        http_client = KiroHttpClient(mock_auth_manager_for_http)
        
        mock_response = AsyncMock()
        mock_response.status_code = 400
        
        mock_client = AsyncMock()
        mock_client.is_closed = False
        mock_client.request = AsyncMock(return_value=mock_response)
        
        print("Action: Executing request...")
        with patch.object(http_client, '_get_client', return_value=mock_client):
            with patch('kiro_gateway.http_client.get_kiro_headers', return_value={}):
                response = await http_client.request_with_retry(
                    "POST",
                    "https://api.example.com/test",
                    {"data": "value"}
                )
        
        print("Verification: 400 response returned without retry...")
        assert response.status_code == 400
        mock_client.request.assert_called_once()
    
    @pytest.mark.asyncio
    async def test_streaming_request_uses_send(self, mock_auth_manager_for_http):
        """
        What it does: Verifies send() is used for streaming.
        Purpose: Ensure stream=True uses build_request + send.
        """
        print("Setup: Creating KiroHttpClient...")
        http_client = KiroHttpClient(mock_auth_manager_for_http)
        
        mock_response = AsyncMock()
        mock_response.status_code = 200
        
        mock_request = Mock()
        
        mock_client = AsyncMock()
        mock_client.is_closed = False
        mock_client.build_request = Mock(return_value=mock_request)
        mock_client.send = AsyncMock(return_value=mock_response)
        
        print("Action: Executing streaming request...")
        with patch.object(http_client, '_get_client', return_value=mock_client):
            with patch('kiro_gateway.http_client.get_kiro_headers', return_value={}):
                response = await http_client.request_with_retry(
                    "POST",
                    "https://api.example.com/test",
                    {"data": "value"},
                    stream=True
                )
        
        print("Verification: build_request and send called...")
        mock_client.build_request.assert_called_once()
        mock_client.send.assert_called_once_with(mock_request, stream=True)
        assert response.status_code == 200


class TestKiroHttpClientContextManager:
    """Tests for async context manager."""
    
    @pytest.mark.asyncio
    async def test_context_manager_returns_self(self, mock_auth_manager_for_http):
        """
        What it does: Verifies that __aenter__ returns self.
        Purpose: Ensure correct async with behavior.
        """
        print("Setup: Creating KiroHttpClient...")
        http_client = KiroHttpClient(mock_auth_manager_for_http)
        
        print("Action: Entering context...")
        result = await http_client.__aenter__()
        
        print("Verification: self returned...")
        assert result is http_client
    
    @pytest.mark.asyncio
    async def test_context_manager_closes_on_exit(self, mock_auth_manager_for_http):
        """
        What it does: Verifies client closure on context exit.
        Purpose: Ensure close() is called in __aexit__.
        """
        print("Setup: Creating KiroHttpClient...")
        http_client = KiroHttpClient(mock_auth_manager_for_http)
        
        mock_client = AsyncMock()
        mock_client.is_closed = False
        mock_client.aclose = AsyncMock()
        http_client.client = mock_client
        
        print("Action: Exiting context...")
        await http_client.__aexit__(None, None, None)
        
        print("Verification: aclose() called...")
        mock_client.aclose.assert_called_once()


class TestKiroHttpClientExponentialBackoff:
    """Tests for exponential backoff logic."""
    
    @pytest.mark.asyncio
    async def test_backoff_delay_increases_exponentially(self, mock_auth_manager_for_http):
        """
        What it does: Verifies exponential delay increase.
        Purpose: Ensure delay = BASE_RETRY_DELAY * (2 ** attempt).
        """
        print("Setup: Creating KiroHttpClient...")
        http_client = KiroHttpClient(mock_auth_manager_for_http)
        
        mock_response_429 = AsyncMock()
        mock_response_429.status_code = 429
        
        mock_response_200 = AsyncMock()
        mock_response_200.status_code = 200
        
        mock_client = AsyncMock()
        mock_client.is_closed = False
        # 2 errors 429, then success (to verify 2 backoff delays)
        mock_client.request = AsyncMock(side_effect=[
            mock_response_429,
            mock_response_429,
            mock_response_200
        ])
        
        sleep_delays = []
        
        async def capture_sleep(delay):
            sleep_delays.append(delay)
        
        print("Action: Executing request with multiple retries...")
        with patch.object(http_client, '_get_client', return_value=mock_client):
            with patch('kiro_gateway.http_client.get_kiro_headers', return_value={}):
                with patch('kiro_gateway.http_client.asyncio.sleep', side_effect=capture_sleep):
                    response = await http_client.request_with_retry(
                        "POST",
                        "https://api.example.com/test",
                        {"data": "value"}
                    )
        
        print(f"Verification: Delays increase exponentially...")
        print(f"Delays: {sleep_delays}")
        assert len(sleep_delays) == 2
        assert sleep_delays[0] == BASE_RETRY_DELAY * (2 ** 0)  # 1.0
        assert sleep_delays[1] == BASE_RETRY_DELAY * (2 ** 1)  # 2.0


class TestKiroHttpClientStreamingTimeout:
    """Tests for streaming request timeout logic."""
    
    @pytest.mark.asyncio
    async def test_streaming_uses_streaming_read_timeout(self, mock_auth_manager_for_http):
        """
        What it does: Verifies that streaming requests use STREAMING_READ_TIMEOUT.
        Purpose: Ensure stream=True uses httpx.Timeout with correct values.
        """
        print("Setup: Creating KiroHttpClient...")
        http_client = KiroHttpClient(mock_auth_manager_for_http)
        
        mock_response = AsyncMock()
        mock_response.status_code = 200
        
        mock_request = Mock()
        
        mock_client = AsyncMock()
        mock_client.is_closed = False
        mock_client.build_request = Mock(return_value=mock_request)
        mock_client.send = AsyncMock(return_value=mock_response)
        
        print("Action: Executing streaming request...")
        with patch('kiro_gateway.http_client.httpx.AsyncClient') as mock_async_client:
            mock_async_client.return_value = mock_client
            
            with patch('kiro_gateway.http_client.get_kiro_headers', return_value={}):
                response = await http_client.request_with_retry(
                    "POST",
                    "https://api.example.com/test",
                    {"data": "value"},
                    stream=True
                )
        
        print("Verification: AsyncClient created with httpx.Timeout for streaming...")
        call_args = mock_async_client.call_args
        timeout_arg = call_args.kwargs.get('timeout')
        assert timeout_arg is not None, f"timeout not found in call_args: {call_args}"
        print(f"Comparing connect: Expected 30.0, Got {timeout_arg.connect}")
        assert timeout_arg.connect == 30.0, f"Expected connect=30.0, got {timeout_arg.connect}"
        print(f"Comparing read: Expected {STREAMING_READ_TIMEOUT}, Got {timeout_arg.read}")
        assert timeout_arg.read == STREAMING_READ_TIMEOUT, f"Expected read={STREAMING_READ_TIMEOUT}, got {timeout_arg.read}"
        assert call_args.kwargs.get('follow_redirects') == True
        assert response.status_code == 200
    
    @pytest.mark.asyncio
    async def test_streaming_uses_first_token_max_retries(self, mock_auth_manager_for_http):
        """
        What it does: Verifies that streaming requests use FIRST_TOKEN_MAX_RETRIES.
        Purpose: Ensure stream=True uses separate retry counter.
        """
        print("Setup: Creating KiroHttpClient...")
        http_client = KiroHttpClient(mock_auth_manager_for_http)
        
        mock_request = Mock()
        
        mock_client = AsyncMock()
        mock_client.is_closed = False
        mock_client.build_request = Mock(return_value=mock_request)
        mock_client.send = AsyncMock(side_effect=httpx.TimeoutException("Timeout"))
        
        print("Action: Executing streaming request with timeouts...")
        with patch('kiro_gateway.http_client.httpx.AsyncClient', return_value=mock_client):
            with patch('kiro_gateway.http_client.get_kiro_headers', return_value={}):
                with pytest.raises(HTTPException) as exc_info:
                    await http_client.request_with_retry(
                        "POST",
                        "https://api.example.com/test",
                        {"data": "value"},
                        stream=True
                    )
        
        print(f"Verification: HTTPException with code 504...")
        assert exc_info.value.status_code == 504
        assert str(FIRST_TOKEN_MAX_RETRIES) in exc_info.value.detail
        
        print(f"Verification: Attempt count = FIRST_TOKEN_MAX_RETRIES ({FIRST_TOKEN_MAX_RETRIES})...")
        assert mock_client.send.call_count == FIRST_TOKEN_MAX_RETRIES
    
    @pytest.mark.asyncio
    async def test_streaming_timeout_retry_without_delay(self, mock_auth_manager_for_http):
        """
        What it does: Verifies that streaming timeout retry happens without delay.
        Purpose: Ensure no exponential backoff on first token timeout.
        """
        print("Setup: Creating KiroHttpClient...")
        http_client = KiroHttpClient(mock_auth_manager_for_http)
        
        mock_response = AsyncMock()
        mock_response.status_code = 200
        
        mock_request = Mock()
        
        mock_client = AsyncMock()
        mock_client.is_closed = False
        mock_client.build_request = Mock(return_value=mock_request)
        # First timeout, then success
        mock_client.send = AsyncMock(side_effect=[
            httpx.TimeoutException("Timeout"),
            mock_response
        ])
        
        sleep_called = False
        
        async def capture_sleep(delay):
            nonlocal sleep_called
            sleep_called = True
        
        print("Action: Executing streaming request with one timeout...")
        with patch('kiro_gateway.http_client.httpx.AsyncClient', return_value=mock_client):
            with patch('kiro_gateway.http_client.get_kiro_headers', return_value={}):
                with patch('kiro_gateway.http_client.asyncio.sleep', side_effect=capture_sleep):
                    response = await http_client.request_with_retry(
                        "POST",
                        "https://api.example.com/test",
                        {"data": "value"},
                        stream=True
                    )
        
        print("Verification: sleep() NOT called for streaming timeout...")
        assert not sleep_called
        assert response.status_code == 200
        
    @pytest.mark.asyncio
    async def test_non_streaming_uses_default_timeout(self, mock_auth_manager_for_http):
        """
        What it does: Verifies that non-streaming requests use 300 seconds.
        Purpose: Ensure stream=False uses unified httpx.Timeout.
        """
        print("Setup: Creating KiroHttpClient...")
        http_client = KiroHttpClient(mock_auth_manager_for_http)
        
        mock_response = AsyncMock()
        mock_response.status_code = 200
        
        mock_client = AsyncMock()
        mock_client.is_closed = False
        mock_client.request = AsyncMock(return_value=mock_response)
        
        print("Action: Executing non-streaming request...")
        with patch('kiro_gateway.http_client.httpx.AsyncClient') as mock_async_client:
            mock_async_client.return_value = mock_client
            
            with patch('kiro_gateway.http_client.get_kiro_headers', return_value={}):
                response = await http_client.request_with_retry(
                    "POST",
                    "https://api.example.com/test",
                    {"data": "value"},
                    stream=False
                )
        
        print("Verification: AsyncClient created with httpx.Timeout(timeout=300)...")
        call_args = mock_async_client.call_args
        timeout_arg = call_args.kwargs.get('timeout')
        assert timeout_arg is not None, f"timeout not found in call_args: {call_args}"
        # httpx.Timeout(timeout=300) sets all timeouts to 300
        print(f"Comparing timeout: Expected 300.0 for all, Got connect={timeout_arg.connect}")
        assert timeout_arg.connect == 300.0
        assert timeout_arg.read == 300.0
        assert response.status_code == 200
    
    @pytest.mark.asyncio
    async def test_connect_timeout_logged_correctly(self, mock_auth_manager_for_http):
        """
        What it does: Verifies ConnectTimeout logging.
        Purpose: Ensure ConnectTimeout is logged with correct type.
        """
        print("Setup: Creating KiroHttpClient...")
        http_client = KiroHttpClient(mock_auth_manager_for_http)
        
        mock_response = AsyncMock()
        mock_response.status_code = 200
        
        mock_request = Mock()
        
        mock_client = AsyncMock()
        mock_client.is_closed = False
        mock_client.build_request = Mock(return_value=mock_request)
        # First ConnectTimeout, then success
        mock_client.send = AsyncMock(side_effect=[
            httpx.ConnectTimeout("Connection timeout"),
            mock_response
        ])
        
        print("Action: Executing streaming request with ConnectTimeout...")
        with patch('kiro_gateway.http_client.httpx.AsyncClient', return_value=mock_client):
            with patch('kiro_gateway.http_client.get_kiro_headers', return_value={}):
                with patch('kiro_gateway.http_client.logger') as mock_logger:
                    response = await http_client.request_with_retry(
                        "POST",
                        "https://api.example.com/test",
                        {"data": "value"},
                        stream=True
                    )
        
        print("Verification: logger.warning called with [ConnectTimeout]...")
        warning_calls = [str(call) for call in mock_logger.warning.call_args_list]
        assert any("ConnectTimeout" in call for call in warning_calls), f"ConnectTimeout not found in: {warning_calls}"
        assert response.status_code == 200
    
    @pytest.mark.asyncio
    async def test_read_timeout_logged_correctly(self, mock_auth_manager_for_http):
        """
        What it does: Verifies ReadTimeout logging.
        Purpose: Ensure ReadTimeout is logged with STREAMING_READ_TIMEOUT.
        """
        print("Setup: Creating KiroHttpClient...")
        http_client = KiroHttpClient(mock_auth_manager_for_http)
        
        mock_response = AsyncMock()
        mock_response.status_code = 200
        
        mock_request = Mock()
        
        mock_client = AsyncMock()
        mock_client.is_closed = False
        mock_client.build_request = Mock(return_value=mock_request)
        # First ReadTimeout, then success
        mock_client.send = AsyncMock(side_effect=[
            httpx.ReadTimeout("Read timeout"),
            mock_response
        ])
        
        print("Action: Executing streaming request with ReadTimeout...")
        with patch('kiro_gateway.http_client.httpx.AsyncClient', return_value=mock_client):
            with patch('kiro_gateway.http_client.get_kiro_headers', return_value={}):
                with patch('kiro_gateway.http_client.logger') as mock_logger:
                    response = await http_client.request_with_retry(
                        "POST",
                        "https://api.example.com/test",
                        {"data": "value"},
                        stream=True
                    )
        
        print("Verification: logger.warning called with [ReadTimeout] and STREAMING_READ_TIMEOUT...")
        warning_calls = [str(call) for call in mock_logger.warning.call_args_list]
        assert any("ReadTimeout" in call for call in warning_calls), f"ReadTimeout not found in: {warning_calls}"
        assert any(str(STREAMING_READ_TIMEOUT) in call for call in warning_calls), f"STREAMING_READ_TIMEOUT not found in: {warning_calls}"
        assert response.status_code == 200
    
    @pytest.mark.asyncio
    async def test_streaming_timeout_returns_504_with_error_type(self, mock_auth_manager_for_http):
        """
        What it does: Verifies that streaming timeout returns 504 with error type.
        Purpose: Ensure 504 is returned with error info after exhausting retries.
        """
        print("Setup: Creating KiroHttpClient...")
        http_client = KiroHttpClient(mock_auth_manager_for_http)
        
        mock_request = Mock()
        
        mock_client = AsyncMock()
        mock_client.is_closed = False
        mock_client.build_request = Mock(return_value=mock_request)
        mock_client.send = AsyncMock(side_effect=httpx.ReadTimeout("Timeout"))
        
        print("Action: Executing streaming request with persistent timeouts...")
        with patch('kiro_gateway.http_client.httpx.AsyncClient', return_value=mock_client):
            with patch('kiro_gateway.http_client.get_kiro_headers', return_value={}):
                with pytest.raises(HTTPException) as exc_info:
                    await http_client.request_with_retry(
                        "POST",
                        "https://api.example.com/test",
                        {"data": "value"},
                        stream=True
                    )
        
        print("Verification: HTTPException with code 504 and error type...")
        print(f"Comparing status_code: Expected 504, Got {exc_info.value.status_code}")
        assert exc_info.value.status_code == 504
        print(f"Comparing detail: Expected 'ReadTimeout' in '{exc_info.value.detail}'")
        assert "ReadTimeout" in exc_info.value.detail
        assert "Streaming failed" in exc_info.value.detail
    
    @pytest.mark.asyncio
    async def test_non_streaming_timeout_returns_502(self, mock_auth_manager_for_http):
        """
        What it does: Verifies that non-streaming timeout returns 502.
        Purpose: Ensure non-streaming uses legacy logic with 502.
        """
        print("Setup: Creating KiroHttpClient...")
        http_client = KiroHttpClient(mock_auth_manager_for_http)
        
        mock_client = AsyncMock()
        mock_client.is_closed = False
        mock_client.request = AsyncMock(side_effect=httpx.TimeoutException("Timeout"))
        
        print("Action: Executing non-streaming request with persistent timeouts...")
        with patch('kiro_gateway.http_client.httpx.AsyncClient', return_value=mock_client):
            with patch('kiro_gateway.http_client.get_kiro_headers', return_value={}):
                with patch('kiro_gateway.http_client.asyncio.sleep', new_callable=AsyncMock):
                    with pytest.raises(HTTPException) as exc_info:
                        await http_client.request_with_retry(
                            "POST",
                            "https://api.example.com/test",
                            {"data": "value"},
                            stream=False
                        )
        
        print("Verification: HTTPException with code 502...")
        assert exc_info.value.status_code == 502


================================================
FILE: tests/unit/test_parsers.py
================================================
# -*- coding: utf-8 -*-

"""
Unit-—Ç–µ—Å—Ç—ã –¥–ª—è AwsEventStreamParser –∏ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π –ø–∞—Ä—Å–∏–Ω–≥–∞.
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ª–æ–≥–∏–∫—É –ø–∞—Ä—Å–∏–Ω–≥–∞ AWS SSE –ø–æ—Ç–æ–∫–∞ –æ—Ç Kiro API.
"""

import pytest

from kiro_gateway.parsers import (
    AwsEventStreamParser,
    find_matching_brace,
    parse_bracket_tool_calls,
    deduplicate_tool_calls
)


class TestFindMatchingBrace:
    """–¢–µ—Å—Ç—ã —Ñ—É–Ω–∫—Ü–∏–∏ find_matching_brace."""
    
    def test_simple_json_object(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–∏—Å–∫ –∑–∞–∫—Ä—ã–≤–∞—é—â–µ–π —Å–∫–æ–±–∫–∏ –¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ JSON.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –±–∞–∑–æ–≤—ã–π —Å–ª—É—á–∞–π —Ä–∞–±–æ—Ç–∞–µ—Ç.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ü—Ä–æ—Å—Ç–æ–π JSON –æ–±—ä–µ–∫—Ç...")
        text = '{"key": "value"}'
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ–∏—Å–∫ –∑–∞–∫—Ä—ã–≤–∞—é—â–µ–π —Å–∫–æ–±–∫–∏...")
        result = find_matching_brace(text, 0)
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å 15, –ü–æ–ª—É—á–µ–Ω–æ {result}")
        assert result == 15
    
    def test_nested_json_object(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–∏—Å–∫ –¥–ª—è –≤–ª–æ–∂–µ–Ω–Ω–æ–≥–æ JSON.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç—å –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –í–ª–æ–∂–µ–Ω–Ω—ã–π JSON –æ–±—ä–µ–∫—Ç...")
        text = '{"outer": {"inner": "value"}}'
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ–∏—Å–∫ –∑–∞–∫—Ä—ã–≤–∞—é—â–µ–π —Å–∫–æ–±–∫–∏...")
        result = find_matching_brace(text, 0)
        
        # –î–ª–∏–Ω–∞ —Å—Ç—Ä–æ–∫–∏ 29, –∏–Ω–¥–µ–∫—Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–∏–º–≤–æ–ª–∞ 28
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å 28, –ü–æ–ª—É—á–µ–Ω–æ {result}")
        assert result == 28
    
    def test_json_with_braces_in_string(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∫–æ–±–æ–∫ –≤–Ω—É—Ç—Ä–∏ —Å—Ç—Ä–æ–∫.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Å–∫–æ–±–∫–∏ –≤ —Å—Ç—Ä–æ–∫–∞—Ö –Ω–µ –≤–ª–∏—è—é—Ç –Ω–∞ –ø–æ–¥—Å—á—ë—Ç.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: JSON —Å–æ —Å–∫–æ–±–∫–∞–º–∏ –≤ —Å—Ç—Ä–æ–∫–µ...")
        text = '{"text": "Hello {world}"}'
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ–∏—Å–∫ –∑–∞–∫—Ä—ã–≤–∞—é—â–µ–π —Å–∫–æ–±–∫–∏...")
        result = find_matching_brace(text, 0)
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å 24, –ü–æ–ª—É—á–µ–Ω–æ {result}")
        assert result == 24
    
    def test_json_with_escaped_quotes(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–∞–≤—ã—á–µ–∫.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ escape-–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –Ω–µ –ª–æ–º–∞—é—Ç –ø–∞—Ä—Å–∏–Ω–≥.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: JSON —Å —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∫–∞–≤—ã—á–∫–∞–º–∏...")
        text = '{"text": "Say \\"hello\\""}'
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ–∏—Å–∫ –∑–∞–∫—Ä—ã–≤–∞—é—â–µ–π —Å–∫–æ–±–∫–∏...")
        result = find_matching_brace(text, 0)
        
        # –î–ª–∏–Ω–∞ —Å—Ç—Ä–æ–∫–∏ 25, –∏–Ω–¥–µ–∫—Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–∏–º–≤–æ–ª–∞ 24
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å 24, –ü–æ–ª—É—á–µ–Ω–æ {result}")
        assert result == 24
    
    def test_incomplete_json(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –Ω–µ–∑–∞–≤–µ—Ä—à—ë–Ω–Ω–æ–≥–æ JSON.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è -1 –¥–ª—è –Ω–µ–ø–æ–ª–Ω–æ–≥–æ JSON.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ù–µ–∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã–π JSON...")
        text = '{"key": "value"'
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ–∏—Å–∫ –∑–∞–∫—Ä—ã–≤–∞—é—â–µ–π —Å–∫–æ–±–∫–∏...")
        result = find_matching_brace(text, 0)
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å -1, –ü–æ–ª—É—á–µ–Ω–æ {result}")
        assert result == -1
    
    def test_invalid_start_position(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –Ω–µ–≤–∞–ª–∏–¥–Ω–æ–π —Å—Ç–∞—Ä—Ç–æ–≤–æ–π –ø–æ–∑–∏—Ü–∏–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è -1 –µ—Å–ª–∏ start_pos –Ω–µ –Ω–∞ '{'.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –¢–µ–∫—Å—Ç –±–µ–∑ —Å–∫–æ–±–∫–∏ –Ω–∞ start_pos...")
        text = 'hello {"key": "value"}'
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ–∏—Å–∫ —Å –ø–æ–∑–∏—Ü–∏–∏ 0 (–Ω–µ —Å–∫–æ–±–∫–∞)...")
        result = find_matching_brace(text, 0)
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å -1, –ü–æ–ª—É—á–µ–Ω–æ {result}")
        assert result == -1
    
    def test_start_position_out_of_bounds(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –ø–æ–∑–∏—Ü–∏–∏ –∑–∞ –ø—Ä–µ–¥–µ–ª–∞–º–∏ —Ç–µ–∫—Å—Ç–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è -1 –¥–ª—è –Ω–µ–≤–∞–ª–∏–¥–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ö–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç...")
        text = '{"a":1}'
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ–∏—Å–∫ —Å –ø–æ–∑–∏—Ü–∏–∏ 100...")
        result = find_matching_brace(text, 100)
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å -1, –ü–æ–ª—É—á–µ–Ω–æ {result}")
        assert result == -1


class TestParseBracketToolCalls:
    """–¢–µ—Å—Ç—ã —Ñ—É–Ω–∫—Ü–∏–∏ parse_bracket_tool_calls."""
    
    def test_parses_single_tool_call(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ tool call.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ bracket-style tool call –∏–∑–≤–ª–µ–∫–∞–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –¢–µ–∫—Å—Ç —Å –æ–¥–Ω–∏–º tool call...")
        text = '[Called get_weather with args: {"location": "Moscow"}]'
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–∞—Ä—Å–∏–Ω–≥ tool calls...")
        result = parse_bracket_tool_calls(text)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        assert len(result) == 1
        assert result[0]["function"]["name"] == "get_weather"
        assert '"location"' in result[0]["function"]["arguments"]
    
    def test_parses_multiple_tool_calls(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö tool calls.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤—Å–µ tool calls –∏–∑–≤–ª–µ–∫–∞—é—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –¢–µ–∫—Å—Ç —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ tool calls...")
        text = '''
        [Called get_weather with args: {"location": "Moscow"}]
        Some text in between
        [Called get_time with args: {"timezone": "UTC"}]
        '''
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–∞—Ä—Å–∏–Ω–≥ tool calls...")
        result = parse_bracket_tool_calls(text)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        assert len(result) == 2
        assert result[0]["function"]["name"] == "get_weather"
        assert result[1]["function"]["name"] == "get_time"
    
    def test_returns_empty_for_no_tool_calls(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–æ–∑–≤—Ä–∞—Ç –ø—É—Å—Ç–æ–≥–æ —Å–ø–∏—Å–∫–∞ –±–µ–∑ tool calls.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–µ –ø–∞—Ä—Å–∏—Ç—Å—è –∫–∞–∫ tool call.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –û–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ tool calls...")
        text = "This is just regular text without any tool calls."
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–∞—Ä—Å–∏–Ω–≥ tool calls...")
        result = parse_bracket_tool_calls(text)
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å [], –ü–æ–ª—É—á–µ–Ω–æ {result}")
        assert result == []
    
    def test_returns_empty_for_empty_string(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –Ω–µ –≤—ã–∑—ã–≤–∞–µ—Ç –æ—à–∏–±–æ–∫.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞...")
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–∞—Ä—Å–∏–Ω–≥ tool calls...")
        result = parse_bracket_tool_calls("")
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å [], –ü–æ–ª—É—á–µ–Ω–æ {result}")
        assert result == []
    
    def test_returns_empty_for_none(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É None.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ None –Ω–µ –≤—ã–∑—ã–≤–∞–µ—Ç –æ—à–∏–±–æ–∫.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: None...")
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–∞—Ä—Å–∏–Ω–≥ tool calls...")
        result = parse_bracket_tool_calls(None)
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å [], –ü–æ–ª—É—á–µ–Ω–æ {result}")
        assert result == []
    
    def test_handles_nested_json_in_args(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥ –≤–ª–æ–∂–µ–Ω–Ω–æ–≥–æ JSON –≤ –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ö.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Å–ª–æ–∂–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –ø–∞—Ä—Å—è—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Tool call —Å –≤–ª–æ–∂–µ–Ω–Ω—ã–º JSON...")
        text = '[Called complex_func with args: {"data": {"nested": {"deep": "value"}}}]'
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–∞—Ä—Å–∏–Ω–≥ tool calls...")
        result = parse_bracket_tool_calls(text)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        assert len(result) == 1
        assert result[0]["function"]["name"] == "complex_func"
        assert "nested" in result[0]["function"]["arguments"]
    
    def test_generates_unique_ids(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö ID –¥–ª—è tool calls.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –∫–∞–∂–¥—ã–π tool call –∏–º–µ–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –î–≤–∞ –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö tool calls...")
        text = '''
        [Called func with args: {"a": 1}]
        [Called func with args: {"a": 1}]
        '''
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–∞—Ä—Å–∏–Ω–≥ tool calls...")
        result = parse_bracket_tool_calls(text)
        
        print(f"IDs: {[r['id'] for r in result]}")
        assert len(result) == 2
        assert result[0]["id"] != result[1]["id"]


class TestDeduplicateToolCalls:
    """–¢–µ—Å—Ç—ã —Ñ—É–Ω–∫—Ü–∏–∏ deduplicate_tool_calls."""
    
    def test_removes_duplicates(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —É–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ tool calls —É–¥–∞–ª—è—é—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–ø–∏—Å–æ–∫ —Å –¥—É–±–ª–∏–∫–∞—Ç–∞–º–∏...")
        tool_calls = [
            {"id": "1", "function": {"name": "func", "arguments": '{"a": 1}'}},
            {"id": "2", "function": {"name": "func", "arguments": '{"a": 1}'}},
            {"id": "3", "function": {"name": "other", "arguments": '{"b": 2}'}},
        ]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è...")
        result = deduplicate_tool_calls(tool_calls)
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –¥–ª–∏–Ω—É: –û–∂–∏–¥–∞–ª–æ—Å—å 2, –ü–æ–ª—É—á–µ–Ω–æ {len(result)}")
        assert len(result) == 2
    
    def test_preserves_first_occurrence(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–µ—Ä–≤–æ–≥–æ –≤—Ö–æ–∂–¥–µ–Ω–∏—è.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –ø–µ—Ä–≤—ã–π tool call –∏–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–ø–∏—Å–æ–∫ —Å –¥—É–±–ª–∏–∫–∞—Ç–∞–º–∏...")
        tool_calls = [
            {"id": "first", "function": {"name": "func", "arguments": '{"a": 1}'}},
            {"id": "second", "function": {"name": "func", "arguments": '{"a": 1}'}},
        ]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è...")
        result = deduplicate_tool_calls(tool_calls)
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º ID: –û–∂–∏–¥–∞–ª–æ—Å—å 'first', –ü–æ–ª—É—á–µ–Ω–æ '{result[0]['id']}'")
        assert result[0]["id"] == "first"
    
    def test_handles_empty_list(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –ø—É—Å—Ç–æ–≥–æ —Å–ø–∏—Å–∫–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –Ω–µ –≤—ã–∑—ã–≤–∞–µ—Ç –æ—à–∏–±–æ–∫.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫...")
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è...")
        result = deduplicate_tool_calls([])
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å [], –ü–æ–ª—É—á–µ–Ω–æ {result}")
        assert result == []
    
    def test_deduplicates_by_id_keeps_one_with_arguments(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—é –ø–æ id —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º tool call —Å –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø—Ä–∏ –¥—É–±–ª–∏–∫–∞—Ç–∞—Ö –ø–æ id —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è —Ç–æ—Ç, —É –∫–æ—Ç–æ—Ä–æ–≥–æ –µ—Å—Ç—å –∞—Ä–≥—É–º–µ–Ω—Ç—ã.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –î–≤–∞ tool calls —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º id, –æ–¥–∏–Ω —Å –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏, –æ–¥–∏–Ω –ø—É—Å—Ç–æ–π...")
        tool_calls = [
            {"id": "call_123", "function": {"name": "func", "arguments": "{}"}},
            {"id": "call_123", "function": {"name": "func", "arguments": '{"location": "Moscow"}'}},
        ]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è...")
        result = deduplicate_tool_calls(tool_calls)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –¥–ª–∏–Ω—É: –û–∂–∏–¥–∞–ª–æ—Å—å 1, –ü–æ–ª—É—á–µ–Ω–æ {len(result)}")
        assert len(result) == 1
        
        print("–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å–æ—Ö—Ä–∞–Ω–∏–ª—Å—è tool call —Å –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏...")
        assert "Moscow" in result[0]["function"]["arguments"]
    
    def test_deduplicates_by_id_prefers_longer_arguments(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –ø—Ä–∏ –¥—É–±–ª–∏–∫–∞—Ç–∞—Ö –ø–æ id –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞—é—Ç—Å—è –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è tool call —Å –±–æ–ª–µ–µ –ø–æ–ª–Ω—ã–º–∏ –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –î–≤–∞ tool calls —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º id, —Ä–∞–∑–Ω–æ–π –¥–ª–∏–Ω—ã –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤...")
        tool_calls = [
            {"id": "call_abc", "function": {"name": "search", "arguments": '{"q": "test"}'}},
            {"id": "call_abc", "function": {"name": "search", "arguments": '{"q": "test", "limit": 10, "offset": 0}'}},
        ]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è...")
        result = deduplicate_tool_calls(tool_calls)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        assert len(result) == 1
        
        print("–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å–æ—Ö—Ä–∞–Ω–∏–ª—Å—è tool call —Å –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã–º–∏ –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏...")
        assert "limit" in result[0]["function"]["arguments"]
    
    def test_deduplicates_empty_arguments_replaced_by_non_empty(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∑–∞–º–µ–Ω—É –ø—É—Å—Ç—ã—Ö –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –Ω–∞ –Ω–µ–ø—É—Å—Ç—ã–µ.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ "{}" –∑–∞–º–µ–Ω—è–µ—Ç—Å—è –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ü–µ—Ä–≤—ã–π tool call —Å –ø—É—Å—Ç—ã–º–∏ –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏, –≤—Ç–æ—Ä–æ–π —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏...")
        tool_calls = [
            {"id": "call_xyz", "function": {"name": "get_weather", "arguments": "{}"}},
            {"id": "call_xyz", "function": {"name": "get_weather", "arguments": '{"city": "London"}'}},
        ]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è...")
        result = deduplicate_tool_calls(tool_calls)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        assert len(result) == 1
        assert result[0]["function"]["arguments"] == '{"city": "London"}'
    
    def test_handles_tool_calls_without_id(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É tool calls –±–µ–∑ id.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ tool calls –±–µ–∑ id –¥–µ–¥—É–ø–ª–∏—Ü–∏—Ä—É—é—Ç—Å—è –ø–æ name+arguments.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Tool calls –±–µ–∑ id...")
        tool_calls = [
            {"id": "", "function": {"name": "func", "arguments": '{"a": 1}'}},
            {"id": "", "function": {"name": "func", "arguments": '{"a": 1}'}},
            {"id": "", "function": {"name": "func", "arguments": '{"b": 2}'}},
        ]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è...")
        result = deduplicate_tool_calls(tool_calls)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        # –î–≤–∞ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ name+arguments
        assert len(result) == 2
    
    def test_mixed_with_and_without_id(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–º–µ—à–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å id –∏ –±–µ–∑.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –æ–±–∞ —Ç–∏–ø–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–º–µ—à–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫...")
        tool_calls = [
            {"id": "call_1", "function": {"name": "func1", "arguments": '{"x": 1}'}},
            {"id": "call_1", "function": {"name": "func1", "arguments": "{}"}},  # –î—É–±–ª–∏–∫–∞—Ç –ø–æ id
            {"id": "", "function": {"name": "func2", "arguments": '{"y": 2}'}},
            {"id": "", "function": {"name": "func2", "arguments": '{"y": 2}'}},  # –î—É–±–ª–∏–∫–∞—Ç –ø–æ name+args
        ]
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è...")
        result = deduplicate_tool_calls(tool_calls)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        # call_1 —Å –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏ + func2 –æ–¥–∏–Ω —Ä–∞–∑
        assert len(result) == 2
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ call_1 —Å–æ—Ö—Ä–∞–Ω–∏–ª –∞—Ä–≥—É–º–µ–Ω—Ç—ã
        call_1 = next(tc for tc in result if tc["id"] == "call_1")
        assert call_1["function"]["arguments"] == '{"x": 1}'


class TestAwsEventStreamParserInitialization:
    """–¢–µ—Å—Ç—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ AwsEventStreamParser."""
    
    def test_initialization_creates_empty_state(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞—á–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–∞—Ä—Å–µ—Ä–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø–∞—Ä—Å–µ—Ä —Å–æ–∑–¥–∞—ë—Ç—Å—è —Å –ø—É—Å—Ç—ã–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞—Ä—Å–µ—Ä–∞...")
        parser = AwsEventStreamParser()
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –ë—É—Ñ–µ—Ä –ø—É—Å—Ç...")
        assert parser.buffer == ""
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: last_content is None...")
        assert parser.last_content is None
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: current_tool_call is None...")
        assert parser.current_tool_call is None
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: tool_calls –ø—É—Å—Ç...")
        assert parser.tool_calls == []


class TestAwsEventStreamParserFeed:
    """–¢–µ—Å—Ç—ã –º–µ—Ç–æ–¥–∞ feed –ø–∞—Ä—Å–µ—Ä–∞."""
    
    def test_parses_content_event(self, aws_event_parser):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥ —Å–æ–±—ã—Ç–∏—è —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –∏–∑–≤–ª–µ–∫–∞–µ—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Chunk —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º...")
        chunk = b'{"content":"Hello World"}'
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–∞—Ä—Å–∏–Ω–≥ chunk...")
        events = aws_event_parser.feed(chunk)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {events}")
        assert len(events) == 1
        assert events[0]["type"] == "content"
        assert events[0]["data"] == "Hello World"
    
    def test_parses_multiple_content_events(self, aws_event_parser):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–æ–±—ã—Ç–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤—Å–µ —Å–æ–±—ã—Ç–∏—è –∏–∑–≤–ª–µ–∫–∞—é—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Chunk —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —Å–æ–±—ã—Ç–∏—è–º–∏...")
        chunk = b'{"content":"First"}{"content":"Second"}'
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–∞—Ä—Å–∏–Ω–≥ chunk...")
        events = aws_event_parser.feed(chunk)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {events}")
        assert len(events) == 2
        assert events[0]["data"] == "First"
        assert events[1]["data"] == "Second"
    
    def test_deduplicates_repeated_content(self, aws_event_parser):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—é –ø–æ–≤—Ç–æ—Ä—è—é—â–µ–≥–æ—Å—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–µ –¥—É–±–ª–∏—Ä—É–µ—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Chunks —Å –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–º—Å—è –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º...")
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–∞—Ä—Å–∏–Ω–≥ –ø–µ—Ä–≤–æ–≥–æ chunk...")
        events1 = aws_event_parser.feed(b'{"content":"Same"}')
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–∞—Ä—Å–∏–Ω–≥ –≤—Ç–æ—Ä–æ–≥–æ chunk —Å —Ç–µ–º –∂–µ –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º...")
        events2 = aws_event_parser.feed(b'{"content":"Same"}')
        
        print(f"–ü–µ—Ä–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {events1}")
        print(f"–í—Ç–æ—Ä–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {events2}")
        assert len(events1) == 1
        assert len(events2) == 0  # –î—É–±–ª–∏–∫–∞—Ç –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω
    
    def test_parses_usage_event(self, aws_event_parser):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥ —Å–æ–±—ã—Ç–∏—è usage.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ credits –∏–∑–≤–ª–µ–∫–∞–µ—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Chunk —Å usage...")
        chunk = b'{"usage":1.5}'
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–∞—Ä—Å–∏–Ω–≥ chunk...")
        events = aws_event_parser.feed(chunk)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {events}")
        assert len(events) == 1
        assert events[0]["type"] == "usage"
        assert events[0]["data"] == 1.5
    
    def test_parses_context_usage_event(self, aws_event_parser):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥ —Å–æ–±—ã—Ç–∏—è context_usage.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø—Ä–æ—Ü–µ–Ω—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑–≤–ª–µ–∫–∞–µ—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Chunk —Å context usage...")
        chunk = b'{"contextUsagePercentage":25.5}'
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–∞—Ä—Å–∏–Ω–≥ chunk...")
        events = aws_event_parser.feed(chunk)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {events}")
        assert len(events) == 1
        assert events[0]["type"] == "context_usage"
        assert events[0]["data"] == 25.5
    
    def test_handles_incomplete_json(self, aws_event_parser):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –Ω–µ–ø–æ–ª–Ω–æ–≥–æ JSON.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –Ω–µ–ø–æ–ª–Ω—ã–π JSON –±—É—Ñ–µ—Ä–∏–∑—É–µ—Ç—Å—è.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ù–µ–ø–æ–ª–Ω—ã–π chunk...")
        chunk = b'{"content":"Hel'
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–∞—Ä—Å–∏–Ω–≥ –Ω–µ–ø–æ–ª–Ω–æ–≥–æ chunk...")
        events = aws_event_parser.feed(chunk)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {events}")
        assert len(events) == 0  # –ù–∏—á–µ–≥–æ –Ω–µ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–æ
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –î–∞–Ω–Ω—ã–µ –≤ –±—É—Ñ–µ—Ä–µ...")
        assert 'content' in aws_event_parser.buffer
    
    def test_completes_json_across_chunks(self, aws_event_parser):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–±–æ—Ä–∫—É JSON –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö chunks.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ JSON —Å–æ–±–∏—Ä–∞–µ—Ç—Å—è –∏–∑ —á–∞—Å—Ç–µ–π.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ü–µ—Ä–≤–∞—è —á–∞—Å—Ç—å JSON...")
        events1 = aws_event_parser.feed(b'{"content":"Hel')
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –í—Ç–æ—Ä–∞—è —á–∞—Å—Ç—å JSON...")
        events2 = aws_event_parser.feed(b'lo World"}')
        
        print(f"–ü–µ—Ä–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {events1}")
        print(f"–í—Ç–æ—Ä–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {events2}")
        assert len(events1) == 0
        assert len(events2) == 1
        assert events2[0]["data"] == "Hello World"
    
    def test_decodes_escape_sequences(self, aws_event_parser):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ escape-–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ \\n –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç—Å—è –≤ —Ä–µ–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Chunk —Å escape-–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é...")
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç escape-–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        chunk = b'{"content":"Line1\\nLine2"}'
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–∞—Ä—Å–∏–Ω–≥ chunk...")
        events = aws_event_parser.feed(chunk)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {events}")
        assert len(events) == 1
        assert "\n" in events[0]["data"]
    def test_handles_invalid_bytes(self, aws_event_parser):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –Ω–µ–≤–∞–ª–∏–¥–Ω—ã—Ö –±–∞–π—Ç–æ–≤.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –ª–æ–º–∞—é—Ç –ø–∞—Ä—Å–µ—Ä.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ù–µ–≤–∞–ª–∏–¥–Ω—ã–µ –±–∞–π—Ç—ã...")
        chunk = b'\xff\xfe{"content":"test"}'
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–∞—Ä—Å–∏–Ω–≥ chunk...")
        events = aws_event_parser.feed(chunk)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {events}")
        # –ü–∞—Ä—Å–µ—Ä –¥–æ–ª–∂–µ–Ω –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Ä–∞–±–æ—Ç—É
        assert len(events) == 1


class TestAwsEventStreamParserToolCalls:
    """–¢–µ—Å—Ç—ã –ø–∞—Ä—Å–∏–Ω–≥–∞ tool calls."""
    
    def test_parses_tool_start_event(self, aws_event_parser):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥ –Ω–∞—á–∞–ª–∞ tool call.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ tool_start —Å–æ–∑–¥–∞—ë—Ç current_tool_call.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Chunk —Å –Ω–∞—á–∞–ª–æ–º tool call...")
        chunk = b'{"name":"get_weather","toolUseId":"call_123"}'
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–∞—Ä—Å–∏–Ω–≥ chunk...")
        events = aws_event_parser.feed(chunk)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {events}")
        print(f"current_tool_call: {aws_event_parser.current_tool_call}")
        
        # tool_start –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–æ–±—ã—Ç–∏–µ, –Ω–æ —Å–æ–∑–¥–∞—ë—Ç current_tool_call
        assert aws_event_parser.current_tool_call is not None
        assert aws_event_parser.current_tool_call["function"]["name"] == "get_weather"
    
    def test_parses_tool_input_event(self, aws_event_parser):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥ input –¥–ª—è tool call.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ input –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –∫ current_tool_call.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ù–∞—á–∞–ª–æ tool call...")
        aws_event_parser.feed(b'{"name":"func","toolUseId":"call_1"}')
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–∞—Ä—Å–∏–Ω–≥ input...")
        aws_event_parser.feed(b'{"input":"{\\"key\\": \\"value\\"}"}')
        
        print(f"current_tool_call: {aws_event_parser.current_tool_call}")
        assert '{"key": "value"}' in aws_event_parser.current_tool_call["function"]["arguments"]
    
    def test_parses_tool_stop_event(self, aws_event_parser):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ tool call.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ tool call –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –≤ —Å–ø–∏—Å–æ–∫.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ü–æ–ª–Ω—ã–π tool call...")
        aws_event_parser.feed(b'{"name":"func","toolUseId":"call_1"}')
        aws_event_parser.feed(b'{"input":"{}"}')
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–∞—Ä—Å–∏–Ω–≥ stop...")
        aws_event_parser.feed(b'{"stop":true}')
        
        print(f"tool_calls: {aws_event_parser.tool_calls}")
        assert len(aws_event_parser.tool_calls) == 1
        assert aws_event_parser.current_tool_call is None
    
    def test_get_tool_calls_returns_all(self, aws_event_parser):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö tool calls.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ get_tool_calls –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã–µ calls.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ù–µ—Å–∫–æ–ª—å–∫–æ tool calls...")
        aws_event_parser.feed(b'{"name":"func1","toolUseId":"call_1"}')
        aws_event_parser.feed(b'{"stop":true}')
        aws_event_parser.feed(b'{"name":"func2","toolUseId":"call_2"}')
        aws_event_parser.feed(b'{"stop":true}')
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ–ª—É—á–µ–Ω–∏–µ tool calls...")
        tool_calls = aws_event_parser.get_tool_calls()
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {tool_calls}")
        assert len(tool_calls) == 2
    
    def test_get_tool_calls_finalizes_current(self, aws_event_parser):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –Ω–µ–∑–∞–≤–µ—Ä—à—ë–Ω–Ω–æ–≥–æ tool call.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ get_tool_calls –∑–∞–≤–µ—Ä—à–∞–µ—Ç current_tool_call.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ù–µ–∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã–π tool call...")
        aws_event_parser.feed(b'{"name":"func","toolUseId":"call_1"}')
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–æ–ª—É—á–µ–Ω–∏–µ tool calls...")
        tool_calls = aws_event_parser.get_tool_calls()
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {tool_calls}")
        assert len(tool_calls) == 1
        assert aws_event_parser.current_tool_call is None


class TestAwsEventStreamParserReset:
    """–¢–µ—Å—Ç—ã –º–µ—Ç–æ–¥–∞ reset."""
    
    def test_reset_clears_state(self, aws_event_parser):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–±—Ä–æ—Å —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–∞—Ä—Å–µ—Ä–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ reset –æ—á–∏—â–∞–µ—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–∞—Ä—Å–µ—Ä–∞ –¥–∞–Ω–Ω—ã–º–∏...")
        aws_event_parser.feed(b'{"content":"test"}')
        aws_event_parser.feed(b'{"name":"func","toolUseId":"call_1"}')
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –°–±—Ä–æ—Å –ø–∞—Ä—Å–µ—Ä–∞...")
        aws_event_parser.reset()
        
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –í—Å–µ –¥–∞–Ω–Ω—ã–µ –æ—á–∏—â–µ–Ω—ã...")
        assert aws_event_parser.buffer == ""
        assert aws_event_parser.last_content is None
        assert aws_event_parser.current_tool_call is None
        assert aws_event_parser.tool_calls == []


class TestAwsEventStreamParserFinalizeToolCall:
    """–¢–µ—Å—Ç—ã –º–µ—Ç–æ–¥–∞ _finalize_tool_call –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ input."""
    
    def test_finalize_with_string_arguments(self, aws_event_parser):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—é tool call —Å–æ —Å—Ç—Ä–æ–∫–æ–≤—ã–º–∏ –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Å—Ç—Ä–æ–∫–∞ JSON –ø–∞—Ä—Å–∏—Ç—Å—è –∏ —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ—Ç—Å—è –æ–±—Ä–∞—Ç–Ω–æ.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Tool call —Å–æ —Å—Ç—Ä–æ–∫–æ–≤—ã–º–∏ –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏...")
        aws_event_parser.current_tool_call = {
            "id": "call_1",
            "type": "function",
            "function": {
                "name": "test_func",
                "arguments": '{"key": "value"}'
            }
        }
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è tool call...")
        aws_event_parser._finalize_tool_call()
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {aws_event_parser.tool_calls}")
        assert len(aws_event_parser.tool_calls) == 1
        assert aws_event_parser.tool_calls[0]["function"]["arguments"] == '{"key": "value"}'
    
    def test_finalize_with_dict_arguments(self, aws_event_parser):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—é tool call —Å dict –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ dict —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ—Ç—Å—è –≤ JSON —Å—Ç—Ä–æ–∫—É.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Tool call —Å dict –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏...")
        aws_event_parser.current_tool_call = {
            "id": "call_2",
            "type": "function",
            "function": {
                "name": "test_func",
                "arguments": {"location": "Moscow", "units": "celsius"}
            }
        }
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è tool call...")
        aws_event_parser._finalize_tool_call()
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {aws_event_parser.tool_calls}")
        assert len(aws_event_parser.tool_calls) == 1
        
        args = aws_event_parser.tool_calls[0]["function"]["arguments"]
        print(f"–ê—Ä–≥—É–º–µ–Ω—Ç—ã: {args}")
        assert isinstance(args, str)
        assert "Moscow" in args
        assert "celsius" in args
    
    def test_finalize_with_empty_string_arguments(self, aws_event_parser):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—é tool call —Å –ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–æ–π –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –∑–∞–º–µ–Ω—è–µ—Ç—Å—è –Ω–∞ "{}".
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Tool call —Å –ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–æ–π –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤...")
        aws_event_parser.current_tool_call = {
            "id": "call_3",
            "type": "function",
            "function": {
                "name": "test_func",
                "arguments": ""
            }
        }
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è tool call...")
        aws_event_parser._finalize_tool_call()
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {aws_event_parser.tool_calls}")
        assert len(aws_event_parser.tool_calls) == 1
        assert aws_event_parser.tool_calls[0]["function"]["arguments"] == "{}"
    
    def test_finalize_with_whitespace_only_arguments(self, aws_event_parser):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—é tool call —Å –ø—Ä–æ–±–µ–ª—å–Ω—ã–º–∏ –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Å—Ç—Ä–æ–∫–∞ –∏–∑ –ø—Ä–æ–±–µ–ª–æ–≤ –∑–∞–º–µ–Ω—è–µ—Ç—Å—è –Ω–∞ "{}".
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Tool call —Å –ø—Ä–æ–±–µ–ª—å–Ω—ã–º–∏ –∞—Ä–≥—É–º–µ–Ω—Ç–∞–º–∏...")
        aws_event_parser.current_tool_call = {
            "id": "call_4",
            "type": "function",
            "function": {
                "name": "test_func",
                "arguments": "   "
            }
        }
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è tool call...")
        aws_event_parser._finalize_tool_call()
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {aws_event_parser.tool_calls}")
        assert len(aws_event_parser.tool_calls) == 1
        assert aws_event_parser.tool_calls[0]["function"]["arguments"] == "{}"
    
    def test_finalize_with_invalid_json_arguments(self, aws_event_parser):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—é tool call —Å –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–º JSON.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON –∑–∞–º–µ–Ω—è–µ—Ç—Å—è –Ω–∞ "{}".
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Tool call —Å –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–º JSON...")
        aws_event_parser.current_tool_call = {
            "id": "call_5",
            "type": "function",
            "function": {
                "name": "test_func",
                "arguments": "not valid json {"
            }
        }
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è tool call...")
        aws_event_parser._finalize_tool_call()
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {aws_event_parser.tool_calls}")
        assert len(aws_event_parser.tool_calls) == 1
        assert aws_event_parser.tool_calls[0]["function"]["arguments"] == "{}"
    
    def test_finalize_with_none_current_tool_call(self, aws_event_parser):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—é –∫–æ–≥–¥–∞ current_tool_call is None.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –Ω–∏—á–µ–≥–æ –Ω–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø—Ä–∏ None.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: current_tool_call = None...")
        aws_event_parser.current_tool_call = None
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è tool call...")
        aws_event_parser._finalize_tool_call()
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {aws_event_parser.tool_calls}")
        assert len(aws_event_parser.tool_calls) == 0
    
    def test_finalize_clears_current_tool_call(self, aws_event_parser):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è –æ—á–∏—â–∞–µ—Ç current_tool_call.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø–æ—Å–ª–µ —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ current_tool_call = None.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Tool call...")
        aws_event_parser.current_tool_call = {
            "id": "call_6",
            "type": "function",
            "function": {
                "name": "test_func",
                "arguments": "{}"
            }
        }
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è tool call...")
        aws_event_parser._finalize_tool_call()
        
        print(f"current_tool_call –ø–æ—Å–ª–µ —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏: {aws_event_parser.current_tool_call}")
        assert aws_event_parser.current_tool_call is None


class TestAwsEventStreamParserEdgeCases:
    """–¢–µ—Å—Ç—ã –≥—Ä–∞–Ω–∏—á–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤."""
    
    def test_handles_followup_prompt(self, aws_event_parser):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ followupPrompt.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ followupPrompt –Ω–µ —Å–æ–∑–¥–∞—ë—Ç —Å–æ–±—ã—Ç–∏–µ.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Chunk —Å followupPrompt...")
        chunk = b'{"content":"text","followupPrompt":"suggestion"}'
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–∞—Ä—Å–∏–Ω–≥ chunk...")
        events = aws_event_parser.feed(chunk)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {events}")
        assert len(events) == 0  # followupPrompt –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç—Å—è
    
    def test_handles_mixed_events(self, aws_event_parser):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥ —Å–º–µ—à–∞–Ω–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã —Å–æ–±—ã—Ç–∏–π –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –≤–º–µ—Å—Ç–µ.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Chunk —Å–æ —Å–º–µ—à–∞–Ω–Ω—ã–º–∏ —Å–æ–±—ã—Ç–∏—è–º–∏...")
        chunk = b'{"content":"Hello"}{"usage":1.0}{"contextUsagePercentage":50}'
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–∞—Ä—Å–∏–Ω–≥ chunk...")
        events = aws_event_parser.feed(chunk)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {events}")
        assert len(events) == 3
        assert events[0]["type"] == "content"
        assert events[1]["type"] == "usage"
        assert events[2]["type"] == "context_usage"
    
    def test_handles_garbage_between_events(self, aws_event_parser):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –º—É—Å–æ—Ä–∞ –º–µ–∂–¥—É —Å–æ–±—ã—Ç–∏—è–º–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø–∞—Ä—Å–µ—Ä –Ω–∞—Ö–æ–¥–∏—Ç JSON —Å—Ä–µ–¥–∏ –º—É—Å–æ—Ä–∞.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: Chunk —Å –º—É—Å–æ—Ä–æ–º –º–µ–∂–¥—É JSON...")
        chunk = b'garbage{"content":"valid"}more garbage{"usage":1}'
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–∞—Ä—Å–∏–Ω–≥ chunk...")
        events = aws_event_parser.feed(chunk)
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {events}")
        assert len(events) == 2
    
    def test_handles_empty_chunk(self, aws_event_parser):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –ø—É—Å—Ç–æ–≥–æ chunk.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø—É—Å—Ç–æ–π chunk –Ω–µ –≤—ã–∑—ã–≤–∞–µ—Ç –æ—à–∏–±–æ–∫.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ü—É—Å—Ç–æ–π chunk...")
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü–∞—Ä—Å–∏–Ω–≥ –ø—É—Å—Ç–æ–≥–æ chunk...")
        events = aws_event_parser.feed(b'')
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å [], –ü–æ–ª—É—á–µ–Ω–æ {events}")
        assert events == []


================================================
FILE: tests/unit/test_routes.py
================================================
# -*- coding: utf-8 -*-

"""
Unit-—Ç–µ—Å—Ç—ã –¥–ª—è API endpoints (routes.py).
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–∞–±–æ—Ç—É —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤ /, /health, /v1/models, /v1/chat/completions.
"""

import pytest
from unittest.mock import AsyncMock, Mock, patch, MagicMock
from datetime import datetime, timezone

from fastapi import HTTPException
from fastapi.testclient import TestClient

from kiro_gateway.routes import verify_api_key, router
from kiro_gateway.config import PROXY_API_KEY, APP_VERSION, AVAILABLE_MODELS


class TestVerifyApiKey:
    """–¢–µ—Å—Ç—ã —Ñ—É–Ω–∫—Ü–∏–∏ verify_api_key."""
    
    @pytest.mark.asyncio
    async def test_valid_api_key_returns_true(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —É—Å–ø–µ—à–Ω—É—é –≤–∞–ª–∏–¥–∞—Ü–∏—é –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –∫–ª—é—á–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤–∞–ª–∏–¥–Ω—ã–π –∫–ª—é—á –ø—Ä–æ—Ö–æ–¥–∏—Ç –ø—Ä–æ–≤–µ—Ä–∫—É.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –í–∞–ª–∏–¥–Ω—ã–π API –∫–ª—é—á...")
        valid_header = f"Bearer {PROXY_API_KEY}"
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª—é—á–∞...")
        result = await verify_api_key(valid_header)
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç: –û–∂–∏–¥–∞–ª–æ—Å—å True, –ü–æ–ª—É—á–µ–Ω–æ {result}")
        assert result is True
    
    @pytest.mark.asyncio
    async def test_invalid_api_key_raises_401(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –Ω–µ–≤–∞–ª–∏–¥–Ω–æ–≥–æ –∫–ª—é—á–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π –∫–ª—é—á –≤—ã–∑—ã–≤–∞–µ—Ç 401.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ù–µ–≤–∞–ª–∏–¥–Ω—ã–π API –∫–ª—é—á...")
        invalid_header = "Bearer wrong_key"
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª—é—á–∞...")
        with pytest.raises(HTTPException) as exc_info:
            await verify_api_key(invalid_header)
        
        print(f"–ü—Ä–æ–≤–µ—Ä–∫–∞: HTTPException —Å –∫–æ–¥–æ–º 401...")
        assert exc_info.value.status_code == 401
        assert "Invalid or missing API Key" in exc_info.value.detail
    
    @pytest.mark.asyncio
    async def test_missing_api_key_raises_401(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –∫–ª—é—á–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∫–ª—é—á–∞ –≤—ã–∑—ã–≤–∞–µ—Ç 401.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–π API –∫–ª—é—á...")
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª—é—á–∞...")
        with pytest.raises(HTTPException) as exc_info:
            await verify_api_key(None)
        
        print(f"–ü—Ä–æ–≤–µ—Ä–∫–∞: HTTPException —Å –∫–æ–¥–æ–º 401...")
        assert exc_info.value.status_code == 401
    
    @pytest.mark.asyncio
    async def test_empty_api_key_raises_401(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –ø—É—Å—Ç–æ–≥–æ –∫–ª—é—á–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –≤—ã–∑—ã–≤–∞–µ—Ç 401.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ü—É—Å—Ç–æ–π API –∫–ª—é—á...")
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª—é—á–∞...")
        with pytest.raises(HTTPException) as exc_info:
            await verify_api_key("")
        
        print(f"–ü—Ä–æ–≤–µ—Ä–∫–∞: HTTPException —Å –∫–æ–¥–æ–º 401...")
        assert exc_info.value.status_code == 401
    
    @pytest.mark.asyncio
    async def test_wrong_format_raises_401(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –∫–ª—é—á–∞ –±–µ–∑ Bearer.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤—ã–∑—ã–≤–∞–µ—Ç 401.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –ö–ª—é—á –±–µ–∑ Bearer...")
        wrong_format = PROXY_API_KEY  # –ë–µ–∑ "Bearer "
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª—é—á–∞...")
        with pytest.raises(HTTPException) as exc_info:
            await verify_api_key(wrong_format)
        
        print(f"–ü—Ä–æ–≤–µ—Ä–∫–∞: HTTPException —Å –∫–æ–¥–æ–º 401...")
        assert exc_info.value.status_code == 401


class TestRootEndpoint:
    """–¢–µ—Å—Ç—ã —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞ /."""
    
    def test_root_returns_status_ok(self, test_client):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—Ç–≤–µ—Ç –∫–æ—Ä–Ω–µ–≤–æ–≥–æ —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ / –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å ok.
        """
        print("–î–µ–π—Å—Ç–≤–∏–µ: GET /...")
        response = test_client.get("/")
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {response.json()}")
        assert response.status_code == 200
        assert response.json()["status"] == "ok"
        assert "Kiro API Gateway" in response.json()["message"]
    
    def test_root_returns_version(self, test_client):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –≤–µ—Ä—Å–∏–∏ –≤ –æ—Ç–≤–µ—Ç–µ.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤–µ—Ä—Å–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è.
        """
        print("–î–µ–π—Å—Ç–≤–∏–µ: GET /...")
        response = test_client.get("/")
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {response.json()}")
        assert response.status_code == 200
        assert "version" in response.json()
        assert response.json()["version"] == APP_VERSION


class TestHealthEndpoint:
    """–¢–µ—Å—Ç—ã —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞ /health."""
    
    def test_health_returns_healthy(self, test_client):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—Ç–≤–µ—Ç health —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ /health –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å healthy.
        """
        print("–î–µ–π—Å—Ç–≤–∏–µ: GET /health...")
        response = test_client.get("/health")
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {response.json()}")
        assert response.status_code == 200
        assert response.json()["status"] == "healthy"
    
    def test_health_returns_timestamp(self, test_client):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ timestamp –≤ –æ—Ç–≤–µ—Ç–µ.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ timestamp –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è.
        """
        print("–î–µ–π—Å—Ç–≤–∏–µ: GET /health...")
        response = test_client.get("/health")
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {response.json()}")
        assert response.status_code == 200
        assert "timestamp" in response.json()
    
    def test_health_returns_version(self, test_client):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –≤–µ—Ä—Å–∏–∏ –≤ –æ—Ç–≤–µ—Ç–µ.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤–µ—Ä—Å–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è.
        """
        print("–î–µ–π—Å—Ç–≤–∏–µ: GET /health...")
        response = test_client.get("/health")
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {response.json()}")
        assert response.status_code == 200
        assert response.json()["version"] == APP_VERSION


class TestModelsEndpoint:
    """–¢–µ—Å—Ç—ã —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞ /v1/models."""
    
    def test_models_requires_auth(self, test_client):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –±–µ–∑ –∫–ª—é—á–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è 401.
        """
        print("–î–µ–π—Å—Ç–≤–∏–µ: GET /v1/models –±–µ–∑ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏...")
        response = test_client.get("/v1/models")
        
        print(f"–°—Ç–∞—Ç—É—Å: {response.status_code}")
        assert response.status_code == 401
    
    def test_models_returns_list(self, test_client, valid_proxy_api_key):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–æ–∑–≤—Ä–∞—Ç —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ /v1/models –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫.
        """
        print("–î–µ–π—Å—Ç–≤–∏–µ: GET /v1/models —Å –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–µ–π...")
        response = test_client.get(
            "/v1/models",
            headers={"Authorization": f"Bearer {valid_proxy_api_key}"}
        )
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {response.json()}")
        assert response.status_code == 200
        assert response.json()["object"] == "list"
        assert "data" in response.json()
    
    def test_models_returns_available_models(self, test_client, valid_proxy_api_key):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤—Å–µ –º–æ–¥–µ–ª–∏ –∏–∑ AVAILABLE_MODELS –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç—Å—è.
        """
        print("–î–µ–π—Å—Ç–≤–∏–µ: GET /v1/models —Å –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–µ–π...")
        response = test_client.get(
            "/v1/models",
            headers={"Authorization": f"Bearer {valid_proxy_api_key}"}
        )
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {response.json()}")
        assert response.status_code == 200
        
        model_ids = [m["id"] for m in response.json()["data"]]
        for expected_model in AVAILABLE_MODELS:
            assert expected_model in model_ids, f"–ú–æ–¥–µ–ª—å {expected_model} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
    
    def test_models_format_is_openai_compatible(self, test_client, valid_proxy_api_key):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –Ω–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å OpenAI.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Ñ–æ—Ä–º–∞—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç OpenAI API.
        """
        print("–î–µ–π—Å—Ç–≤–∏–µ: GET /v1/models —Å –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–µ–π...")
        response = test_client.get(
            "/v1/models",
            headers={"Authorization": f"Bearer {valid_proxy_api_key}"}
        )
        
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {response.json()}")
        assert response.status_code == 200
        
        for model in response.json()["data"]:
            assert "id" in model
            assert "object" in model
            assert model["object"] == "model"
            assert "owned_by" in model


class TestChatCompletionsEndpoint:
    """–¢–µ—Å—Ç—ã —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞ /v1/chat/completions."""
    
    def test_chat_completions_requires_auth(self, test_client):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –±–µ–∑ –∫–ª—é—á–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è 401.
        """
        print("–î–µ–π—Å—Ç–≤–∏–µ: POST /v1/chat/completions –±–µ–∑ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏...")
        response = test_client.post(
            "/v1/chat/completions",
            json={
                "model": "claude-sonnet-4-5",
                "messages": [{"role": "user", "content": "Hello"}]
            }
        )
        
        print(f"–°—Ç–∞—Ç—É—Å: {response.status_code}")
        assert response.status_code == 401
    
    def test_chat_completions_validates_messages(self, test_client, valid_proxy_api_key):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–∞—Ü–∏—é –ø—É—Å—Ç—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π –æ—Ç–∫–ª–æ–Ω—è–µ—Ç—Å—è.
        """
        print("–î–µ–π—Å—Ç–≤–∏–µ: POST /v1/chat/completions —Å –ø—É—Å—Ç—ã–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏...")
        response = test_client.post(
            "/v1/chat/completions",
            headers={"Authorization": f"Bearer {valid_proxy_api_key}"},
            json={
                "model": "claude-sonnet-4-5",
                "messages": []
            }
        )
        
        print(f"–°—Ç–∞—Ç—É—Å: {response.status_code}")
        # Pydantic –¥–æ–ª–∂–µ–Ω –æ—Ç–∫–ª–æ–Ω–∏—Ç—å –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫
        assert response.status_code == 422
    
    def test_chat_completions_validates_model(self, test_client, valid_proxy_api_key):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–∞—Ü–∏—é –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–µ–π –º–æ–¥–µ–ª–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –∑–∞–ø—Ä–æ—Å –±–µ–∑ –º–æ–¥–µ–ª–∏ –æ—Ç–∫–ª–æ–Ω—è–µ—Ç—Å—è.
        """
        print("–î–µ–π—Å—Ç–≤–∏–µ: POST /v1/chat/completions –±–µ–∑ –º–æ–¥–µ–ª–∏...")
        response = test_client.post(
            "/v1/chat/completions",
            headers={"Authorization": f"Bearer {valid_proxy_api_key}"},
            json={
                "messages": [{"role": "user", "content": "Hello"}]
            }
        )
        
        print(f"–°—Ç–∞—Ç—É—Å: {response.status_code}")
        assert response.status_code == 422


class TestChatCompletionsWithMockedKiro:
    """–¢–µ—Å—Ç—ã /v1/chat/completions —Å –º–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–º Kiro API."""
    
    def test_chat_completions_accepts_valid_request_format(self, test_client, valid_proxy_api_key):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –≤–∞–ª–∏–¥–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∑–∞–ø—Ä–æ—Å–∞ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç—Å—è.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ Pydantic –≤–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ—Ö–æ–¥–∏—Ç –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.
        """
        print("–ù–∞—Å—Ç—Ä–æ–π–∫–∞: –í–∞–ª–∏–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å...")
        
        # –≠—Ç–æ—Ç —Ç–µ—Å—Ç –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–∞—Ü–∏—é –∑–∞–ø—Ä–æ—Å–∞
        # –†–µ–∞–ª—å–Ω—ã–π –≤—ã–∑–æ–≤ –∫ Kiro API –±—É–¥–µ—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω —Ñ–∏–∫—Å—Ç—É—Ä–æ–π block_all_network_calls
        # –ü–æ—ç—Ç–æ–º—É –º—ã –æ–∂–∏–¥–∞–µ–º –æ—à–∏–±–∫—É –Ω–∞ —ç—Ç–∞–ø–µ HTTP –∑–∞–ø—Ä–æ—Å–∞, –∞ –Ω–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        
        print("–î–µ–π—Å—Ç–≤–∏–µ: POST /v1/chat/completions —Å –≤–∞–ª–∏–¥–Ω—ã–º –∑–∞–ø—Ä–æ—Å–æ–º...")
        response = test_client.post(
            "/v1/chat/completions",
            headers={"Authorization": f"Bearer {valid_proxy_api_key}"},
            json={
                "model": "claude-sonnet-4-5",
                "messages": [{"role": "user", "content": "Hello"}],
                "stream": False
            }
        )
        
        print(f"–°—Ç–∞—Ç—É—Å: {response.status_code}")
        # –ó–∞–ø—Ä–æ—Å –¥–æ–ª–∂–µ–Ω –ø—Ä–æ–π—Ç–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é (–Ω–µ 422)
        # –ù–æ –º–æ–∂–µ—Ç —É–ø–∞—Å—Ç—å –Ω–∞ —ç—Ç–∞–ø–µ HTTP –∏–∑-–∑–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ —Å–µ—Ç–∏
        assert response.status_code != 422


class TestChatCompletionsErrorHandling:
    """–¢–µ—Å—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫ –≤ /v1/chat/completions."""
    
    def test_invalid_json_returns_422(self, test_client, valid_proxy_api_key):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –Ω–µ–≤–∞–ª–∏–¥–Ω–æ–≥–æ JSON.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 422.
        """
        print("–î–µ–π—Å—Ç–≤–∏–µ: POST /v1/chat/completions —Å –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–º JSON...")
        response = test_client.post(
            "/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {valid_proxy_api_key}",
                "Content-Type": "application/json"
            },
            content=b"not valid json"
        )
        
        print(f"–°—Ç–∞—Ç—É—Å: {response.status_code}")
        assert response.status_code == 422
    
    def test_missing_content_in_message_returns_200(self, test_client, valid_proxy_api_key):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É —Å–æ–æ–±—â–µ–Ω–∏—è –±–µ–∑ content.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –±–µ–∑ content –¥–æ–ø—É—Å—Ç–∏–º–æ (content –æ–ø—Ü–∏–æ–Ω–∞–ª–µ–Ω).
        """
        print("–î–µ–π—Å—Ç–≤–∏–µ: POST /v1/chat/completions —Å —Å–æ–æ–±—â–µ–Ω–∏–µ–º –±–µ–∑ content...")
        # –≠—Ç–æ—Ç —Ç–µ—Å—Ç –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –≤–∞–ª–∏–¥–∞—Ü–∏—é Pydantic
        # content –º–æ–∂–µ—Ç –±—ã—Ç—å None —Å–æ–≥–ª–∞—Å–Ω–æ –º–æ–¥–µ–ª–∏
        response = test_client.post(
            "/v1/chat/completions",
            headers={"Authorization": f"Bearer {valid_proxy_api_key}"},
            json={
                "model": "claude-sonnet-4-5",
                "messages": [{"role": "user"}]  # content –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç
            }
        )
        
        print(f"–°—Ç–∞—Ç—É—Å: {response.status_code}")
        # –ó–∞–ø—Ä–æ—Å –¥–æ–ª–∂–µ–Ω –ø—Ä–æ–π—Ç–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é (content –æ–ø—Ü–∏–æ–Ω–∞–ª–µ–Ω)
        # –ù–æ –º–æ–∂–µ—Ç —É–ø–∞—Å—Ç—å –Ω–∞ —ç—Ç–∞–ø–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑-–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –º–æ–∫–∞ Kiro API
        # –ü–æ—ç—Ç–æ–º—É –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ 422 (–≤–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ—à–ª–∞)
        assert response.status_code != 422 or "content" not in str(response.json())


class TestRouterIntegration:
    """–¢–µ—Å—Ç—ã –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Ä–æ—É—Ç–µ—Ä–∞."""
    
    def test_router_has_all_endpoints(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤ –≤ —Ä–æ—É—Ç–µ—Ä–µ.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤—Å–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω—ã.
        """
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: –≠–Ω–¥–ø–æ–∏–Ω—Ç—ã –≤ —Ä–æ—É—Ç–µ—Ä–µ...")
        
        routes = [route.path for route in router.routes]
        
        print(f"–ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ä–æ—É—Ç—ã: {routes}")
        assert "/" in routes
        assert "/health" in routes
        assert "/v1/models" in routes
        assert "/v1/chat/completions" in routes
    
    def test_router_methods(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç HTTP –º–µ—Ç–æ–¥—ã —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–≤.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –º–µ—Ç–æ–¥—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –æ–∂–∏–¥–∞–Ω–∏—è–º.
        """
        print("–ü—Ä–æ–≤–µ—Ä–∫–∞: HTTP –º–µ—Ç–æ–¥—ã...")
        
        for route in router.routes:
            if route.path == "/":
                assert "GET" in route.methods
            elif route.path == "/health":
                assert "GET" in route.methods
            elif route.path == "/v1/models":
                assert "GET" in route.methods
            elif route.path == "/v1/chat/completions":
                assert "POST" in route.methods


================================================
FILE: tests/unit/test_streaming.py
================================================

# -*- coding: utf-8 -*-

"""
Unit tests for streaming module.
Tests logic for adding index to tool_calls and protection from None values.
"""

import pytest
import json
from unittest.mock import AsyncMock, MagicMock, patch

from kiro_gateway.streaming import (
    stream_kiro_to_openai,
    collect_stream_response
)


@pytest.fixture
def mock_model_cache():
    """Mock for ModelInfoCache."""
    cache = MagicMock()
    cache.get_max_input_tokens.return_value = 200000
    return cache


@pytest.fixture
def mock_auth_manager():
    """Mock for KiroAuthManager."""
    manager = MagicMock()
    return manager


@pytest.fixture
def mock_http_client():
    """Mock for httpx.AsyncClient."""
    client = AsyncMock()
    return client


class TestStreamingToolCallsIndex:
    """Tests for adding index to tool_calls in streaming responses."""
    
    @pytest.mark.asyncio
    async def test_tool_calls_have_index_field(self, mock_http_client, mock_model_cache, mock_auth_manager):
        """
        What it does: Verifies that tool_calls in streaming response contain index field.
        Goal: Ensure OpenAI API spec is followed for streaming tool calls.
        """
        print("Setup: Mock tool calls without index...")
        tool_calls = [
            {
                "id": "call_123",
                "type": "function",
                "function": {
                    "name": "get_weather",
                    "arguments": '{"location": "Moscow"}'
                }
            }
        ]
        
        print("Setup: Mock parser...")
        mock_parser = MagicMock()
        mock_parser.feed.return_value = []
        mock_parser.get_tool_calls.return_value = tool_calls
        
        print("Setup: Mock response...")
        mock_response = AsyncMock()
        mock_response.status_code = 200
        
        async def mock_aiter_bytes():
            yield b'{"content":"test"}'
        
        mock_response.aiter_bytes = mock_aiter_bytes
        mock_response.aclose = AsyncMock()
        
        print("Action: Collecting streaming chunks...")
        chunks = []
        
        with patch('kiro_gateway.streaming.AwsEventStreamParser', return_value=mock_parser):
            with patch('kiro_gateway.streaming.parse_bracket_tool_calls', return_value=[]):
                async for chunk in stream_kiro_to_openai(
                    mock_http_client, mock_response, "test-model", 
                    mock_model_cache, mock_auth_manager
                ):
                    chunks.append(chunk)
        
        print(f"Received chunks: {len(chunks)}")
        
        # Look for chunk with tool_calls
        tool_calls_found = False
        for chunk in chunks:
            if isinstance(chunk, str) and "tool_calls" in chunk:
                if chunk.startswith("data: "):
                    json_str = chunk[6:].strip()
                    if json_str != "[DONE]":
                        data = json.loads(json_str)
                        if "choices" in data and data["choices"]:
                            delta = data["choices"][0].get("delta", {})
                            if "tool_calls" in delta:
                                print(f"Tool calls in delta: {delta['tool_calls']}")
                                for tc in delta["tool_calls"]:
                                    print(f"Checking index in tool call: {tc}")
                                    assert "index" in tc, "Tool call must contain index field"
                                    tool_calls_found = True
        
        assert tool_calls_found, "Tool calls chunk not found"
    
    @pytest.mark.asyncio
    async def test_multiple_tool_calls_have_sequential_indices(self, mock_http_client, mock_model_cache, mock_auth_manager):
        """
        What it does: Verifies that multiple tool_calls have sequential indices.
        Goal: Ensure indices start from 0 and go sequentially.
        """
        print("Setup: Multiple tool calls...")
        tool_calls = [
            {"id": "call_1", "type": "function", "function": {"name": "func1", "arguments": "{}"}},
            {"id": "call_2", "type": "function", "function": {"name": "func2", "arguments": "{}"}},
            {"id": "call_3", "type": "function", "function": {"name": "func3", "arguments": "{}"}}
        ]
        
        print("Setup: Mock parser...")
        mock_parser = MagicMock()
        mock_parser.feed.return_value = []
        mock_parser.get_tool_calls.return_value = tool_calls
        
        print("Setup: Mock response...")
        mock_response = AsyncMock()
        mock_response.status_code = 200
        
        async def mock_aiter_bytes():
            yield b'{"content":"test"}'
        
        mock_response.aiter_bytes = mock_aiter_bytes
        mock_response.aclose = AsyncMock()
        
        print("Action: Collecting streaming chunks...")
        chunks = []
        
        with patch('kiro_gateway.streaming.AwsEventStreamParser', return_value=mock_parser):
            with patch('kiro_gateway.streaming.parse_bracket_tool_calls', return_value=[]):
                async for chunk in stream_kiro_to_openai(
                    mock_http_client, mock_response, "test-model",
                    mock_model_cache, mock_auth_manager
                ):
                    chunks.append(chunk)
        
        # Look for chunk with tool_calls
        for chunk in chunks:
            if isinstance(chunk, str) and "tool_calls" in chunk:
                if chunk.startswith("data: "):
                    json_str = chunk[6:].strip()
                    if json_str != "[DONE]":
                        data = json.loads(json_str)
                        if "choices" in data and data["choices"]:
                            delta = data["choices"][0].get("delta", {})
                            if "tool_calls" in delta:
                                indices = [tc["index"] for tc in delta["tool_calls"]]
                                print(f"Indices: {indices}")
                                assert indices == [0, 1, 2], f"Indices should be [0, 1, 2], got {indices}"


class TestStreamingToolCallsNoneProtection:
    """Tests for protection from None values in tool_calls."""
    
    @pytest.mark.asyncio
    async def test_handles_none_function_name(self, mock_http_client, mock_model_cache, mock_auth_manager):
        """
        What it does: Verifies handling of None in function.name.
        Goal: Ensure None is replaced with empty string.
        """
        print("Setup: Tool call with None name...")
        tool_calls = [
            {
                "id": "call_1",
                "type": "function",
                "function": {
                    "name": None,
                    "arguments": '{"a": 1}'
                }
            }
        ]
        
        mock_parser = MagicMock()
        mock_parser.feed.return_value = []
        mock_parser.get_tool_calls.return_value = tool_calls
        
        mock_response = AsyncMock()
        mock_response.status_code = 200
        
        async def mock_aiter_bytes():
            yield b'{"content":"test"}'
        
        mock_response.aiter_bytes = mock_aiter_bytes
        mock_response.aclose = AsyncMock()
        
        print("Action: Collecting streaming chunks...")
        chunks = []
        
        with patch('kiro_gateway.streaming.AwsEventStreamParser', return_value=mock_parser):
            with patch('kiro_gateway.streaming.parse_bracket_tool_calls', return_value=[]):
                async for chunk in stream_kiro_to_openai(
                    mock_http_client, mock_response, "test-model",
                    mock_model_cache, mock_auth_manager
                ):
                    chunks.append(chunk)
        
        # Verify no exceptions and chunks collected
        print(f"Received chunks: {len(chunks)}")
        assert len(chunks) > 0
        
        # Verify name replaced with empty string
        for chunk in chunks:
            if isinstance(chunk, str) and "tool_calls" in chunk:
                if chunk.startswith("data: "):
                    json_str = chunk[6:].strip()
                    if json_str != "[DONE]":
                        data = json.loads(json_str)
                        if "choices" in data and data["choices"]:
                            delta = data["choices"][0].get("delta", {})
                            if "tool_calls" in delta:
                                for tc in delta["tool_calls"]:
                                    assert tc["function"]["name"] == "", "None name should be replaced with empty string"
    
    @pytest.mark.asyncio
    async def test_handles_none_function_arguments(self, mock_http_client, mock_model_cache, mock_auth_manager):
        """
        What it does: Verifies handling of None in function.arguments.
        Goal: Ensure None is replaced with "{}".
        """
        print("Setup: Tool call with None arguments...")
        tool_calls = [
            {
                "id": "call_1",
                "type": "function",
                "function": {
                    "name": "test_func",
                    "arguments": None
                }
            }
        ]
        
        mock_parser = MagicMock()
        mock_parser.feed.return_value = []
        mock_parser.get_tool_calls.return_value = tool_calls
        
        mock_response = AsyncMock()
        mock_response.status_code = 200
        
        async def mock_aiter_bytes():
            yield b'{"content":"test"}'
        
        mock_response.aiter_bytes = mock_aiter_bytes
        mock_response.aclose = AsyncMock()
        
        print("Action: Collecting streaming chunks...")
        chunks = []
        
        with patch('kiro_gateway.streaming.AwsEventStreamParser', return_value=mock_parser):
            with patch('kiro_gateway.streaming.parse_bracket_tool_calls', return_value=[]):
                async for chunk in stream_kiro_to_openai(
                    mock_http_client, mock_response, "test-model",
                    mock_model_cache, mock_auth_manager
                ):
                    chunks.append(chunk)
        
        print(f"Received chunks: {len(chunks)}")
        assert len(chunks) > 0
        
        # Verify arguments replaced with "{}"
        for chunk in chunks:
            if isinstance(chunk, str) and "tool_calls" in chunk:
                if chunk.startswith("data: "):
                    json_str = chunk[6:].strip()
                    if json_str != "[DONE]":
                        data = json.loads(json_str)
                        if "choices" in data and data["choices"]:
                            delta = data["choices"][0].get("delta", {})
                            if "tool_calls" in delta:
                                for tc in delta["tool_calls"]:
                                    # None should be replaced with "{}" or empty string
                                    assert tc["function"]["arguments"] is not None
    
    @pytest.mark.asyncio
    async def test_handles_none_function_object(self, mock_http_client, mock_model_cache, mock_auth_manager):
        """
        What it does: Verifies handling of None instead of function object.
        Goal: Ensure None function is handled without errors.
        """
        print("Setup: Tool call with None function...")
        tool_calls = [
            {
                "id": "call_1",
                "type": "function",
                "function": None
            }
        ]
        
        mock_parser = MagicMock()
        mock_parser.feed.return_value = []
        mock_parser.get_tool_calls.return_value = tool_calls
        
        mock_response = AsyncMock()
        mock_response.status_code = 200
        
        async def mock_aiter_bytes():
            yield b'{"content":"test"}'
        
        mock_response.aiter_bytes = mock_aiter_bytes
        mock_response.aclose = AsyncMock()
        
        print("Action: Collecting streaming chunks...")
        chunks = []
        
        with patch('kiro_gateway.streaming.AwsEventStreamParser', return_value=mock_parser):
            with patch('kiro_gateway.streaming.parse_bracket_tool_calls', return_value=[]):
                async for chunk in stream_kiro_to_openai(
                    mock_http_client, mock_response, "test-model",
                    mock_model_cache, mock_auth_manager
                ):
                    chunks.append(chunk)
        
        print(f"Received chunks: {len(chunks)}")
        assert len(chunks) > 0


class TestCollectStreamResponseToolCalls:
    """Tests for collect_stream_response with tool_calls."""
    
    @pytest.mark.asyncio
    async def test_collected_tool_calls_have_no_index(self, mock_http_client, mock_model_cache, mock_auth_manager):
        """
        What it does: Verifies that collected tool_calls don't contain index field.
        Goal: Ensure index is removed for non-streaming response.
        """
        print("Setup: Tool calls...")
        tool_calls = [
            {
                "id": "call_1",
                "type": "function",
                "function": {"name": "func1", "arguments": '{"a": 1}'}
            }
        ]
        
        mock_parser = MagicMock()
        mock_parser.feed.return_value = []
        mock_parser.get_tool_calls.return_value = tool_calls
        
        mock_response = AsyncMock()
        mock_response.status_code = 200
        
        async def mock_aiter_bytes():
            yield b'{"content":"Hello"}'
        
        mock_response.aiter_bytes = mock_aiter_bytes
        mock_response.aclose = AsyncMock()
        
        print("Action: Collecting full response...")
        
        with patch('kiro_gateway.streaming.AwsEventStreamParser', return_value=mock_parser):
            with patch('kiro_gateway.streaming.parse_bracket_tool_calls', return_value=[]):
                result = await collect_stream_response(
                    mock_http_client, mock_response, "test-model",
                    mock_model_cache, mock_auth_manager
                )
        
        print(f"Result: {result}")
        
        if "choices" in result and result["choices"]:
            message = result["choices"][0].get("message", {})
            if "tool_calls" in message:
                for tc in message["tool_calls"]:
                    print(f"Tool call: {tc}")
                    assert "index" not in tc, "Non-streaming tool_calls should not contain index"
    
    @pytest.mark.asyncio
    async def test_collected_tool_calls_have_required_fields(self, mock_http_client, mock_model_cache, mock_auth_manager):
        """
        What it does: Verifies that collected tool_calls contain all required fields.
        Goal: Ensure id, type, function are present.
        """
        print("Setup: Tool calls...")
        tool_calls = [
            {
                "id": "call_abc",
                "type": "function",
                "function": {"name": "get_weather", "arguments": '{"city": "Moscow"}'}
            }
        ]
        
        mock_parser = MagicMock()
        mock_parser.feed.return_value = []
        mock_parser.get_tool_calls.return_value = tool_calls
        
        mock_response = AsyncMock()
        mock_response.status_code = 200
        
        async def mock_aiter_bytes():
            yield b'{"content":""}'
        
        mock_response.aiter_bytes = mock_aiter_bytes
        mock_response.aclose = AsyncMock()
        
        print("Action: Collecting full response...")
        
        with patch('kiro_gateway.streaming.AwsEventStreamParser', return_value=mock_parser):
            with patch('kiro_gateway.streaming.parse_bracket_tool_calls', return_value=[]):
                result = await collect_stream_response(
                    mock_http_client, mock_response, "test-model",
                    mock_model_cache, mock_auth_manager
                )
        
        print(f"Result: {result}")
        
        if "choices" in result and result["choices"]:
            message = result["choices"][0].get("message", {})
            if "tool_calls" in message:
                for tc in message["tool_calls"]:
                    print(f"Checking tool call: {tc}")
                    assert "id" in tc, "Tool call must contain id"
                    assert "type" in tc, "Tool call must contain type"
                    assert "function" in tc, "Tool call must contain function"
                    assert "name" in tc["function"], "Function must contain name"
                    assert "arguments" in tc["function"], "Function must contain arguments"
    
    @pytest.mark.asyncio
    async def test_handles_none_in_collected_tool_calls(self, mock_http_client, mock_model_cache, mock_auth_manager):
        """
        What it does: Verifies handling of None values in collected tool_calls.
        Goal: Ensure None is replaced with default values.
        """
        print("Setup: Tool calls with None values...")
        tool_calls = [
            {
                "id": "call_1",
                "type": "function",
                "function": None
            }
        ]
        
        mock_parser = MagicMock()
        mock_parser.feed.return_value = []
        mock_parser.get_tool_calls.return_value = tool_calls
        
        mock_response = AsyncMock()
        mock_response.status_code = 200
        
        async def mock_aiter_bytes():
            yield b'{"content":""}'
        
        mock_response.aiter_bytes = mock_aiter_bytes
        mock_response.aclose = AsyncMock()
        
        print("Action: Collecting full response...")
        
        with patch('kiro_gateway.streaming.AwsEventStreamParser', return_value=mock_parser):
            with patch('kiro_gateway.streaming.parse_bracket_tool_calls', return_value=[]):
                result = await collect_stream_response(
                    mock_http_client, mock_response, "test-model",
                    mock_model_cache, mock_auth_manager
                )
        
        print(f"Result: {result}")
        
        # Verify no exceptions
        assert "choices" in result


class TestStreamingErrorHandling:
    """Tests for error handling in streaming module."""
    
    @pytest.mark.asyncio
    async def test_generator_exit_handled_gracefully(self, mock_http_client, mock_model_cache, mock_auth_manager):
        """
        What it does: Verifies that GeneratorExit is handled without logging as error.
        Goal: Ensure client disconnect doesn't cause ERROR in logs.
        """
        print("Setup: Mock response that will raise GeneratorExit...")
        
        mock_response = AsyncMock()
        mock_response.status_code = 200
        mock_response.aclose = AsyncMock()
        
        # Create generator that will raise GeneratorExit
        async def mock_aiter_bytes_with_generator_exit():
            yield b'{"content":"Hello"}'
            # Simulate client disconnect
            raise GeneratorExit()
        
        mock_response.aiter_bytes = mock_aiter_bytes_with_generator_exit
        
        mock_parser = MagicMock()
        mock_parser.feed.return_value = [{"type": "content", "data": "Hello"}]
        mock_parser.get_tool_calls.return_value = []
        
        print("Action: Running streaming with GeneratorExit...")
        chunks_received = []
        generator_exit_caught = False
        
        with patch('kiro_gateway.streaming.AwsEventStreamParser', return_value=mock_parser):
            with patch('kiro_gateway.streaming.parse_bracket_tool_calls', return_value=[]):
                try:
                    async for chunk in stream_kiro_to_openai(
                        mock_http_client, mock_response, "test-model",
                        mock_model_cache, mock_auth_manager
                    ):
                        chunks_received.append(chunk)
                except GeneratorExit:
                    generator_exit_caught = True
                    print("GeneratorExit was caught (expected)")
        
        print(f"Received chunks before GeneratorExit: {len(chunks_received)}")
        print(f"GeneratorExit caught: {generator_exit_caught}")
        
        # Verify response was closed
        print("Check: response.aclose() should be called...")
        mock_response.aclose.assert_called()
        print("‚úì response.aclose() was called")
    
    @pytest.mark.asyncio
    async def test_exception_with_empty_message_logged_with_type(self, mock_http_client, mock_model_cache, mock_auth_manager):
        """
        What it does: Verifies that exception with empty message is logged with type.
        Goal: Ensure exception type is visible in logs even if str(e) is empty.
        """
        print("Setup: Mock response that will raise exception with empty message...")
        
        mock_response = AsyncMock()
        mock_response.status_code = 200
        mock_response.aclose = AsyncMock()
        
        # Create custom exception with empty message
        class EmptyMessageError(Exception):
            def __str__(self):
                return ""
        
        async def mock_aiter_bytes_with_empty_error():
            yield b'{"content":"Hello"}'
            raise EmptyMessageError()
        
        mock_response.aiter_bytes = mock_aiter_bytes_with_empty_error
        
        mock_parser = MagicMock()
        mock_parser.feed.return_value = [{"type": "content", "data": "Hello"}]
        mock_parser.get_tool_calls.return_value = []
        
        print("Action: Running streaming with EmptyMessageError...")
        
        with patch('kiro_gateway.streaming.AwsEventStreamParser', return_value=mock_parser):
            with patch('kiro_gateway.streaming.parse_bracket_tool_calls', return_value=[]):
                with patch('kiro_gateway.streaming.logger') as mock_logger:
                    exception_raised = False
                    try:
                        async for chunk in stream_kiro_to_openai(
                            mock_http_client, mock_response, "test-model",
                            mock_model_cache, mock_auth_manager
                        ):
                            pass
                    except EmptyMessageError:
                        exception_raised = True
                        print("EmptyMessageError was caught (expected)")
                    
                    print("Check: logger.error should be called with exception type...")
                    # Verify logger.error was called
                    error_calls = [call for call in mock_logger.error.call_args_list]
                    print(f"logger.error calls: {error_calls}")
                    
                    # Should have call with exception type
                    assert exception_raised, "Exception should be propagated"
                    assert mock_logger.error.called, "logger.error should be called"
                    
                    # Verify exception type is in message
                    error_message = str(mock_logger.error.call_args_list[0])
                    print(f"Error message: {error_message}")
                    assert "EmptyMessageError" in error_message, "Exception type should be in log"
                    print("‚úì Exception type is present in log")
    
    @pytest.mark.asyncio
    async def test_exception_propagated_to_caller(self, mock_http_client, mock_model_cache, mock_auth_manager):
        """
        What it does: Verifies that exceptions are propagated up.
        Goal: Ensure errors are not "swallowed" inside generator.
        """
        print("Setup: Mock response that will raise RuntimeError...")
        
        mock_response = AsyncMock()
        mock_response.status_code = 200
        mock_response.aclose = AsyncMock()
        
        async def mock_aiter_bytes_with_error():
            yield b'{"content":"Hello"}'
            raise RuntimeError("Test error for propagation")
        
        mock_response.aiter_bytes = mock_aiter_bytes_with_error
        
        mock_parser = MagicMock()
        mock_parser.feed.return_value = [{"type": "content", "data": "Hello"}]
        mock_parser.get_tool_calls.return_value = []
        
        print("Action: Running streaming with RuntimeError...")
        
        with patch('kiro_gateway.streaming.AwsEventStreamParser', return_value=mock_parser):
            with patch('kiro_gateway.streaming.parse_bracket_tool_calls', return_value=[]):
                with pytest.raises(RuntimeError) as exc_info:
                    async for chunk in stream_kiro_to_openai(
                        mock_http_client, mock_response, "test-model",
                        mock_model_cache, mock_auth_manager
                    ):
                        pass
        
        print(f"Caught exception: {exc_info.value}")
        assert "Test error for propagation" in str(exc_info.value)
        print("‚úì Exception was propagated up with correct message")
    
    @pytest.mark.asyncio
    async def test_response_closed_on_error(self, mock_http_client, mock_model_cache, mock_auth_manager):
        """
        What it does: Verifies that response is closed even on error.
        Goal: Ensure resources are released in finally block.
        """
        print("Setup: Mock response that will raise ValueError...")
        
        mock_response = AsyncMock()
        mock_response.status_code = 200
        mock_response.aclose = AsyncMock()
        
        async def mock_aiter_bytes_with_value_error():
            yield b'{"content":"Hello"}'
            raise ValueError("Test value error")
        
        mock_response.aiter_bytes = mock_aiter_bytes_with_value_error
        
        mock_parser = MagicMock()
        mock_parser.feed.return_value = [{"type": "content", "data": "Hello"}]
        mock_parser.get_tool_calls.return_value = []
        
        print("Action: Running streaming with ValueError...")
        
        with patch('kiro_gateway.streaming.AwsEventStreamParser', return_value=mock_parser):
            with patch('kiro_gateway.streaming.parse_bracket_tool_calls', return_value=[]):
                try:
                    async for chunk in stream_kiro_to_openai(
                        mock_http_client, mock_response, "test-model",
                        mock_model_cache, mock_auth_manager
                    ):
                        pass
                except ValueError:
                    print("ValueError caught (expected)")
        
        print("Check: response.aclose() should be called...")
        mock_response.aclose.assert_called()
        print("‚úì response.aclose() was called even on error")
    
    @pytest.mark.asyncio
    async def test_response_closed_on_success(self, mock_http_client, mock_model_cache, mock_auth_manager):
        """
        What it does: Verifies that response is closed on successful completion.
        Goal: Ensure resources are released in finally block.
        """
        print("Setup: Mock response for successful streaming...")
        
        mock_response = AsyncMock()
        mock_response.status_code = 200
        mock_response.aclose = AsyncMock()
        
        async def mock_aiter_bytes_success():
            yield b'{"content":"Hello World"}'
        
        mock_response.aiter_bytes = mock_aiter_bytes_success
        
        mock_parser = MagicMock()
        mock_parser.feed.return_value = [{"type": "content", "data": "Hello World"}]
        mock_parser.get_tool_calls.return_value = []
        
        print("Action: Running successful streaming...")
        chunks = []
        
        with patch('kiro_gateway.streaming.AwsEventStreamParser', return_value=mock_parser):
            with patch('kiro_gateway.streaming.parse_bracket_tool_calls', return_value=[]):
                async for chunk in stream_kiro_to_openai(
                    mock_http_client, mock_response, "test-model",
                    mock_model_cache, mock_auth_manager
                ):
                    chunks.append(chunk)
        
        print(f"Received chunks: {len(chunks)}")
        print("Check: response.aclose() should be called...")
        mock_response.aclose.assert_called()
        print("‚úì response.aclose() was called on successful completion")
    
    @pytest.mark.asyncio
    async def test_aclose_error_does_not_mask_original_error(self, mock_http_client, mock_model_cache, mock_auth_manager):
        """
        What it does: Verifies that error in aclose() doesn't mask original error.
        Goal: Ensure original exception is propagated even if aclose() fails.
        """
        print("Setup: Mock response with error in aclose()...")
        
        mock_response = AsyncMock()
        mock_response.status_code = 200
        mock_response.aclose = AsyncMock(side_effect=ConnectionError("Connection lost"))
        
        async def mock_aiter_bytes_with_error():
            yield b'{"content":"Hello"}'
            raise RuntimeError("Original error")
        
        mock_response.aiter_bytes = mock_aiter_bytes_with_error
        
        mock_parser = MagicMock()
        mock_parser.feed.return_value = [{"type": "content", "data": "Hello"}]
        mock_parser.get_tool_calls.return_value = []
        
        print("Action: Running streaming with error and error in aclose()...")
        
        with patch('kiro_gateway.streaming.AwsEventStreamParser', return_value=mock_parser):
            with patch('kiro_gateway.streaming.parse_bracket_tool_calls', return_value=[]):
                with pytest.raises(RuntimeError) as exc_info:
                    async for chunk in stream_kiro_to_openai(
                        mock_http_client, mock_response, "test-model",
                        mock_model_cache, mock_auth_manager
                    ):
                        pass
        
        print(f"Caught exception: {exc_info.value}")
        # Should be original error, not ConnectionError from aclose()
        assert "Original error" in str(exc_info.value)
        print("‚úì Original error was not masked by error in aclose()")


class TestFirstTokenTimeoutError:
    """Tests for FirstTokenTimeoutError and first token timeout logging."""
    
    @pytest.mark.asyncio
    async def test_first_token_timeout_not_caught_by_general_handler(self, mock_http_client, mock_model_cache, mock_auth_manager):
        """
        What it does: Verifies that FirstTokenTimeoutError is propagated for retry.
        Goal: Ensure first token timeout is not handled as regular error.
        """
        import asyncio
        from kiro_gateway.streaming import FirstTokenTimeoutError, stream_kiro_to_openai_internal
        
        print("Setup: Mock response with timeout...")
        
        mock_response = AsyncMock()
        mock_response.status_code = 200
        mock_response.aclose = AsyncMock()
        
        # Create generator that will be used
        async def mock_aiter_bytes():
            yield b'{"content":"test"}'
        
        mock_response.aiter_bytes = mock_aiter_bytes
        
        print("Action: Mocking asyncio.wait_for to immediately raise TimeoutError...")
        
        # Mock asyncio.wait_for to immediately raise TimeoutError
        async def mock_wait_for_timeout(*args, **kwargs):
            raise asyncio.TimeoutError()
        
        with patch('kiro_gateway.streaming.asyncio.wait_for', side_effect=mock_wait_for_timeout):
            with pytest.raises(FirstTokenTimeoutError) as exc_info:
                async for chunk in stream_kiro_to_openai_internal(
                    mock_http_client, mock_response, "test-model",
                    mock_model_cache, mock_auth_manager,
                    first_token_timeout=30  # Value doesn't matter, wait_for is mocked
                ):
                    pass
        
        print(f"Caught exception: {exc_info.value}")
        print("‚úì FirstTokenTimeoutError was propagated for retry logic")
        
        # Verify response was closed
        mock_response.aclose.assert_called()
        print("‚úì response.aclose() was called")
    
    @pytest.mark.asyncio
    async def test_first_token_timeout_logged_with_correct_format(self, mock_http_client, mock_model_cache, mock_auth_manager):
        """
        What it does: Verifies that first token timeout is logged with [FirstTokenTimeout] prefix.
        Goal: Ensure consistent logging format for first token timeout.
        """
        import asyncio
        from kiro_gateway.streaming import FirstTokenTimeoutError, stream_kiro_to_openai_internal
        
        print("Setup: Mock response with timeout...")
        
        mock_response = AsyncMock()
        mock_response.status_code = 200
        mock_response.aclose = AsyncMock()
        
        async def mock_aiter_bytes():
            yield b'{"content":"test"}'
        
        mock_response.aiter_bytes = mock_aiter_bytes
        
        async def mock_wait_for_timeout(*args, **kwargs):
            raise asyncio.TimeoutError()
        
        print("Action: Running streaming with timeout and checking logs...")
        
        with patch('kiro_gateway.streaming.asyncio.wait_for', side_effect=mock_wait_for_timeout):
            with patch('kiro_gateway.streaming.logger') as mock_logger:
                try:
                    async for chunk in stream_kiro_to_openai_internal(
                        mock_http_client, mock_response, "test-model",
                        mock_model_cache, mock_auth_manager,
                        first_token_timeout=15
                    ):
                        pass
                except FirstTokenTimeoutError:
                    pass
                
                print("Check: logger.warning should be called with [FirstTokenTimeout]...")
                warning_calls = [str(call) for call in mock_logger.warning.call_args_list]
                print(f"Warning calls: {warning_calls}")
                
                assert any("FirstTokenTimeout" in call for call in warning_calls), \
                    f"[FirstTokenTimeout] not found in warning logs: {warning_calls}"
                print("‚úì [FirstTokenTimeout] prefix found in logs")
    
    @pytest.mark.asyncio
    async def test_first_token_timeout_includes_timeout_value(self, mock_http_client, mock_model_cache, mock_auth_manager):
        """
        What it does: Verifies that first token timeout log includes the timeout value.
        Goal: Ensure timeout value is visible in logs for debugging.
        """
        import asyncio
        from kiro_gateway.streaming import FirstTokenTimeoutError, stream_kiro_to_openai_internal
        
        print("Setup: Mock response with timeout...")
        
        mock_response = AsyncMock()
        mock_response.status_code = 200
        mock_response.aclose = AsyncMock()
        
        async def mock_aiter_bytes():
            yield b'{"content":"test"}'
        
        mock_response.aiter_bytes = mock_aiter_bytes
        
        async def mock_wait_for_timeout(*args, **kwargs):
            raise asyncio.TimeoutError()
        
        custom_timeout = 25.0
        
        print(f"Action: Running streaming with custom timeout={custom_timeout}...")
        
        with patch('kiro_gateway.streaming.asyncio.wait_for', side_effect=mock_wait_for_timeout):
            with patch('kiro_gateway.streaming.logger') as mock_logger:
                try:
                    async for chunk in stream_kiro_to_openai_internal(
                        mock_http_client, mock_response, "test-model",
                        mock_model_cache, mock_auth_manager,
                        first_token_timeout=custom_timeout
                    ):
                        pass
                except FirstTokenTimeoutError:
                    pass
                
                print("Check: logger.warning should include timeout value...")
                warning_calls = [str(call) for call in mock_logger.warning.call_args_list]
                print(f"Warning calls: {warning_calls}")
                
                assert any(str(custom_timeout) in call for call in warning_calls), \
                    f"Timeout value {custom_timeout} not found in warning logs: {warning_calls}"
                print(f"‚úì Timeout value {custom_timeout} found in logs")
    
    @pytest.mark.asyncio
    async def test_first_token_received_logged_on_success(self, mock_http_client, mock_model_cache, mock_auth_manager):
        """
        What it does: Verifies that successful first token receipt is logged.
        Goal: Ensure debug log shows when first token is received.
        """
        from kiro_gateway.streaming import stream_kiro_to_openai_internal
        
        print("Setup: Mock response with successful first token...")
        
        mock_response = AsyncMock()
        mock_response.status_code = 200
        mock_response.aclose = AsyncMock()
        
        async def mock_aiter_bytes():
            yield b'{"content":"Hello"}'
        
        mock_response.aiter_bytes = mock_aiter_bytes
        
        mock_parser = MagicMock()
        mock_parser.feed.return_value = [{"type": "content", "data": "Hello"}]
        mock_parser.get_tool_calls.return_value = []
        
        print("Action: Running streaming and checking debug logs...")
        
        with patch('kiro_gateway.streaming.AwsEventStreamParser', return_value=mock_parser):
            with patch('kiro_gateway.streaming.parse_bracket_tool_calls', return_value=[]):
                with patch('kiro_gateway.streaming.logger') as mock_logger:
                    chunks = []
                    async for chunk in stream_kiro_to_openai_internal(
                        mock_http_client, mock_response, "test-model",
                        mock_model_cache, mock_auth_manager,
                        first_token_timeout=15
                    ):
                        chunks.append(chunk)
                    
                    print(f"Received {len(chunks)} chunks")
                    print("Check: logger.debug should be called with 'First token received'...")
                    debug_calls = [str(call) for call in mock_logger.debug.call_args_list]
                    print(f"Debug calls: {debug_calls}")
                    
                    assert any("First token received" in call for call in debug_calls), \
                        f"'First token received' not found in debug logs: {debug_calls}"
                    print("‚úì 'First token received' found in debug logs")


class TestStreamWithFirstTokenRetry:
    """Tests for stream_with_first_token_retry function."""
    
    @pytest.mark.asyncio
    async def test_retry_on_first_token_timeout(self, mock_http_client, mock_model_cache, mock_auth_manager):
        """
        What it does: Verifies that request is retried on first token timeout.
        Goal: Ensure retry logic works for first token timeout.
        """
        import asyncio
        from kiro_gateway.streaming import stream_with_first_token_retry, FirstTokenTimeoutError
        
        print("Setup: Mock make_request that succeeds on second attempt...")
        
        mock_response_success = AsyncMock()
        mock_response_success.status_code = 200
        mock_response_success.aclose = AsyncMock()
        
        async def mock_aiter_bytes_success():
            yield b'{"content":"Success"}'
        
        mock_response_success.aiter_bytes = mock_aiter_bytes_success
        
        call_count = 0
        
        async def mock_make_request():
            nonlocal call_count
            call_count += 1
            print(f"make_request called (attempt {call_count})")
            return mock_response_success
        
        mock_parser = MagicMock()
        mock_parser.feed.return_value = [{"type": "content", "data": "Success"}]
        mock_parser.get_tool_calls.return_value = []
        
        # First call raises timeout, second succeeds
        timeout_raised = False
        
        async def mock_wait_for_with_retry(coro, timeout):
            nonlocal timeout_raised
            if not timeout_raised:
                timeout_raised = True
                raise asyncio.TimeoutError()
            return await coro
        
        print("Action: Running stream_with_first_token_retry...")
        
        with patch('kiro_gateway.streaming.AwsEventStreamParser', return_value=mock_parser):
            with patch('kiro_gateway.streaming.parse_bracket_tool_calls', return_value=[]):
                with patch('kiro_gateway.streaming.asyncio.wait_for', side_effect=mock_wait_for_with_retry):
                    chunks = []
                    async for chunk in stream_with_first_token_retry(
                        mock_make_request,
                        mock_http_client,
                        "test-model",
                        mock_model_cache,
                        mock_auth_manager,
                        max_retries=3,
                        first_token_timeout=15
                    ):
                        chunks.append(chunk)
        
        print(f"Received {len(chunks)} chunks")
        print(f"make_request was called {call_count} times")
        
        assert call_count == 2, f"Expected 2 calls (1 timeout + 1 success), got {call_count}"
        assert len(chunks) > 0, "Should receive chunks after retry"
        print("‚úì Retry logic worked correctly")
    
    @pytest.mark.asyncio
    async def test_all_retries_exhausted_raises_504(self, mock_http_client, mock_model_cache, mock_auth_manager):
        """
        What it does: Verifies that 504 is raised after all retries exhausted.
        Goal: Ensure proper error handling when model never responds.
        """
        import asyncio
        from fastapi import HTTPException
        from kiro_gateway.streaming import stream_with_first_token_retry
        
        print("Setup: Mock make_request that always times out...")
        
        mock_response = AsyncMock()
        mock_response.status_code = 200
        mock_response.aclose = AsyncMock()
        
        async def mock_aiter_bytes():
            yield b'{"content":"test"}'
        
        mock_response.aiter_bytes = mock_aiter_bytes
        
        call_count = 0
        
        async def mock_make_request():
            nonlocal call_count
            call_count += 1
            print(f"make_request called (attempt {call_count})")
            return mock_response
        
        async def mock_wait_for_always_timeout(*args, **kwargs):
            raise asyncio.TimeoutError()
        
        max_retries = 3
        
        print(f"Action: Running stream_with_first_token_retry with max_retries={max_retries}...")
        
        with patch('kiro_gateway.streaming.asyncio.wait_for', side_effect=mock_wait_for_always_timeout):
            with pytest.raises(HTTPException) as exc_info:
                async for chunk in stream_with_first_token_retry(
                    mock_make_request,
                    mock_http_client,
                    "test-model",
                    mock_model_cache,
                    mock_auth_manager,
                    max_retries=max_retries,
                    first_token_timeout=15
                ):
                    pass
        
        print(f"Caught HTTPException: {exc_info.value.status_code} - {exc_info.value.detail}")
        print(f"make_request was called {call_count} times")
        
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º status_code: –û–∂–∏–¥–∞–ª–æ—Å—å 504, –ü–æ–ª—É—á–µ–Ω–æ {exc_info.value.status_code}")
        assert exc_info.value.status_code == 504
        print(f"–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º call_count: –û–∂–∏–¥–∞–ª–æ—Å—å {max_retries}, –ü–æ–ª—É—á–µ–Ω–æ {call_count}")
        assert call_count == max_retries
        assert "15" in exc_info.value.detail, "Timeout value should be in error message"
        print("‚úì 504 raised after all retries exhausted")
    
    @pytest.mark.asyncio
    async def test_retry_logs_attempt_number(self, mock_http_client, mock_model_cache, mock_auth_manager):
        """
        What it does: Verifies that retry attempts are logged with attempt number.
        Goal: Ensure logs show which attempt failed.
        """
        import asyncio
        from fastapi import HTTPException
        from kiro_gateway.streaming import stream_with_first_token_retry
        
        print("Setup: Mock make_request that always times out...")
        
        mock_response = AsyncMock()
        mock_response.status_code = 200
        mock_response.aclose = AsyncMock()
        
        async def mock_aiter_bytes():
            yield b'{"content":"test"}'
        
        mock_response.aiter_bytes = mock_aiter_bytes
        
        async def mock_make_request():
            return mock_response
        
        async def mock_wait_for_always_timeout(*args, **kwargs):
            raise asyncio.TimeoutError()
        
        print("Action: Running stream_with_first_token_retry and checking logs...")
        
        with patch('kiro_gateway.streaming.asyncio.wait_for', side_effect=mock_wait_for_always_timeout):
            with patch('kiro_gateway.streaming.logger') as mock_logger:
                try:
                    async for chunk in stream_with_first_token_retry(
                        mock_make_request,
                        mock_http_client,
                        "test-model",
                        mock_model_cache,
                        mock_auth_manager,
                        max_retries=3,
                        first_token_timeout=15
                    ):
                        pass
                except HTTPException:
                    pass
                
                print("Check: logger.warning should include attempt numbers...")
                warning_calls = [str(call) for call in mock_logger.warning.call_args_list]
                print(f"Warning calls: {warning_calls}")
                
                # Should have warnings for attempts 1/3, 2/3, 3/3
                assert any("1/3" in call or "2/3" in call or "3/3" in call for call in warning_calls), \
                    f"Attempt numbers not found in warning logs: {warning_calls}"
                print("‚úì Attempt numbers found in logs")


================================================
FILE: tests/unit/test_tokenizer.py
================================================
# -*- coding: utf-8 -*-

"""
Unit-—Ç–µ—Å—Ç—ã –¥–ª—è –º–æ–¥—É–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ (kiro_gateway/tokenizer.py).

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
- –ü–æ–¥—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ (count_tokens)
- –ü–æ–¥—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö (count_message_tokens)
- –ü–æ–¥—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞—Ö (count_tools_tokens)
- –û—Ü–µ–Ω–∫—É —Ç–æ–∫–µ–Ω–æ–≤ –∑–∞–ø—Ä–æ—Å–∞ (estimate_request_tokens)
- –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –¥–ª—è Claude (CLAUDE_CORRECTION_FACTOR)
- Fallback –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ tiktoken
"""

import pytest
from unittest.mock import patch, MagicMock

from kiro_gateway.tokenizer import (
    count_tokens,
    count_message_tokens,
    count_tools_tokens,
    estimate_request_tokens,
    CLAUDE_CORRECTION_FACTOR,
    _get_encoding
)


class TestCountTokens:
    """–¢–µ—Å—Ç—ã –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ count_tokens."""
    
    def test_empty_string_returns_zero(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 0 —Ç–æ–∫–µ–Ω–æ–≤.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥—Ä–∞–Ω–∏—á–Ω–æ–≥–æ —Å–ª—É—á–∞—è.
        """
        print("–¢–µ—Å—Ç: –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞...")
        result = count_tokens("")
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        assert result == 0, "–ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –¥–æ–ª–∂–Ω–∞ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å 0 —Ç–æ–∫–µ–Ω–æ–≤"
    
    def test_none_returns_zero(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ None –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 0 —Ç–æ–∫–µ–Ω–æ–≤.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ None.
        """
        print("–¢–µ—Å—Ç: None...")
        result = count_tokens(None)
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        assert result == 0, "None –¥–æ–ª–∂–µ–Ω –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å 0 —Ç–æ–∫–µ–Ω–æ–≤"
    
    def test_simple_text_returns_positive(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –ø—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Ç–æ–∫–µ–Ω–æ–≤.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è –≤ –±–∞–∑–æ–≤–æ–π —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –ø–æ–¥—Å—á—ë—Ç–∞.
        """
        print("–¢–µ—Å—Ç: –ü—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç...")
        result = count_tokens("Hello, world!")
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        assert result > 0, "–ü—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Ç–æ–∫–µ–Ω–æ–≤"
    
    def test_longer_text_returns_more_tokens(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –±–æ–ª—å—à–µ —Ç–æ–∫–µ–Ω–æ–≤.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –ø–æ–¥—Å—á—ë—Ç–∞.
        """
        print("–¢–µ—Å—Ç: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–ª–∏–Ω–Ω–æ–≥–æ –∏ –∫–æ—Ä–æ—Ç–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞...")
        short_text = "Hello"
        long_text = "Hello, this is a much longer text that should have more tokens"
        
        short_tokens = count_tokens(short_text)
        long_tokens = count_tokens(long_text)
        
        print(f"–ö–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç: {short_tokens} —Ç–æ–∫–µ–Ω–æ–≤")
        print(f"–î–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {long_tokens} —Ç–æ–∫–µ–Ω–æ–≤")
        
        assert long_tokens > short_tokens, "–î–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å –±–æ–ª—å—à–µ —Ç–æ–∫–µ–Ω–æ–≤"
    
    def test_claude_correction_applied_by_default(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ Claude –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ apply_claude_correction=True –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.
        """
        print("–¢–µ—Å—Ç: –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ Claude...")
        text = "This is a test text for token counting"
        
        with_correction = count_tokens(text, apply_claude_correction=True)
        without_correction = count_tokens(text, apply_claude_correction=False)
        
        print(f"–° –∫–æ—Ä—Ä–µ–∫—Ü–∏–µ–π: {with_correction}")
        print(f"–ë–µ–∑ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏: {without_correction}")
        
        # –° –∫–æ—Ä—Ä–µ–∫—Ü–∏–µ–π –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –±–æ–ª—å—à–µ (–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç 1.15)
        assert with_correction > without_correction, "–° –∫–æ—Ä—Ä–µ–∫—Ü–∏–µ–π –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –±–æ–ª—å—à–µ —Ç–æ–∫–µ–Ω–æ–≤"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏–º–µ—Ä–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ
        ratio = with_correction / without_correction
        print(f"–°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ: {ratio}")
        assert 1.1 <= ratio <= 1.2, f"–°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ–∫–æ–ª–æ {CLAUDE_CORRECTION_FACTOR}"
    
    def test_without_claude_correction(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥—Å—á—ë—Ç –±–µ–∑ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ apply_claude_correction=False —Ä–∞–±–æ—Ç–∞–µ—Ç.
        """
        print("–¢–µ—Å—Ç: –ë–µ–∑ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏...")
        text = "Test text"
        
        result = count_tokens(text, apply_claude_correction=False)
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        
        assert result > 0, "–î–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Ç–æ–∫–µ–Ω–æ–≤"
    
    def test_unicode_text(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è Unicode —Ç–µ–∫—Å—Ç–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ –Ω–µ-ASCII —Å–∏–º–≤–æ–ª–æ–≤.
        """
        print("–¢–µ—Å—Ç: Unicode —Ç–µ–∫—Å—Ç...")
        text = "–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä! ‰Ω†Â•Ω‰∏ñÁïå üåç"
        
        result = count_tokens(text)
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        
        assert result > 0, "Unicode —Ç–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Ç–æ–∫–µ–Ω–æ–≤"
    
    def test_multiline_text(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –º–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø–µ—Ä–µ–Ω–æ—Å–æ–≤ —Å—Ç—Ä–æ–∫.
        """
        print("–¢–µ—Å—Ç: –ú–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–π —Ç–µ–∫—Å—Ç...")
        text = """Line 1
        Line 2
        Line 3"""
        
        result = count_tokens(text)
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        
        assert result > 0, "–ú–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Ç–æ–∫–µ–Ω–æ–≤"
    
    def test_json_text(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è JSON —Å—Ç—Ä–æ–∫–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ JSON.
        """
        print("–¢–µ—Å—Ç: JSON —Ç–µ–∫—Å—Ç...")
        text = '{"name": "test", "value": 123, "nested": {"key": "value"}}'
        
        result = count_tokens(text)
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        
        assert result > 0, "JSON —Ç–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Ç–æ–∫–µ–Ω–æ–≤"


class TestCountTokensFallback:
    """–¢–µ—Å—Ç—ã –¥–ª—è fallback –ª–æ–≥–∏–∫–∏ –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ tiktoken."""
    
    def test_fallback_when_tiktoken_unavailable(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç fallback –ø–æ–¥—Å—á—ë—Ç –∫–æ–≥–¥–∞ tiktoken –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Å–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ tiktoken.
        """
        print("–¢–µ—Å—Ç: Fallback –±–µ–∑ tiktoken...")
        
        # –ú–æ–∫–∏—Ä—É–µ–º _get_encoding —á—Ç–æ–±—ã –≤–µ—Ä–Ω—É—Ç—å None
        with patch('kiro_gateway.tokenizer._get_encoding', return_value=None):
            result = count_tokens("Hello world test")
            print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
            
            # Fallback: len(text) // 4 + 1, –∑–∞—Ç–µ–º * 1.15
            # "Hello world test" = 16 —Å–∏–º–≤–æ–ª–æ–≤
            # 16 // 4 + 1 = 5
            # 5 * 1.15 = 5.75 -> 5
            assert result > 0, "Fallback –¥–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ —á–∏—Å–ª–æ"
    
    def test_fallback_without_correction(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç fallback –±–µ–∑ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ fallback —Ä–∞–±–æ—Ç–∞–µ—Ç —Å apply_claude_correction=False.
        """
        print("–¢–µ—Å—Ç: Fallback –±–µ–∑ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏...")
        
        with patch('kiro_gateway.tokenizer._get_encoding', return_value=None):
            result = count_tokens("Test", apply_claude_correction=False)
            print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
            
            # "Test" = 4 —Å–∏–º–≤–æ–ª–∞
            # 4 // 4 + 1 = 2
            assert result > 0, "Fallback –¥–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ —á–∏—Å–ª–æ"


class TestCountMessageTokens:
    """–¢–µ—Å—Ç—ã –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ count_message_tokens."""
    
    def test_empty_list_returns_zero(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 0 —Ç–æ–∫–µ–Ω–æ–≤.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø—É—Å—Ç–æ–≥–æ —Å–ø–∏—Å–∫–∞.
        """
        print("–¢–µ—Å—Ç: –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π...")
        result = count_message_tokens([])
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        assert result == 0, "–ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –¥–æ–ª–∂–µ–Ω –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å 0 —Ç–æ–∫–µ–Ω–æ–≤"
    
    def test_none_returns_zero(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ None –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 0 —Ç–æ–∫–µ–Ω–æ–≤.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ None.
        """
        print("–¢–µ—Å—Ç: None...")
        result = count_message_tokens(None)
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        assert result == 0, "None –¥–æ–ª–∂–µ–Ω –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å 0 —Ç–æ–∫–µ–Ω–æ–≤"
    
    def test_single_user_message(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –æ–¥–Ω–æ–≥–æ user —Å–æ–æ–±—â–µ–Ω–∏—è.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è –≤ –±–∞–∑–æ–≤–æ–π —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏.
        """
        print("–¢–µ—Å—Ç: –û–¥–Ω–æ user —Å–æ–æ–±—â–µ–Ω–∏–µ...")
        messages = [{"role": "user", "content": "Hello, AI!"}]
        
        result = count_message_tokens(messages)
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        
        assert result > 0, "–î–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —Ç–æ–∫–µ–Ω–æ–≤"
    
    def test_multiple_messages(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Ç–æ–∫–µ–Ω—ã —Å—É–º–º–∏—Ä—É—é—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.
        """
        print("–¢–µ—Å—Ç: –ù–µ—Å–∫–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏–π...")
        messages = [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "Hello!"},
            {"role": "assistant", "content": "Hi there! How can I help you?"},
            {"role": "user", "content": "What is the weather?"}
        ]
        
        result = count_message_tokens(messages)
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        
        # –ë–æ–ª—å—à–µ —Å–æ–æ–±—â–µ–Ω–∏–π = –±–æ–ª—å—à–µ —Ç–æ–∫–µ–Ω–æ–≤
        single_message = count_message_tokens([messages[0]])
        assert result > single_message, "–ù–µ—Å–∫–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å –±–æ–ª—å—à–µ —Ç–æ–∫–µ–Ω–æ–≤"
    
    def test_message_with_tool_calls(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏—è —Å tool_calls.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ tool_calls —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è.
        """
        print("–¢–µ—Å—Ç: –°–æ–æ–±—â–µ–Ω–∏–µ —Å tool_calls...")
        messages = [
            {
                "role": "assistant",
                "content": "",
                "tool_calls": [
                    {
                        "id": "call_123",
                        "type": "function",
                        "function": {
                            "name": "get_weather",
                            "arguments": '{"location": "Moscow"}'
                        }
                    }
                ]
            }
        ]
        
        result = count_message_tokens(messages)
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        
        assert result > 0, "–°–æ–æ–±—â–µ–Ω–∏–µ —Å tool_calls –¥–æ–ª–∂–Ω–æ –∏–º–µ—Ç—å —Ç–æ–∫–µ–Ω—ã"
    
    def test_message_with_tool_call_id(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è tool response —Å–æ–æ–±—â–µ–Ω–∏—è.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ tool_call_id —É—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è.
        """
        print("–¢–µ—Å—Ç: Tool response —Å–æ–æ–±—â–µ–Ω–∏–µ...")
        messages = [
            {
                "role": "tool",
                "content": "The weather in Moscow is sunny, 25¬∞C",
                "tool_call_id": "call_123"
            }
        ]
        
        result = count_message_tokens(messages)
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        
        assert result > 0, "Tool response –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å —Ç–æ–∫–µ–Ω—ã"
    
    def test_message_with_list_content(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ list content –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è.
        """
        print("–¢–µ—Å—Ç: –ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç...")
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "What is in this image?"},
                    {"type": "image_url", "image_url": {"url": "https://example.com/image.jpg"}}
                ]
            }
        ]
        
        result = count_message_tokens(messages)
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        
        assert result > 0, "–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å —Ç–æ–∫–µ–Ω—ã"
    
    def test_without_claude_correction(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥—Å—á—ë—Ç –±–µ–∑ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ apply_claude_correction=False —Ä–∞–±–æ—Ç–∞–µ—Ç.
        """
        print("–¢–µ—Å—Ç: –ë–µ–∑ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏...")
        messages = [{"role": "user", "content": "Test message"}]
        
        with_correction = count_message_tokens(messages, apply_claude_correction=True)
        without_correction = count_message_tokens(messages, apply_claude_correction=False)
        
        print(f"–° –∫–æ—Ä—Ä–µ–∫—Ü–∏–µ–π: {with_correction}")
        print(f"–ë–µ–∑ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏: {without_correction}")
        
        assert with_correction > without_correction, "–° –∫–æ—Ä—Ä–µ–∫—Ü–∏–µ–π –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –±–æ–ª—å—à–µ"
    
    def test_message_with_empty_content(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥—Å—á—ë—Ç –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏—è —Å –ø—É—Å—Ç—ã–º content.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø—É—Å—Ç–æ–π content –Ω–µ –ª–æ–º–∞–µ—Ç –ø–æ–¥—Å—á—ë—Ç.
        """
        print("–¢–µ—Å—Ç: –ü—É—Å—Ç–æ–π content...")
        messages = [{"role": "user", "content": ""}]
        
        result = count_message_tokens(messages)
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        
        # –î–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–ª—É–∂–µ–±–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã (role, —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏)
        assert result > 0, "–î–∞–∂–µ –ø—É—Å—Ç–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –∏–º–µ—Ç—å —Å–ª—É–∂–µ–±–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã"
    
    def test_message_with_none_content(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥—Å—á—ë—Ç –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏—è —Å None content.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ None content –Ω–µ –ª–æ–º–∞–µ—Ç –ø–æ–¥—Å—á—ë—Ç.
        """
        print("–¢–µ—Å—Ç: None content...")
        messages = [{"role": "assistant", "content": None}]
        
        result = count_message_tokens(messages)
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        
        assert result > 0, "–°–æ–æ–±—â–µ–Ω–∏–µ —Å None content –¥–æ–ª–∂–Ω–æ –∏–º–µ—Ç—å —Å–ª—É–∂–µ–±–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã"


class TestCountToolsTokens:
    """–¢–µ—Å—Ç—ã –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ count_tools_tokens."""
    
    def test_none_returns_zero(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ None –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 0 —Ç–æ–∫–µ–Ω–æ–≤.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ None.
        """
        print("–¢–µ—Å—Ç: None...")
        result = count_tools_tokens(None)
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        assert result == 0, "None –¥–æ–ª–∂–µ–Ω –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å 0 —Ç–æ–∫–µ–Ω–æ–≤"
    
    def test_empty_list_returns_zero(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 0 —Ç–æ–∫–µ–Ω–æ–≤.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø—É—Å—Ç–æ–≥–æ —Å–ø–∏—Å–∫–∞.
        """
        print("–¢–µ—Å—Ç: –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫...")
        result = count_tools_tokens([])
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        assert result == 0, "–ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –¥–æ–ª–∂–µ–Ω –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å 0 —Ç–æ–∫–µ–Ω–æ–≤"
    
    def test_single_tool(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è –≤ –±–∞–∑–æ–≤–æ–π —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏.
        """
        print("–¢–µ—Å—Ç: –û–¥–∏–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç...")
        tools = [
            {
                "type": "function",
                "function": {
                    "name": "get_weather",
                    "description": "Get the current weather for a location",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "location": {"type": "string", "description": "City name"}
                        },
                        "required": ["location"]
                    }
                }
            }
        ]
        
        result = count_tools_tokens(tools)
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        
        assert result > 0, "–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å —Ç–æ–∫–µ–Ω—ã"
    
    def test_multiple_tools(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Ç–æ–∫–µ–Ω—ã —Å—É–º–º–∏—Ä—É—é—Ç—Å—è.
        """
        print("–¢–µ—Å—Ç: –ù–µ—Å–∫–æ–ª—å–∫–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤...")
        tools = [
            {
                "type": "function",
                "function": {
                    "name": "get_weather",
                    "description": "Get weather",
                    "parameters": {"type": "object", "properties": {}}
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "search_web",
                    "description": "Search the web",
                    "parameters": {"type": "object", "properties": {}}
                }
            }
        ]
        
        result = count_tools_tokens(tools)
        single_tool = count_tools_tokens([tools[0]])
        
        print(f"–î–≤–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞: {result}")
        print(f"–û–¥–∏–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {single_tool}")
        
        assert result > single_tool, "–ë–æ–ª—å—à–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ = –±–æ–ª—å—à–µ —Ç–æ–∫–µ–Ω–æ–≤"
    
    def test_tool_with_complex_parameters(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥—Å—á—ë—Ç –¥–ª—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ —Å–æ —Å–ª–æ–∂–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ JSON schema –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —É—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è.
        """
        print("–¢–µ—Å—Ç: –°–ª–æ–∂–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã...")
        tools = [
            {
                "type": "function",
                "function": {
                    "name": "complex_function",
                    "description": "A function with complex parameters",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "name": {"type": "string", "description": "Name"},
                            "age": {"type": "integer", "description": "Age"},
                            "address": {
                                "type": "object",
                                "properties": {
                                    "street": {"type": "string"},
                                    "city": {"type": "string"},
                                    "country": {"type": "string"}
                                }
                            },
                            "tags": {
                                "type": "array",
                                "items": {"type": "string"}
                            }
                        },
                        "required": ["name", "age"]
                    }
                }
            }
        ]
        
        result = count_tools_tokens(tools)
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        
        assert result > 0, "–°–ª–æ–∂–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å —Ç–æ–∫–µ–Ω—ã"
    
    def test_tool_without_parameters(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥—Å—á—ë—Ç –¥–ª—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ –±–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ parameters –Ω–µ –ª–æ–º–∞–µ—Ç –ø–æ–¥—Å—á—ë—Ç.
        """
        print("–¢–µ—Å—Ç: –ë–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤...")
        tools = [
            {
                "type": "function",
                "function": {
                    "name": "no_params_func",
                    "description": "A function without parameters"
                }
            }
        ]
        
        result = count_tools_tokens(tools)
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        
        assert result > 0, "–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –±–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å —Ç–æ–∫–µ–Ω—ã"
    
    def test_tool_with_empty_description(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥—Å—á—ë—Ç –¥–ª—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ —Å –ø—É—Å—Ç—ã–º description.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –ø—É—Å—Ç–æ–π description –Ω–µ –ª–æ–º–∞–µ—Ç –ø–æ–¥—Å—á—ë—Ç.
        """
        print("–¢–µ—Å—Ç: –ü—É—Å—Ç–æ–π description...")
        tools = [
            {
                "type": "function",
                "function": {
                    "name": "func",
                    "description": "",
                    "parameters": {"type": "object", "properties": {}}
                }
            }
        ]
        
        result = count_tools_tokens(tools)
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        
        assert result > 0, "–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç —Å –ø—É—Å—Ç—ã–º description –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å —Ç–æ–∫–µ–Ω—ã"
    
    def test_non_function_tool_type(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ —Å type != "function".
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ non-function tools –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è.
        """
        print("–¢–µ—Å—Ç: Non-function tool...")
        tools = [
            {
                "type": "other_type",
                "some_field": "value"
            }
        ]
        
        result = count_tools_tokens(tools)
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        
        # –î–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ö–æ—Ç—è –±—ã —Å–ª—É–∂–µ–±–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
        assert result >= 0, "Non-function tool –Ω–µ –¥–æ–ª–∂–µ–Ω –ª–æ–º–∞—Ç—å –ø–æ–¥—Å—á—ë—Ç"
    
    def test_without_claude_correction(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥—Å—á—ë—Ç –±–µ–∑ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ apply_claude_correction=False —Ä–∞–±–æ—Ç–∞–µ—Ç.
        """
        print("–¢–µ—Å—Ç: –ë–µ–∑ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏...")
        tools = [
            {
                "type": "function",
                "function": {
                    "name": "test_func",
                    "description": "Test function",
                    "parameters": {"type": "object", "properties": {}}
                }
            }
        ]
        
        with_correction = count_tools_tokens(tools, apply_claude_correction=True)
        without_correction = count_tools_tokens(tools, apply_claude_correction=False)
        
        print(f"–° –∫–æ—Ä—Ä–µ–∫—Ü–∏–µ–π: {with_correction}")
        print(f"–ë–µ–∑ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏: {without_correction}")
        
        assert with_correction > without_correction, "–° –∫–æ—Ä—Ä–µ–∫—Ü–∏–µ–π –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –±–æ–ª—å—à–µ"


class TestEstimateRequestTokens:
    """–¢–µ—Å—Ç—ã –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ estimate_request_tokens."""
    
    def test_messages_only(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—Ü–µ–Ω–∫—É —Ç–æ–∫–µ–Ω–æ–≤ —Ç–æ–ª—å–∫–æ –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏–π.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è –≤ –±–∞–∑–æ–≤–æ–π —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏.
        """
        print("–¢–µ—Å—Ç: –¢–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏—è...")
        messages = [{"role": "user", "content": "Hello!"}]
        
        result = estimate_request_tokens(messages)
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        
        assert "messages_tokens" in result
        assert "tools_tokens" in result
        assert "system_tokens" in result
        assert "total_tokens" in result
        
        assert result["messages_tokens"] > 0
        assert result["tools_tokens"] == 0
        assert result["system_tokens"] == 0
        assert result["total_tokens"] == result["messages_tokens"]
    
    def test_messages_with_tools(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—Ü–µ–Ω–∫—É —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —Å–æ–æ–±—â–µ–Ω–∏–π —Å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ tools —É—á–∏—Ç—ã–≤–∞—é—Ç—Å—è.
        """
        print("–¢–µ—Å—Ç: –°–æ–æ–±—â–µ–Ω–∏—è —Å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏...")
        messages = [{"role": "user", "content": "What is the weather?"}]
        tools = [
            {
                "type": "function",
                "function": {
                    "name": "get_weather",
                    "description": "Get weather",
                    "parameters": {"type": "object", "properties": {}}
                }
            }
        ]
        
        result = estimate_request_tokens(messages, tools=tools)
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        
        assert result["messages_tokens"] > 0
        assert result["tools_tokens"] > 0
        assert result["total_tokens"] == result["messages_tokens"] + result["tools_tokens"]
    
    def test_messages_with_system_prompt(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—Ü–µ–Ω–∫—É —Ç–æ–∫–µ–Ω–æ–≤ —Å –æ—Ç–¥–µ–ª—å–Ω—ã–º system prompt.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ system_prompt —É—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è.
        """
        print("–¢–µ—Å—Ç: –° system prompt...")
        messages = [{"role": "user", "content": "Hello!"}]
        system_prompt = "You are a helpful assistant."
        
        result = estimate_request_tokens(messages, system_prompt=system_prompt)
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        
        assert result["messages_tokens"] > 0
        assert result["system_tokens"] > 0
        assert result["total_tokens"] == result["messages_tokens"] + result["system_tokens"]
    
    def test_full_request(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—Ü–µ–Ω–∫—É —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å—É–º–º–∏—Ä—É—é—Ç—Å—è.
        """
        print("–¢–µ—Å—Ç: –ü–æ–ª–Ω—ã–π –∑–∞–ø—Ä–æ—Å...")
        messages = [
            {"role": "user", "content": "What is the weather in Moscow?"}
        ]
        tools = [
            {
                "type": "function",
                "function": {
                    "name": "get_weather",
                    "description": "Get weather for a location",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "location": {"type": "string"}
                        }
                    }
                }
            }
        ]
        system_prompt = "You are a weather assistant."
        
        result = estimate_request_tokens(messages, tools=tools, system_prompt=system_prompt)
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        
        expected_total = result["messages_tokens"] + result["tools_tokens"] + result["system_tokens"]
        assert result["total_tokens"] == expected_total, "Total –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—É–º–º–æ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"
    
    def test_empty_messages(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ—Ü–µ–Ω–∫—É –¥–ª—è –ø—É—Å—Ç–æ–≥–æ —Å–ø–∏—Å–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥—Ä–∞–Ω–∏—á–Ω–æ–≥–æ —Å–ª—É—á–∞—è.
        """
        print("–¢–µ—Å—Ç: –ü—É—Å—Ç—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è...")
        result = estimate_request_tokens([])
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        
        assert result["messages_tokens"] == 0
        assert result["total_tokens"] == 0


class TestClaudeCorrectionFactor:
    """–¢–µ—Å—Ç—ã –¥–ª—è –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ Claude."""
    
    def test_correction_factor_value(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Ä–∞–≤–µ–Ω 1.15.
        """
        print(f"–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏: {CLAUDE_CORRECTION_FACTOR}")
        assert CLAUDE_CORRECTION_FACTOR == 1.15, "–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 1.15"
    
    def test_correction_increases_token_count(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –∫–æ—Ä—Ä–µ–∫—Ü–∏—è —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.
        """
        print("–¢–µ—Å—Ç: –ö–æ—Ä—Ä–µ–∫—Ü–∏—è —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç —Ç–æ–∫–µ–Ω—ã...")
        text = "This is a test text for checking the correction factor"
        
        with_correction = count_tokens(text, apply_claude_correction=True)
        without_correction = count_tokens(text, apply_claude_correction=False)
        
        print(f"–° –∫–æ—Ä—Ä–µ–∫—Ü–∏–µ–π: {with_correction}")
        print(f"–ë–µ–∑ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏: {without_correction}")
        
        assert with_correction > without_correction
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ä–∞–∑–Ω–∏—Ü–∞ –ø—Ä–∏–º–µ—Ä–Ω–æ 15%
        increase_percent = (with_correction - without_correction) / without_correction * 100
        print(f"–£–≤–µ–ª–∏—á–µ–Ω–∏–µ: {increase_percent:.1f}%")
        
        # –î–æ–ø—É—Å–∫–∞–µ–º –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç—å –∏–∑-–∑–∞ –æ–∫—Ä—É–≥–ª–µ–Ω–∏—è
        assert 10 <= increase_percent <= 20, "–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ–∫–æ–ª–æ 15%"
class TestGetEncoding:
    """–¢–µ—Å—Ç—ã –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ _get_encoding."""
    
    def test_returns_encoding_when_tiktoken_available(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ _get_encoding –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç encoding –∫–æ–≥–¥–∞ tiktoken –¥–æ—Å—Ç—É–ø–µ–Ω.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ tiktoken.
        """
        print("–¢–µ—Å—Ç: tiktoken –¥–æ—Å—Ç—É–ø–µ–Ω...")
        
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –¥–ª—è —á–∏—Å—Ç–æ–≥–æ —Ç–µ—Å—Ç–∞
        import kiro_gateway.tokenizer as tokenizer_module
        original_encoding = tokenizer_module._encoding
        tokenizer_module._encoding = None
        
        try:
            encoding = _get_encoding()
            print(f"Encoding: {encoding}")
            
            # –ï—Å–ª–∏ tiktoken —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –¥–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å encoding
            if encoding is not None:
                assert hasattr(encoding, 'encode'), "Encoding –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å –º–µ—Ç–æ–¥ encode"
        finally:
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º
            tokenizer_module._encoding = original_encoding
    
    def test_caches_encoding(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ encoding –∫—ç—à–∏—Ä—É–µ—Ç—Å—è.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è –≤ –ª–µ–Ω–∏–≤–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏.
        """
        print("–¢–µ—Å—Ç: –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ encoding...")
        
        encoding1 = _get_encoding()
        encoding2 = _get_encoding()
        
        print(f"Encoding 1: {encoding1}")
        print(f"Encoding 2: {encoding2}")
        
        # –î–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å —Ç–æ—Ç –∂–µ –æ–±—ä–µ–∫—Ç
        assert encoding1 is encoding2, "Encoding –¥–æ–ª–∂–µ–Ω –∫—ç—à–∏—Ä–æ–≤–∞—Ç—å—Å—è"
    
    def test_handles_import_error(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É ImportError –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ tiktoken.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Å–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ tiktoken.
        """
        print("–¢–µ—Å—Ç: ImportError...")
        
        import kiro_gateway.tokenizer as tokenizer_module
        original_encoding = tokenizer_module._encoding
        tokenizer_module._encoding = None
        
        try:
            # –ú–æ–∫–∏—Ä—É–µ–º import tiktoken —á—Ç–æ–±—ã –≤—ã–±—Ä–æ—Å–∏—Ç—å ImportError
            with patch.dict('sys.modules', {'tiktoken': None}):
                with patch('builtins.__import__', side_effect=ImportError("No module named 'tiktoken'")):
                    # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∫—ç—à
                    tokenizer_module._encoding = None
                    
                    # –î–æ–ª–∂–µ–Ω –≤–µ—Ä–Ω—É—Ç—å None –∏ –Ω–µ —É–ø–∞—Å—Ç—å
                    # –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –∏–∑-–∑–∞ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è —ç—Ç–æ—Ç —Ç–µ—Å—Ç –º–æ–∂–µ—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å –∏–¥–µ–∞–ª—å–Ω–æ
                    # –Ω–æ –≥–ª–∞–≤–Ω–æ–µ - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ –∫–æ–¥ –Ω–µ –ø–∞–¥–∞–µ—Ç
                    pass
        finally:
            tokenizer_module._encoding = original_encoding


class TestTokenizerIntegration:
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞."""
    
    def test_realistic_chat_request(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–≥–æ chat –∑–∞–ø—Ä–æ—Å–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è –≤ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–±–æ—Ç–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
        """
        print("–¢–µ—Å—Ç: –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π chat –∑–∞–ø—Ä–æ—Å...")
        
        messages = [
            {"role": "system", "content": "You are a helpful AI assistant. Be concise and accurate."},
            {"role": "user", "content": "What is the capital of France?"},
            {"role": "assistant", "content": "The capital of France is Paris."},
            {"role": "user", "content": "What is its population?"}
        ]
        
        tools = [
            {
                "type": "function",
                "function": {
                    "name": "search_web",
                    "description": "Search the web for information",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "query": {"type": "string", "description": "Search query"}
                        },
                        "required": ["query"]
                    }
                }
            }
        ]
        
        result = estimate_request_tokens(messages, tools=tools)
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç: {result}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑—É–º–Ω–æ—Å—Ç—å –∑–Ω–∞—á–µ–Ω–∏–π
        assert result["messages_tokens"] > 50, "–°–æ–æ–±—â–µ–Ω–∏—è –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å > 50 —Ç–æ–∫–µ–Ω–æ–≤"
        assert result["tools_tokens"] > 20, "Tools –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å > 20 —Ç–æ–∫–µ–Ω–æ–≤"
        assert result["total_tokens"] > 70, "Total –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å > 70 —Ç–æ–∫–µ–Ω–æ–≤"
    
    def test_large_context(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –±–æ–ª—å—à–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è –≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö.
        """
        print("–¢–µ—Å—Ç: –ë–æ–ª—å—à–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç...")
        
        # –°–æ–∑–¥–∞—ë–º –±–æ–ª—å—à–æ–π —Ç–µ–∫—Å—Ç
        large_text = "This is a test sentence. " * 1000  # ~5000 —Å–ª–æ–≤
        
        messages = [{"role": "user", "content": large_text}]
        
        result = estimate_request_tokens(messages)
        print(f"–¢–æ–∫–µ–Ω–æ–≤ –≤ –±–æ–ª—å—à–æ–º —Ç–µ–∫—Å—Ç–µ: {result['total_tokens']}")
        
        # –î–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤
        assert result["total_tokens"] > 1000, "–ë–æ–ª—å—à–æ–π —Ç–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å > 1000 —Ç–æ–∫–µ–Ω–æ–≤"
    
    def test_consistency_across_calls(self):
        """
        –ß—Ç–æ –æ–Ω –¥–µ–ª–∞–µ—Ç: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –ø–æ–¥—Å—á—ë—Ç–∞ –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –≤—ã–∑–æ–≤–∞—Ö.
        –¶–µ–ª—å: –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω—ã.
        """
        print("–¢–µ—Å—Ç: –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å...")
        
        text = "This is a test for consistency checking"
        
        results = [count_tokens(text) for _ in range(5)]
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {results}")
        
        # –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏
        assert len(set(results)) == 1, "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–º–∏"
    
    


================================================
FILE: .github/ISSUE_TEMPLATE/bug_report.yml
================================================
name: üêõ Bug Report
description: Something isn't working? Report it here
title: "[Bug]: "
labels: ["bug"]
body:
  - type: markdown
    attributes:
      value: |
        ## Before submitting
        
        Please enable debug logging to help me fix the issue faster:
        1. Add `DEBUG_MODE=errors` to your `.env` file
        2. Restart the gateway
        3. Reproduce the error
        4. Attach files from `debug_logs/` folder below

  - type: input
    id: version
    attributes:
      label: Gateway Version
      description: Which version are you using?
      placeholder: "e.g. v1.0.6"
    validations:
      required: true

  - type: textarea
    id: description
    attributes:
      label: What happened?
      description: Describe what you were doing and what went wrong
      placeholder: "I was trying to use X and got a 400 error \"Improperly formed request\"..."
    validations:
      required: true

  - type: textarea
    id: logs
    attributes:
      label: Debug Logs
      description: |
        Attach files from `debug_logs/` folder, especially these:
        - `app_logs.txt`
        - `request_body.json`
        - `kiro_request_body.json`
        
        Drag & drop files here or paste the content.
      placeholder: "Drag & drop your log files here..."
    validations:
      required: true

